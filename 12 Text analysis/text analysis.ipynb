{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87763e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "941fafd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  score\n",
       "0  So there is no way for me to plug it in here i...      0\n",
       "1                        Good case, Excellent value.      1\n",
       "2                             Great for the jawbone.      1\n",
       "3  Tied to charger for conversations lasting more...      0\n",
       "4                                  The mic is great.      1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv('review.txt',delimiter='\\t')\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d446070c",
   "metadata": {},
   "source": [
    "<h3>Term-Frequency Inverse-Document-Frequency (TF-IDF)</h3>\n",
    "\n",
    "<h4>Tokenizing the Documents</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee9ca033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['So',\n",
       "  'there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'way',\n",
       "  'for',\n",
       "  'me',\n",
       "  'to',\n",
       "  'plug',\n",
       "  'it',\n",
       "  'in',\n",
       "  'here',\n",
       "  'in',\n",
       "  'the',\n",
       "  'US',\n",
       "  'unless',\n",
       "  'I',\n",
       "  'go',\n",
       "  'by',\n",
       "  'a',\n",
       "  'converter',\n",
       "  '.'],\n",
       " ['Good', 'case', ',', 'Excellent', 'value', '.'],\n",
       " ['Great', 'for', 'the', 'jawbone', '.'],\n",
       " ['Tied',\n",
       "  'to',\n",
       "  'charger',\n",
       "  'for',\n",
       "  'conversations',\n",
       "  'lasting',\n",
       "  'more',\n",
       "  'than',\n",
       "  '45',\n",
       "  'minutes.MAJOR',\n",
       "  'PROBLEMS',\n",
       "  '!',\n",
       "  '!'],\n",
       " ['The', 'mic', 'is', 'great', '.']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "reviews_tknz = [word_tokenize(r) for r in reviews['review']]\n",
    "reviews_tknz[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712d663a",
   "metadata": {},
   "source": [
    "<h4>Removing Stop Words</h4>\n",
    "\n",
    "While being a common step in processing text data, we can see that in this case, removing stop words largely neutralizes the reviews, therefore we will not do this in this particular project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2934df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'had', 'then', \"should've\", 'with', 'he', 'nor', 'off', 'in', 'will', 'been', 'its', 'after', 'are', \"wasn't\", 'about', \"shouldn't\", 'isn', 'before', 've', 's', 'yours', 'no', 'ma', 'out', 'wasn', \"she's\", 'our', 'below', 'how', 'some', 't', 'needn', \"couldn't\", \"you've\", 'do', 'while', 'the', 'why', 'theirs', 'if', \"mightn't\", 'now', 'it', 'into', 'where', 'most', 'y', \"hadn't\", 'she', 'all', 'under', 'has', 'that', 'down', \"mustn't\", 'doing', 'ain', 'didn', 'whom', 'what', 'for', 'few', 'only', 'we', 'ours', 'did', 'be', 'other', 'each', \"it's\", \"hasn't\", 'so', 'was', 'during', \"needn't\", 'doesn', 'shouldn', 'from', 'between', 'don', 'hadn', 'on', 'can', 'herself', 'they', 'should', 'such', 'just', 'my', 'them', 'who', 'because', \"doesn't\", \"haven't\", \"shan't\", 'won', 'does', 'myself', 'themselves', \"you'd\", 'once', 'very', 'mustn', 'up', 'than', 'this', 'as', 'their', 'of', 'll', 'not', 're', \"don't\", 'having', 'to', 'and', 'himself', \"won't\", 'ourselves', 'being', \"wouldn't\", 'here', 'hasn', 'an', 'weren', 'yourselves', \"aren't\", \"you'll\", 'through', 'those', 'same', 'm', 'd', 'more', 'aren', 'couldn', 'at', 'him', \"you're\", 'a', 'itself', 'by', 'is', 'these', 'over', 'i', 'too', 'haven', 'wouldn', 'his', 'own', 'against', 'yourself', 'which', 'any', 'when', 'your', 'you', \"isn't\", \"that'll\", 'mightn', 'her', 'both', \"didn't\", 'or', 'me', 'were', 'am', 'until', \"weren't\", 'but', 'above', 'have', 'shan', 'there', 'again', 'o', 'hers', 'further'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d46bcf0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['So', 'way', 'plug', 'US', 'unless', 'I', 'go', 'converter', '.'],\n",
       " ['Good', 'case', ',', 'Excellent', 'value', '.']]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_flt = [[w  for w in r if w not in stop_words] for r in reviews_tknz]\n",
    "reviews_flt[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b58caff",
   "metadata": {},
   "source": [
    "<h4>Stemming</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a0087a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['so',\n",
       "  'there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'way',\n",
       "  'for',\n",
       "  'me',\n",
       "  'to',\n",
       "  'plug',\n",
       "  'it',\n",
       "  'in',\n",
       "  'here',\n",
       "  'in',\n",
       "  'the',\n",
       "  'us',\n",
       "  'unless',\n",
       "  'i',\n",
       "  'go',\n",
       "  'by',\n",
       "  'a',\n",
       "  'convert',\n",
       "  '.'],\n",
       " ['good', 'case', ',', 'excel', 'valu', '.']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "reviews_stm = [[ps.stem(w) for w in r] for r in reviews_tknz]\n",
    "reviews_stm[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a03237",
   "metadata": {},
   "source": [
    "<h4>Lemmatizing</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3da81f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['so',\n",
       "  'there',\n",
       "  'be',\n",
       "  'no',\n",
       "  'way',\n",
       "  'for',\n",
       "  'me',\n",
       "  'to',\n",
       "  'plug',\n",
       "  'it',\n",
       "  'in',\n",
       "  'here',\n",
       "  'in',\n",
       "  'the',\n",
       "  'us',\n",
       "  'unless',\n",
       "  'i',\n",
       "  'go',\n",
       "  'by',\n",
       "  'a',\n",
       "  'convert',\n",
       "  '.'],\n",
       " ['good', 'case', ',', 'excel', 'valu', '.']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "reviews_lem = [[lem.lemmatize(w,'v') for w in r] for r in reviews_stm]\n",
    "reviews_lem[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24450667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['so there be no way for me to plug it in here in the us unless i go by a convert .',\n",
       " 'good case , excel valu .',\n",
       " 'great for the jawbon .',\n",
       " 'tie to charger for convers last more than 45 minutes.major problem ! !',\n",
       " 'the mic be great .']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_prc = [' '.join(r) for r in reviews_lem]\n",
    "reviews_prc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d7c11269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "reviews_tfidf = tfidf.fit_transform(reviews_prc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "57628394",
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = np.random.permutation(np.arange(len(reviews)))\n",
    "train_indx = indx[:2000]\n",
    "test_indx = indx[2000:]\n",
    "\n",
    "trainX = reviews_tfidf[train_indx]\n",
    "testX = reviews_tfidf[test_indx]\n",
    "trainY = reviews['score'].values[train_indx]\n",
    "testY = reviews['score'].values[test_indx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd57531",
   "metadata": {},
   "source": [
    "<h4>Support Vector Machine</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c97db9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid=[{'C': [0.01, 0.1, 1, 10, 100],\n",
       "                          'gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                          'kernel': ['rbf']}],\n",
       "             return_train_score=True, scoring='accuracy')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "param_grid = [{\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'kernel' : ['rbf'],\n",
    "    'gamma' : [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=5, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "52fa5637",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.8245000000000001\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "17da2e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8275401069518716"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dt = grid_search.best_estimator_\n",
    "best_dt.score(testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f216e136",
   "metadata": {},
   "source": [
    "<h4>Neural Network</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1cbf8781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=MLPClassifier(max_iter=1000),\n",
       "             param_grid=[{'alpha': [0.01, 0.1, 1],\n",
       "                          'hidden_layer_sizes': [[2024, 2024],\n",
       "                                                 [2024, 2024, 2024]]}],\n",
       "             return_train_score=True, scoring='accuracy')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "n_features = trainX.shape[1]\n",
    "\n",
    "param_grid = [{\n",
    "    'hidden_layer_sizes' : [\n",
    "                            [n_features//2,n_features//2],                 #two hidden layer with n_features/2 neurons\n",
    "                            [n_features//2,n_features//2,n_features//2]],   #three hidden layer with n_features/2 neurons\n",
    "    'alpha' : [0.01, 0.1, 1]                                    #regularization terms\n",
    "}]\n",
    "\n",
    "mlp = MLPClassifier(max_iter=1000)\n",
    "\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=3, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "26291bf3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1, 'hidden_layer_sizes': [2024, 2024]}\n",
      "0.8005051528289909\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3bb00e3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8141711229946524"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dt = grid_search.best_estimator_\n",
    "best_dt.score(testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e4640a",
   "metadata": {},
   "source": [
    "<h3>Universal Sentence Encoder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "76ab6b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "model = hub.load(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d86022e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_use = model(reviews['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b44a9d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_use = np.array(reviews_use)\n",
    "trainX_use = reviews_use[train_indx]\n",
    "testX_use = reviews_use[test_indx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29cd5a1",
   "metadata": {},
   "source": [
    "<h4>Support Vector Machine</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bc91crdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid=[{'C': [0.01, 0.1, 1, 10, 100],\n",
       "                          'gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                          'kernel': ['rbf']}],\n",
       "             return_train_score=True, scoring='accuracy')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "param_grid = [{\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'kernel' : ['rbf'],\n",
    "    'gamma' : [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=5, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX_use,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "271e7c70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.9019999999999999\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "17ds2e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.893048128342246"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dt = grid_search.best_estimator_\n",
    "best_dt.score(testX_use, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6110a34d",
   "metadata": {},
   "source": [
    "<h4>Neural Network</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da900bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "n_features = trainX.shape[1]\n",
    "\n",
    "param_grid = [{\n",
    "    'hidden_layer_sizes' : [\n",
    "                            [n_features//2,n_features//2],                 #two hidden layer with n_features/2 neurons\n",
    "                            [n_features//2,n_features//2,n_features//2]],   #three hidden layer with n_features/2 neurons\n",
    "    'alpha' : [0.01, 0.1, 1]                                    #regularization terms\n",
    "}]\n",
    "\n",
    "mlp = MLPClassifier(max_iter=1000)\n",
    "\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=3, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX_use,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "26391bf3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1, 'hidden_layer_sizes': [2024, 2024]}\n",
      "0.8885114499807153\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7650a814",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8850267379679144"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dt = grid_search.best_estimator_\n",
    "best_dt.score(testX_use, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750605cb",
   "metadata": {},
   "source": [
    "<h3>Word Embedding</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d7e903f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rlength = [len(r) for r in reviews_lem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1fceb254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5217bd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(rlength, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3b1df044",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c1abad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews_tknz = list(np.array(reviews_tknz, dtype=object)[train_indx])\n",
    "test_reviews_tknz = list(np.array(reviews_tknz, dtype=object)[test_indx])\n",
    "\n",
    "train_reviews = [r for r in train_reviews_tknz if len(r) <= max_length]\n",
    "train_reviews_lab = [lab for (r,lab) in zip(train_reviews_tknz,trainY) if len(r) <= max_length]\n",
    "train_reviews_lab = np.int32(train_reviews_lab)\n",
    "\n",
    "test_reviews = [r for r in test_reviews if len(r) <= max_length]\n",
    "test_reviews_lab = [lab for (r,lab) in zip(test_reviews_tknz,testY) if len(r) <= max_length]\n",
    "testY_embs = np.int32(test_reviews_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "17f17e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 758.5/758.5MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "\n",
    "glove_vectors = gensim.downloader.load('glove-twitter-200')\n",
    "\n",
    "train_embs = [[glove_vectors[w] for w in r if w in glove_vectors.key_to_index]for r in train_reviews]\n",
    "test_embs = [[glove_vectors[w] for w in r if w in glove_vectors.key_to_index] for r in test_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f375d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_embs = np.zeros([len(train_embs), max_length, 200], dtype=np.float32)\n",
    "for i in range(len(train_embs)):\n",
    "    len_review = len(train_embs[i])\n",
    "    if len_review > 0:\n",
    "        trainX_embs[i,-len_review:] = np.array(train_embs[i])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainX_embs, validX_embs, trainY_embs, validY_embs = train_test_split(trainX_embs, train_reviews_lab)\n",
    "\n",
    "testX_embs = np.zeros([len(test_embs), max_length, 200], dtype=np.float32)\n",
    "for i in range(len(test_embs)):\n",
    "    len_review = len(test_embs[i])\n",
    "    if len_review > 0:\n",
    "        testX_embs[i,-len_review:] = np.array(test_embs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "50b7768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "810319e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_10 (GRU)                (None, 400)               722400    \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 400)               160400    \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 400)               160400    \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 1)                 401       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,043,601\n",
      "Trainable params: 1,043,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Input([max_length,200]))\n",
    "model.add(layers.GRU(400))\n",
    "\n",
    "model.add(layers.Dense(400, activation='relu'))\n",
    "model.add(layers.Dense(400, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a37f8122",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/750\n",
      "5/5 [==============================] - 3s 351ms/step - loss: 0.6958 - accuracy: 0.5000 - val_loss: 0.6945 - val_accuracy: 0.4901\n",
      "Epoch 2/750\n",
      "5/5 [==============================] - 1s 267ms/step - loss: 0.6949 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.4926\n",
      "Epoch 3/750\n",
      "5/5 [==============================] - 1s 260ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6917 - val_accuracy: 0.4926\n",
      "Epoch 4/750\n",
      "5/5 [==============================] - 1s 278ms/step - loss: 0.6920 - accuracy: 0.5082 - val_loss: 0.6905 - val_accuracy: 0.5000\n",
      "Epoch 5/750\n",
      "5/5 [==============================] - 1s 288ms/step - loss: 0.6908 - accuracy: 0.5181 - val_loss: 0.6896 - val_accuracy: 0.5369\n",
      "Epoch 6/750\n",
      "5/5 [==============================] - 1s 271ms/step - loss: 0.6898 - accuracy: 0.5567 - val_loss: 0.6888 - val_accuracy: 0.5714\n",
      "Epoch 7/750\n",
      "5/5 [==============================] - 1s 271ms/step - loss: 0.6890 - accuracy: 0.5764 - val_loss: 0.6881 - val_accuracy: 0.5862\n",
      "Epoch 8/750\n",
      "5/5 [==============================] - 1s 288ms/step - loss: 0.6883 - accuracy: 0.5903 - val_loss: 0.6874 - val_accuracy: 0.6158\n",
      "Epoch 9/750\n",
      "5/5 [==============================] - 1s 299ms/step - loss: 0.6876 - accuracy: 0.6051 - val_loss: 0.6868 - val_accuracy: 0.6207\n",
      "Epoch 10/750\n",
      "5/5 [==============================] - 1s 260ms/step - loss: 0.6870 - accuracy: 0.6010 - val_loss: 0.6863 - val_accuracy: 0.6133\n",
      "Epoch 11/750\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.6864 - accuracy: 0.6034 - val_loss: 0.6857 - val_accuracy: 0.6207\n",
      "Epoch 12/750\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.6858 - accuracy: 0.6141 - val_loss: 0.6852 - val_accuracy: 0.6305\n",
      "Epoch 13/750\n",
      "5/5 [==============================] - 1s 266ms/step - loss: 0.6852 - accuracy: 0.6190 - val_loss: 0.6847 - val_accuracy: 0.6232\n",
      "Epoch 14/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.6847 - accuracy: 0.6240 - val_loss: 0.6842 - val_accuracy: 0.6232\n",
      "Epoch 15/750\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 0.6841 - accuracy: 0.6264 - val_loss: 0.6837 - val_accuracy: 0.6330\n",
      "Epoch 16/750\n",
      "5/5 [==============================] - 1s 270ms/step - loss: 0.6836 - accuracy: 0.6297 - val_loss: 0.6832 - val_accuracy: 0.6379\n",
      "Epoch 17/750\n",
      "5/5 [==============================] - 1s 266ms/step - loss: 0.6831 - accuracy: 0.6305 - val_loss: 0.6827 - val_accuracy: 0.6404\n",
      "Epoch 18/750\n",
      "5/5 [==============================] - 1s 264ms/step - loss: 0.6826 - accuracy: 0.6322 - val_loss: 0.6823 - val_accuracy: 0.6379\n",
      "Epoch 19/750\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.6821 - accuracy: 0.6346 - val_loss: 0.6818 - val_accuracy: 0.6379\n",
      "Epoch 20/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.6816 - accuracy: 0.6396 - val_loss: 0.6814 - val_accuracy: 0.6404\n",
      "Epoch 21/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.6811 - accuracy: 0.6355 - val_loss: 0.6810 - val_accuracy: 0.6379\n",
      "Epoch 22/750\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.6807 - accuracy: 0.6281 - val_loss: 0.6806 - val_accuracy: 0.6355\n",
      "Epoch 23/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.6802 - accuracy: 0.6297 - val_loss: 0.6801 - val_accuracy: 0.6379\n",
      "Epoch 24/750\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.6797 - accuracy: 0.6330 - val_loss: 0.6797 - val_accuracy: 0.6453\n",
      "Epoch 25/750\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.6792 - accuracy: 0.6371 - val_loss: 0.6793 - val_accuracy: 0.6429\n",
      "Epoch 26/750\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.6787 - accuracy: 0.6346 - val_loss: 0.6789 - val_accuracy: 0.6478\n",
      "Epoch 27/750\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.6783 - accuracy: 0.6371 - val_loss: 0.6785 - val_accuracy: 0.6478\n",
      "Epoch 28/750\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 0.6779 - accuracy: 0.6363 - val_loss: 0.6780 - val_accuracy: 0.6527\n",
      "Epoch 29/750\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.6774 - accuracy: 0.6412 - val_loss: 0.6776 - val_accuracy: 0.6527\n",
      "Epoch 30/750\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.6769 - accuracy: 0.6404 - val_loss: 0.6772 - val_accuracy: 0.6552\n",
      "Epoch 31/750\n",
      "5/5 [==============================] - 1s 257ms/step - loss: 0.6764 - accuracy: 0.6437 - val_loss: 0.6768 - val_accuracy: 0.6601\n",
      "Epoch 32/750\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.6760 - accuracy: 0.6486 - val_loss: 0.6763 - val_accuracy: 0.6601\n",
      "Epoch 33/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6755 - accuracy: 0.6502 - val_loss: 0.6759 - val_accuracy: 0.6601\n",
      "Epoch 34/750\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.6751 - accuracy: 0.6461 - val_loss: 0.6755 - val_accuracy: 0.6552\n",
      "Epoch 35/750\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.6746 - accuracy: 0.6453 - val_loss: 0.6751 - val_accuracy: 0.6650\n",
      "Epoch 36/750\n",
      "5/5 [==============================] - 1s 264ms/step - loss: 0.6742 - accuracy: 0.6470 - val_loss: 0.6747 - val_accuracy: 0.6700\n",
      "Epoch 37/750\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.6737 - accuracy: 0.6437 - val_loss: 0.6743 - val_accuracy: 0.6700\n",
      "Epoch 38/750\n",
      "5/5 [==============================] - 1s 259ms/step - loss: 0.6732 - accuracy: 0.6502 - val_loss: 0.6738 - val_accuracy: 0.6724\n",
      "Epoch 39/750\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.6728 - accuracy: 0.6568 - val_loss: 0.6734 - val_accuracy: 0.6724\n",
      "Epoch 40/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.6723 - accuracy: 0.6544 - val_loss: 0.6729 - val_accuracy: 0.6724\n",
      "Epoch 41/750\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.6719 - accuracy: 0.6560 - val_loss: 0.6724 - val_accuracy: 0.6749\n",
      "Epoch 42/750\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.6714 - accuracy: 0.6568 - val_loss: 0.6720 - val_accuracy: 0.6724\n",
      "Epoch 43/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6708 - accuracy: 0.6568 - val_loss: 0.6715 - val_accuracy: 0.6724\n",
      "Epoch 44/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.6703 - accuracy: 0.6576 - val_loss: 0.6710 - val_accuracy: 0.6700\n",
      "Epoch 45/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.6699 - accuracy: 0.6634 - val_loss: 0.6705 - val_accuracy: 0.6724\n",
      "Epoch 46/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.6694 - accuracy: 0.6658 - val_loss: 0.6700 - val_accuracy: 0.6724\n",
      "Epoch 47/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.6688 - accuracy: 0.6658 - val_loss: 0.6696 - val_accuracy: 0.6675\n",
      "Epoch 48/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.6683 - accuracy: 0.6617 - val_loss: 0.6691 - val_accuracy: 0.6749\n",
      "Epoch 49/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6678 - accuracy: 0.6593 - val_loss: 0.6686 - val_accuracy: 0.6749\n",
      "Epoch 50/750\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 0.6672 - accuracy: 0.6568 - val_loss: 0.6681 - val_accuracy: 0.6773\n",
      "Epoch 51/750\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.6668 - accuracy: 0.6650 - val_loss: 0.6675 - val_accuracy: 0.6700\n",
      "Epoch 52/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.6662 - accuracy: 0.6716 - val_loss: 0.6670 - val_accuracy: 0.6700\n",
      "Epoch 53/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.6656 - accuracy: 0.6724 - val_loss: 0.6664 - val_accuracy: 0.6724\n",
      "Epoch 54/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6651 - accuracy: 0.6724 - val_loss: 0.6659 - val_accuracy: 0.6724\n",
      "Epoch 55/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.6645 - accuracy: 0.6790 - val_loss: 0.6653 - val_accuracy: 0.6724\n",
      "Epoch 56/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.6640 - accuracy: 0.6806 - val_loss: 0.6647 - val_accuracy: 0.6773\n",
      "Epoch 57/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.6634 - accuracy: 0.6806 - val_loss: 0.6642 - val_accuracy: 0.6724\n",
      "Epoch 58/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6628 - accuracy: 0.6749 - val_loss: 0.6637 - val_accuracy: 0.6773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6623 - accuracy: 0.6683 - val_loss: 0.6631 - val_accuracy: 0.6749\n",
      "Epoch 60/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.6618 - accuracy: 0.6658 - val_loss: 0.6626 - val_accuracy: 0.6749\n",
      "Epoch 61/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.6612 - accuracy: 0.6658 - val_loss: 0.6620 - val_accuracy: 0.6749\n",
      "Epoch 62/750\n",
      "5/5 [==============================] - 1s 258ms/step - loss: 0.6607 - accuracy: 0.6757 - val_loss: 0.6614 - val_accuracy: 0.6798\n",
      "Epoch 63/750\n",
      "5/5 [==============================] - 1s 301ms/step - loss: 0.6601 - accuracy: 0.6806 - val_loss: 0.6609 - val_accuracy: 0.6847\n",
      "Epoch 64/750\n",
      "5/5 [==============================] - 1s 265ms/step - loss: 0.6595 - accuracy: 0.6814 - val_loss: 0.6603 - val_accuracy: 0.6798\n",
      "Epoch 65/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6590 - accuracy: 0.6790 - val_loss: 0.6598 - val_accuracy: 0.6798\n",
      "Epoch 66/750\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.6584 - accuracy: 0.6806 - val_loss: 0.6592 - val_accuracy: 0.6921\n",
      "Epoch 67/750\n",
      "5/5 [==============================] - 1s 262ms/step - loss: 0.6579 - accuracy: 0.6806 - val_loss: 0.6586 - val_accuracy: 0.6946\n",
      "Epoch 68/750\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.6573 - accuracy: 0.6839 - val_loss: 0.6580 - val_accuracy: 0.6847\n",
      "Epoch 69/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6568 - accuracy: 0.6823 - val_loss: 0.6575 - val_accuracy: 0.6946\n",
      "Epoch 70/750\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.6562 - accuracy: 0.6856 - val_loss: 0.6569 - val_accuracy: 0.6872\n",
      "Epoch 71/750\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.6556 - accuracy: 0.6864 - val_loss: 0.6563 - val_accuracy: 0.6847\n",
      "Epoch 72/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6550 - accuracy: 0.6839 - val_loss: 0.6558 - val_accuracy: 0.6897\n",
      "Epoch 73/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.6545 - accuracy: 0.6806 - val_loss: 0.6553 - val_accuracy: 0.6823\n",
      "Epoch 74/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6538 - accuracy: 0.6798 - val_loss: 0.6547 - val_accuracy: 0.6946\n",
      "Epoch 75/750\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.6534 - accuracy: 0.6839 - val_loss: 0.6540 - val_accuracy: 0.6872\n",
      "Epoch 76/750\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.6527 - accuracy: 0.6880 - val_loss: 0.6535 - val_accuracy: 0.6872\n",
      "Epoch 77/750\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.6521 - accuracy: 0.6872 - val_loss: 0.6529 - val_accuracy: 0.6921\n",
      "Epoch 78/750\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.6515 - accuracy: 0.6864 - val_loss: 0.6523 - val_accuracy: 0.6921\n",
      "Epoch 79/750\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.6509 - accuracy: 0.6888 - val_loss: 0.6517 - val_accuracy: 0.6897\n",
      "Epoch 80/750\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.6502 - accuracy: 0.6905 - val_loss: 0.6511 - val_accuracy: 0.6921\n",
      "Epoch 81/750\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.6496 - accuracy: 0.6880 - val_loss: 0.6505 - val_accuracy: 0.6921\n",
      "Epoch 82/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6490 - accuracy: 0.6872 - val_loss: 0.6499 - val_accuracy: 0.6921\n",
      "Epoch 83/750\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.6483 - accuracy: 0.6856 - val_loss: 0.6493 - val_accuracy: 0.6921\n",
      "Epoch 84/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.6477 - accuracy: 0.6888 - val_loss: 0.6486 - val_accuracy: 0.6921\n",
      "Epoch 85/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.6471 - accuracy: 0.6897 - val_loss: 0.6480 - val_accuracy: 0.6921\n",
      "Epoch 86/750\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.6464 - accuracy: 0.6913 - val_loss: 0.6474 - val_accuracy: 0.6946\n",
      "Epoch 87/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.6458 - accuracy: 0.6929 - val_loss: 0.6467 - val_accuracy: 0.6946\n",
      "Epoch 88/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.6452 - accuracy: 0.6938 - val_loss: 0.6461 - val_accuracy: 0.6946\n",
      "Epoch 89/750\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.6445 - accuracy: 0.6954 - val_loss: 0.6455 - val_accuracy: 0.6970\n",
      "Epoch 90/750\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.6438 - accuracy: 0.6954 - val_loss: 0.6448 - val_accuracy: 0.6970\n",
      "Epoch 91/750\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.6432 - accuracy: 0.6962 - val_loss: 0.6442 - val_accuracy: 0.6946\n",
      "Epoch 92/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6426 - accuracy: 0.6946 - val_loss: 0.6435 - val_accuracy: 0.6970\n",
      "Epoch 93/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.6419 - accuracy: 0.6979 - val_loss: 0.6428 - val_accuracy: 0.6970\n",
      "Epoch 94/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6412 - accuracy: 0.6962 - val_loss: 0.6421 - val_accuracy: 0.6946\n",
      "Epoch 95/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.6406 - accuracy: 0.6954 - val_loss: 0.6416 - val_accuracy: 0.6921\n",
      "Epoch 96/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.6401 - accuracy: 0.6954 - val_loss: 0.6408 - val_accuracy: 0.6921\n",
      "Epoch 97/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.6391 - accuracy: 0.6962 - val_loss: 0.6401 - val_accuracy: 0.6921\n",
      "Epoch 98/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.6384 - accuracy: 0.6979 - val_loss: 0.6394 - val_accuracy: 0.6946\n",
      "Epoch 99/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.6379 - accuracy: 0.6962 - val_loss: 0.6387 - val_accuracy: 0.6921\n",
      "Epoch 100/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.6370 - accuracy: 0.6979 - val_loss: 0.6380 - val_accuracy: 0.6921\n",
      "Epoch 101/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6362 - accuracy: 0.6970 - val_loss: 0.6373 - val_accuracy: 0.6946\n",
      "Epoch 102/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.6355 - accuracy: 0.6987 - val_loss: 0.6366 - val_accuracy: 0.6946\n",
      "Epoch 103/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.6348 - accuracy: 0.6962 - val_loss: 0.6358 - val_accuracy: 0.6946\n",
      "Epoch 104/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.6340 - accuracy: 0.6970 - val_loss: 0.6351 - val_accuracy: 0.6946\n",
      "Epoch 105/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6332 - accuracy: 0.6970 - val_loss: 0.6343 - val_accuracy: 0.6970\n",
      "Epoch 106/750\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.6325 - accuracy: 0.6954 - val_loss: 0.6335 - val_accuracy: 0.6995\n",
      "Epoch 107/750\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.6317 - accuracy: 0.6987 - val_loss: 0.6327 - val_accuracy: 0.6946\n",
      "Epoch 108/750\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.6310 - accuracy: 0.6987 - val_loss: 0.6320 - val_accuracy: 0.6946\n",
      "Epoch 109/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.6302 - accuracy: 0.6979 - val_loss: 0.6312 - val_accuracy: 0.6995\n",
      "Epoch 110/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.6294 - accuracy: 0.6979 - val_loss: 0.6304 - val_accuracy: 0.6995\n",
      "Epoch 111/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.6285 - accuracy: 0.7028 - val_loss: 0.6296 - val_accuracy: 0.6970\n",
      "Epoch 112/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6278 - accuracy: 0.7020 - val_loss: 0.6288 - val_accuracy: 0.6995\n",
      "Epoch 113/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6269 - accuracy: 0.7053 - val_loss: 0.6280 - val_accuracy: 0.6970\n",
      "Epoch 114/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6261 - accuracy: 0.7044 - val_loss: 0.6272 - val_accuracy: 0.6970\n",
      "Epoch 115/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6253 - accuracy: 0.7044 - val_loss: 0.6264 - val_accuracy: 0.6995\n",
      "Epoch 116/750\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.6245 - accuracy: 0.7011 - val_loss: 0.6257 - val_accuracy: 0.7020\n",
      "Epoch 117/750\n",
      "5/5 [==============================] - 1s 256ms/step - loss: 0.6236 - accuracy: 0.7028 - val_loss: 0.6249 - val_accuracy: 0.7044\n",
      "Epoch 118/750\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 0.6228 - accuracy: 0.7036 - val_loss: 0.6240 - val_accuracy: 0.7020\n",
      "Epoch 119/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.6220 - accuracy: 0.7061 - val_loss: 0.6232 - val_accuracy: 0.7020\n",
      "Epoch 120/750\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.6211 - accuracy: 0.7069 - val_loss: 0.6223 - val_accuracy: 0.7020\n",
      "Epoch 121/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6201 - accuracy: 0.7053 - val_loss: 0.6216 - val_accuracy: 0.7044\n",
      "Epoch 122/750\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.6192 - accuracy: 0.7061 - val_loss: 0.6207 - val_accuracy: 0.7020\n",
      "Epoch 123/750\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.6184 - accuracy: 0.7061 - val_loss: 0.6199 - val_accuracy: 0.7020\n",
      "Epoch 124/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.6175 - accuracy: 0.7085 - val_loss: 0.6190 - val_accuracy: 0.7044\n",
      "Epoch 125/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.6167 - accuracy: 0.7085 - val_loss: 0.6183 - val_accuracy: 0.7044\n",
      "Epoch 126/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.6157 - accuracy: 0.7085 - val_loss: 0.6172 - val_accuracy: 0.7020\n",
      "Epoch 127/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.6148 - accuracy: 0.7094 - val_loss: 0.6163 - val_accuracy: 0.7020\n",
      "Epoch 128/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.6140 - accuracy: 0.7094 - val_loss: 0.6154 - val_accuracy: 0.7020\n",
      "Epoch 129/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.6130 - accuracy: 0.7077 - val_loss: 0.6147 - val_accuracy: 0.7044\n",
      "Epoch 130/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.6120 - accuracy: 0.7118 - val_loss: 0.6140 - val_accuracy: 0.7044\n",
      "Epoch 131/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.6112 - accuracy: 0.7118 - val_loss: 0.6130 - val_accuracy: 0.7044\n",
      "Epoch 132/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.6101 - accuracy: 0.7118 - val_loss: 0.6121 - val_accuracy: 0.7044\n",
      "Epoch 133/750\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 0.6092 - accuracy: 0.7126 - val_loss: 0.6112 - val_accuracy: 0.7069\n",
      "Epoch 134/750\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.6082 - accuracy: 0.7126 - val_loss: 0.6104 - val_accuracy: 0.7044\n",
      "Epoch 135/750\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.6076 - accuracy: 0.7118 - val_loss: 0.6096 - val_accuracy: 0.7044\n",
      "Epoch 136/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.6065 - accuracy: 0.7126 - val_loss: 0.6084 - val_accuracy: 0.7020\n",
      "Epoch 137/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6054 - accuracy: 0.7094 - val_loss: 0.6076 - val_accuracy: 0.7020\n",
      "Epoch 138/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6044 - accuracy: 0.7102 - val_loss: 0.6067 - val_accuracy: 0.7020\n",
      "Epoch 139/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.6034 - accuracy: 0.7126 - val_loss: 0.6058 - val_accuracy: 0.6995\n",
      "Epoch 140/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.6025 - accuracy: 0.7167 - val_loss: 0.6050 - val_accuracy: 0.7069\n",
      "Epoch 141/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.6016 - accuracy: 0.7094 - val_loss: 0.6039 - val_accuracy: 0.7044\n",
      "Epoch 142/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.6005 - accuracy: 0.7094 - val_loss: 0.6031 - val_accuracy: 0.7020\n",
      "Epoch 143/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.5994 - accuracy: 0.7118 - val_loss: 0.6022 - val_accuracy: 0.6995\n",
      "Epoch 144/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.5983 - accuracy: 0.7126 - val_loss: 0.6014 - val_accuracy: 0.7044\n",
      "Epoch 145/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.5974 - accuracy: 0.7167 - val_loss: 0.6004 - val_accuracy: 0.6995\n",
      "Epoch 146/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.5963 - accuracy: 0.7143 - val_loss: 0.5996 - val_accuracy: 0.7020\n",
      "Epoch 147/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.5955 - accuracy: 0.7200 - val_loss: 0.5988 - val_accuracy: 0.7044\n",
      "Epoch 148/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.5943 - accuracy: 0.7167 - val_loss: 0.5976 - val_accuracy: 0.7044\n",
      "Epoch 149/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.5931 - accuracy: 0.7135 - val_loss: 0.5966 - val_accuracy: 0.7020\n",
      "Epoch 150/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.5922 - accuracy: 0.7102 - val_loss: 0.5956 - val_accuracy: 0.7069\n",
      "Epoch 151/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.5913 - accuracy: 0.7126 - val_loss: 0.5947 - val_accuracy: 0.7044\n",
      "Epoch 152/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.5900 - accuracy: 0.7126 - val_loss: 0.5938 - val_accuracy: 0.7069\n",
      "Epoch 153/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.5889 - accuracy: 0.7135 - val_loss: 0.5929 - val_accuracy: 0.7069\n",
      "Epoch 154/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.5882 - accuracy: 0.7151 - val_loss: 0.5922 - val_accuracy: 0.7069\n",
      "Epoch 155/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.5867 - accuracy: 0.7151 - val_loss: 0.5911 - val_accuracy: 0.7069\n",
      "Epoch 156/750\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 0.5857 - accuracy: 0.7126 - val_loss: 0.5900 - val_accuracy: 0.7094\n",
      "Epoch 157/750\n",
      "5/5 [==============================] - 1s 262ms/step - loss: 0.5846 - accuracy: 0.7151 - val_loss: 0.5890 - val_accuracy: 0.7118\n",
      "Epoch 158/750\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.5835 - accuracy: 0.7159 - val_loss: 0.5881 - val_accuracy: 0.7118\n",
      "Epoch 159/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.5824 - accuracy: 0.7135 - val_loss: 0.5872 - val_accuracy: 0.7094\n",
      "Epoch 160/750\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.5813 - accuracy: 0.7151 - val_loss: 0.5864 - val_accuracy: 0.7118\n",
      "Epoch 161/750\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.5803 - accuracy: 0.7176 - val_loss: 0.5856 - val_accuracy: 0.7167\n",
      "Epoch 162/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.5792 - accuracy: 0.7192 - val_loss: 0.5844 - val_accuracy: 0.7143\n",
      "Epoch 163/750\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.5780 - accuracy: 0.7159 - val_loss: 0.5833 - val_accuracy: 0.7192\n",
      "Epoch 164/750\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.5769 - accuracy: 0.7176 - val_loss: 0.5824 - val_accuracy: 0.7192\n",
      "Epoch 165/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.5758 - accuracy: 0.7200 - val_loss: 0.5818 - val_accuracy: 0.7143\n",
      "Epoch 166/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.5747 - accuracy: 0.7184 - val_loss: 0.5807 - val_accuracy: 0.7143\n",
      "Epoch 167/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.5735 - accuracy: 0.7192 - val_loss: 0.5799 - val_accuracy: 0.7167\n",
      "Epoch 168/750\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 0.5724 - accuracy: 0.7200 - val_loss: 0.5788 - val_accuracy: 0.7217\n",
      "Epoch 169/750\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.5714 - accuracy: 0.7225 - val_loss: 0.5776 - val_accuracy: 0.7167\n",
      "Epoch 170/750\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.5702 - accuracy: 0.7233 - val_loss: 0.5770 - val_accuracy: 0.7241\n",
      "Epoch 171/750\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.5691 - accuracy: 0.7209 - val_loss: 0.5760 - val_accuracy: 0.7241\n",
      "Epoch 172/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.5679 - accuracy: 0.7225 - val_loss: 0.5753 - val_accuracy: 0.7192\n",
      "Epoch 173/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 256ms/step - loss: 0.5667 - accuracy: 0.7241 - val_loss: 0.5741 - val_accuracy: 0.7266\n",
      "Epoch 174/750\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.5657 - accuracy: 0.7225 - val_loss: 0.5734 - val_accuracy: 0.7266\n",
      "Epoch 175/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.5645 - accuracy: 0.7217 - val_loss: 0.5723 - val_accuracy: 0.7266\n",
      "Epoch 176/750\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.5632 - accuracy: 0.7217 - val_loss: 0.5712 - val_accuracy: 0.7192\n",
      "Epoch 177/750\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.5621 - accuracy: 0.7250 - val_loss: 0.5703 - val_accuracy: 0.7217\n",
      "Epoch 178/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.5609 - accuracy: 0.7233 - val_loss: 0.5695 - val_accuracy: 0.7241\n",
      "Epoch 179/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.5599 - accuracy: 0.7266 - val_loss: 0.5689 - val_accuracy: 0.7266\n",
      "Epoch 180/750\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 0.5593 - accuracy: 0.7299 - val_loss: 0.5676 - val_accuracy: 0.7291\n",
      "Epoch 181/750\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.5573 - accuracy: 0.7291 - val_loss: 0.5670 - val_accuracy: 0.7266\n",
      "Epoch 182/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.5563 - accuracy: 0.7291 - val_loss: 0.5663 - val_accuracy: 0.7266\n",
      "Epoch 183/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.5551 - accuracy: 0.7299 - val_loss: 0.5652 - val_accuracy: 0.7291\n",
      "Epoch 184/750\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.5539 - accuracy: 0.7299 - val_loss: 0.5641 - val_accuracy: 0.7340\n",
      "Epoch 185/750\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.5529 - accuracy: 0.7323 - val_loss: 0.5632 - val_accuracy: 0.7340\n",
      "Epoch 186/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.5516 - accuracy: 0.7332 - val_loss: 0.5622 - val_accuracy: 0.7340\n",
      "Epoch 187/750\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.5508 - accuracy: 0.7356 - val_loss: 0.5614 - val_accuracy: 0.7389\n",
      "Epoch 188/750\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.5497 - accuracy: 0.7332 - val_loss: 0.5613 - val_accuracy: 0.7340\n",
      "Epoch 189/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.5483 - accuracy: 0.7332 - val_loss: 0.5599 - val_accuracy: 0.7389\n",
      "Epoch 190/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.5470 - accuracy: 0.7323 - val_loss: 0.5591 - val_accuracy: 0.7389\n",
      "Epoch 191/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.5458 - accuracy: 0.7348 - val_loss: 0.5581 - val_accuracy: 0.7389\n",
      "Epoch 192/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.5447 - accuracy: 0.7373 - val_loss: 0.5572 - val_accuracy: 0.7389\n",
      "Epoch 193/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.5436 - accuracy: 0.7389 - val_loss: 0.5564 - val_accuracy: 0.7389\n",
      "Epoch 194/750\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.5424 - accuracy: 0.7348 - val_loss: 0.5560 - val_accuracy: 0.7414\n",
      "Epoch 195/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.5414 - accuracy: 0.7356 - val_loss: 0.5549 - val_accuracy: 0.7389\n",
      "Epoch 196/750\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.5400 - accuracy: 0.7356 - val_loss: 0.5543 - val_accuracy: 0.7414\n",
      "Epoch 197/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.5390 - accuracy: 0.7348 - val_loss: 0.5536 - val_accuracy: 0.7414\n",
      "Epoch 198/750\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.5377 - accuracy: 0.7348 - val_loss: 0.5526 - val_accuracy: 0.7463\n",
      "Epoch 199/750\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.5372 - accuracy: 0.7406 - val_loss: 0.5515 - val_accuracy: 0.7340\n",
      "Epoch 200/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.5355 - accuracy: 0.7414 - val_loss: 0.5513 - val_accuracy: 0.7438\n",
      "Epoch 201/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.5344 - accuracy: 0.7348 - val_loss: 0.5504 - val_accuracy: 0.7463\n",
      "Epoch 202/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.5331 - accuracy: 0.7406 - val_loss: 0.5494 - val_accuracy: 0.7463\n",
      "Epoch 203/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.5319 - accuracy: 0.7414 - val_loss: 0.5488 - val_accuracy: 0.7463\n",
      "Epoch 204/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.5307 - accuracy: 0.7389 - val_loss: 0.5481 - val_accuracy: 0.7438\n",
      "Epoch 205/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.5296 - accuracy: 0.7365 - val_loss: 0.5474 - val_accuracy: 0.7463\n",
      "Epoch 206/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.5285 - accuracy: 0.7397 - val_loss: 0.5464 - val_accuracy: 0.7438\n",
      "Epoch 207/750\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.5280 - accuracy: 0.7381 - val_loss: 0.5462 - val_accuracy: 0.7488\n",
      "Epoch 208/750\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.5264 - accuracy: 0.7438 - val_loss: 0.5447 - val_accuracy: 0.7315\n",
      "Epoch 209/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.5256 - accuracy: 0.7438 - val_loss: 0.5442 - val_accuracy: 0.7438\n",
      "Epoch 210/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.5239 - accuracy: 0.7447 - val_loss: 0.5437 - val_accuracy: 0.7463\n",
      "Epoch 211/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.5228 - accuracy: 0.7381 - val_loss: 0.5434 - val_accuracy: 0.7488\n",
      "Epoch 212/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.5219 - accuracy: 0.7406 - val_loss: 0.5424 - val_accuracy: 0.7438\n",
      "Epoch 213/750\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.5206 - accuracy: 0.7414 - val_loss: 0.5413 - val_accuracy: 0.7291\n",
      "Epoch 214/750\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.5198 - accuracy: 0.7455 - val_loss: 0.5407 - val_accuracy: 0.7315\n",
      "Epoch 215/750\n",
      "5/5 [==============================] - 1s 260ms/step - loss: 0.5182 - accuracy: 0.7422 - val_loss: 0.5411 - val_accuracy: 0.7488\n",
      "Epoch 216/750\n",
      "5/5 [==============================] - 1s 264ms/step - loss: 0.5174 - accuracy: 0.7422 - val_loss: 0.5402 - val_accuracy: 0.7463\n",
      "Epoch 217/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.5160 - accuracy: 0.7438 - val_loss: 0.5388 - val_accuracy: 0.7315\n",
      "Epoch 218/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.5152 - accuracy: 0.7463 - val_loss: 0.5382 - val_accuracy: 0.7389\n",
      "Epoch 219/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.5140 - accuracy: 0.7488 - val_loss: 0.5374 - val_accuracy: 0.7315\n",
      "Epoch 220/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.5130 - accuracy: 0.7471 - val_loss: 0.5374 - val_accuracy: 0.7389\n",
      "Epoch 221/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.5116 - accuracy: 0.7447 - val_loss: 0.5368 - val_accuracy: 0.7389\n",
      "Epoch 222/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.5110 - accuracy: 0.7512 - val_loss: 0.5357 - val_accuracy: 0.7315\n",
      "Epoch 223/750\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.5099 - accuracy: 0.7463 - val_loss: 0.5359 - val_accuracy: 0.7512\n",
      "Epoch 224/750\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.5088 - accuracy: 0.7455 - val_loss: 0.5352 - val_accuracy: 0.7438\n",
      "Epoch 225/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.5072 - accuracy: 0.7496 - val_loss: 0.5339 - val_accuracy: 0.7340\n",
      "Epoch 226/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.5067 - accuracy: 0.7496 - val_loss: 0.5335 - val_accuracy: 0.7389\n",
      "Epoch 227/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.5051 - accuracy: 0.7488 - val_loss: 0.5334 - val_accuracy: 0.7438\n",
      "Epoch 228/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.5042 - accuracy: 0.7496 - val_loss: 0.5332 - val_accuracy: 0.7463\n",
      "Epoch 229/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.5037 - accuracy: 0.7553 - val_loss: 0.5318 - val_accuracy: 0.7389\n",
      "Epoch 230/750\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.5026 - accuracy: 0.7521 - val_loss: 0.5323 - val_accuracy: 0.7488\n",
      "Epoch 231/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.5011 - accuracy: 0.7529 - val_loss: 0.5310 - val_accuracy: 0.7438\n",
      "Epoch 232/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.4999 - accuracy: 0.7512 - val_loss: 0.5305 - val_accuracy: 0.7438\n",
      "Epoch 233/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.4989 - accuracy: 0.7537 - val_loss: 0.5301 - val_accuracy: 0.7463\n",
      "Epoch 234/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.4978 - accuracy: 0.7570 - val_loss: 0.5305 - val_accuracy: 0.7512\n",
      "Epoch 235/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.4967 - accuracy: 0.7553 - val_loss: 0.5294 - val_accuracy: 0.7512\n",
      "Epoch 236/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.4960 - accuracy: 0.7578 - val_loss: 0.5284 - val_accuracy: 0.7438\n",
      "Epoch 237/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.4947 - accuracy: 0.7562 - val_loss: 0.5285 - val_accuracy: 0.7512\n",
      "Epoch 238/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.4937 - accuracy: 0.7611 - val_loss: 0.5283 - val_accuracy: 0.7512\n",
      "Epoch 239/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.4931 - accuracy: 0.7553 - val_loss: 0.5270 - val_accuracy: 0.7389\n",
      "Epoch 240/750\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.4922 - accuracy: 0.7537 - val_loss: 0.5277 - val_accuracy: 0.7586\n",
      "Epoch 241/750\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.4904 - accuracy: 0.7586 - val_loss: 0.5267 - val_accuracy: 0.7512\n",
      "Epoch 242/750\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.4895 - accuracy: 0.7578 - val_loss: 0.5257 - val_accuracy: 0.7414\n",
      "Epoch 243/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.4885 - accuracy: 0.7594 - val_loss: 0.5259 - val_accuracy: 0.7537\n",
      "Epoch 244/750\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.4883 - accuracy: 0.7611 - val_loss: 0.5266 - val_accuracy: 0.7537\n",
      "Epoch 245/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.4864 - accuracy: 0.7603 - val_loss: 0.5246 - val_accuracy: 0.7414\n",
      "Epoch 246/750\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.4856 - accuracy: 0.7619 - val_loss: 0.5244 - val_accuracy: 0.7537\n",
      "Epoch 247/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.4842 - accuracy: 0.7619 - val_loss: 0.5246 - val_accuracy: 0.7586\n",
      "Epoch 248/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.4834 - accuracy: 0.7652 - val_loss: 0.5240 - val_accuracy: 0.7562\n",
      "Epoch 249/750\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.4826 - accuracy: 0.7619 - val_loss: 0.5232 - val_accuracy: 0.7488\n",
      "Epoch 250/750\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.4811 - accuracy: 0.7611 - val_loss: 0.5236 - val_accuracy: 0.7611\n",
      "Epoch 251/750\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.4810 - accuracy: 0.7652 - val_loss: 0.5243 - val_accuracy: 0.7611\n",
      "Epoch 252/750\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.4795 - accuracy: 0.7668 - val_loss: 0.5221 - val_accuracy: 0.7365\n",
      "Epoch 253/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.4788 - accuracy: 0.7677 - val_loss: 0.5222 - val_accuracy: 0.7512\n",
      "Epoch 254/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.4777 - accuracy: 0.7677 - val_loss: 0.5231 - val_accuracy: 0.7611\n",
      "Epoch 255/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.4783 - accuracy: 0.7619 - val_loss: 0.5212 - val_accuracy: 0.7414\n",
      "Epoch 256/750\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.4754 - accuracy: 0.7652 - val_loss: 0.5225 - val_accuracy: 0.7635\n",
      "Epoch 257/750\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.4749 - accuracy: 0.7685 - val_loss: 0.5211 - val_accuracy: 0.7512\n",
      "Epoch 258/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.4736 - accuracy: 0.7668 - val_loss: 0.5204 - val_accuracy: 0.7414\n",
      "Epoch 259/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.4729 - accuracy: 0.7677 - val_loss: 0.5210 - val_accuracy: 0.7611\n",
      "Epoch 260/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.4715 - accuracy: 0.7685 - val_loss: 0.5200 - val_accuracy: 0.7488\n",
      "Epoch 261/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.4708 - accuracy: 0.7734 - val_loss: 0.5197 - val_accuracy: 0.7438\n",
      "Epoch 262/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.4696 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7438\n",
      "Epoch 263/750\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.4687 - accuracy: 0.7718 - val_loss: 0.5194 - val_accuracy: 0.7488\n",
      "Epoch 264/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.4692 - accuracy: 0.7726 - val_loss: 0.5187 - val_accuracy: 0.7389\n",
      "Epoch 265/750\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.4663 - accuracy: 0.7734 - val_loss: 0.5211 - val_accuracy: 0.7611\n",
      "Epoch 266/750\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.4670 - accuracy: 0.7718 - val_loss: 0.5187 - val_accuracy: 0.7463\n",
      "Epoch 267/750\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.4669 - accuracy: 0.7767 - val_loss: 0.5178 - val_accuracy: 0.7414\n",
      "Epoch 268/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.4647 - accuracy: 0.7750 - val_loss: 0.5210 - val_accuracy: 0.7611\n",
      "Epoch 269/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.4640 - accuracy: 0.7759 - val_loss: 0.5179 - val_accuracy: 0.7438\n",
      "Epoch 270/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.4630 - accuracy: 0.7791 - val_loss: 0.5172 - val_accuracy: 0.7389\n",
      "Epoch 271/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.4615 - accuracy: 0.7800 - val_loss: 0.5192 - val_accuracy: 0.7537\n",
      "Epoch 272/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.4610 - accuracy: 0.7734 - val_loss: 0.5176 - val_accuracy: 0.7438\n",
      "Epoch 273/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.4595 - accuracy: 0.7783 - val_loss: 0.5167 - val_accuracy: 0.7463\n",
      "Epoch 274/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.4591 - accuracy: 0.7759 - val_loss: 0.5172 - val_accuracy: 0.7463\n",
      "Epoch 275/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.4600 - accuracy: 0.7808 - val_loss: 0.5165 - val_accuracy: 0.7438\n",
      "Epoch 276/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.4589 - accuracy: 0.7767 - val_loss: 0.5203 - val_accuracy: 0.7537\n",
      "Epoch 277/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.4556 - accuracy: 0.7849 - val_loss: 0.5159 - val_accuracy: 0.7438\n",
      "Epoch 278/750\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.4560 - accuracy: 0.7849 - val_loss: 0.5157 - val_accuracy: 0.7438\n",
      "Epoch 279/750\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.4546 - accuracy: 0.7816 - val_loss: 0.5182 - val_accuracy: 0.7488\n",
      "Epoch 280/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.4537 - accuracy: 0.7849 - val_loss: 0.5155 - val_accuracy: 0.7438\n",
      "Epoch 281/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.4527 - accuracy: 0.7833 - val_loss: 0.5154 - val_accuracy: 0.7438\n",
      "Epoch 282/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.4513 - accuracy: 0.7841 - val_loss: 0.5175 - val_accuracy: 0.7512\n",
      "Epoch 283/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.4511 - accuracy: 0.7849 - val_loss: 0.5151 - val_accuracy: 0.7438\n",
      "Epoch 284/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.4506 - accuracy: 0.7841 - val_loss: 0.5151 - val_accuracy: 0.7463\n",
      "Epoch 285/750\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.4487 - accuracy: 0.7849 - val_loss: 0.5157 - val_accuracy: 0.7438\n",
      "Epoch 286/750\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.4483 - accuracy: 0.7906 - val_loss: 0.5149 - val_accuracy: 0.7488\n",
      "Epoch 287/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 241ms/step - loss: 0.4477 - accuracy: 0.7841 - val_loss: 0.5144 - val_accuracy: 0.7438\n",
      "Epoch 288/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.4471 - accuracy: 0.7874 - val_loss: 0.5145 - val_accuracy: 0.7463\n",
      "Epoch 289/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.4452 - accuracy: 0.7882 - val_loss: 0.5147 - val_accuracy: 0.7463\n",
      "Epoch 290/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.4449 - accuracy: 0.7898 - val_loss: 0.5141 - val_accuracy: 0.7438\n",
      "Epoch 291/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.4437 - accuracy: 0.7865 - val_loss: 0.5151 - val_accuracy: 0.7463\n",
      "Epoch 292/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.4439 - accuracy: 0.7923 - val_loss: 0.5139 - val_accuracy: 0.7488\n",
      "Epoch 293/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.4454 - accuracy: 0.7931 - val_loss: 0.5135 - val_accuracy: 0.7537\n",
      "Epoch 294/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.4415 - accuracy: 0.7964 - val_loss: 0.5175 - val_accuracy: 0.7488\n",
      "Epoch 295/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.4420 - accuracy: 0.7923 - val_loss: 0.5132 - val_accuracy: 0.7463\n",
      "Epoch 296/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.5139 - val_accuracy: 0.7488\n",
      "Epoch 297/750\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.4386 - accuracy: 0.7915 - val_loss: 0.5133 - val_accuracy: 0.7512\n",
      "Epoch 298/750\n",
      "5/5 [==============================] - 1s 258ms/step - loss: 0.4383 - accuracy: 0.7939 - val_loss: 0.5137 - val_accuracy: 0.7488\n",
      "Epoch 299/750\n",
      "5/5 [==============================] - 1s 265ms/step - loss: 0.4367 - accuracy: 0.7923 - val_loss: 0.5127 - val_accuracy: 0.7488\n",
      "Epoch 300/750\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.4367 - accuracy: 0.7947 - val_loss: 0.5132 - val_accuracy: 0.7512\n",
      "Epoch 301/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.4394 - accuracy: 0.7939 - val_loss: 0.5156 - val_accuracy: 0.7488\n",
      "Epoch 302/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.4348 - accuracy: 0.7964 - val_loss: 0.5133 - val_accuracy: 0.7512\n",
      "Epoch 303/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.4348 - accuracy: 0.7989 - val_loss: 0.5138 - val_accuracy: 0.7512\n",
      "Epoch 304/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.4344 - accuracy: 0.7964 - val_loss: 0.5142 - val_accuracy: 0.7537\n",
      "Epoch 305/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.4321 - accuracy: 0.7972 - val_loss: 0.5121 - val_accuracy: 0.7512\n",
      "Epoch 306/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.4328 - accuracy: 0.7947 - val_loss: 0.5131 - val_accuracy: 0.7512\n",
      "Epoch 307/750\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.4319 - accuracy: 0.7956 - val_loss: 0.5121 - val_accuracy: 0.7537\n",
      "Epoch 308/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.4296 - accuracy: 0.8013 - val_loss: 0.5138 - val_accuracy: 0.7562\n",
      "Epoch 309/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.4297 - accuracy: 0.7972 - val_loss: 0.5134 - val_accuracy: 0.7537\n",
      "Epoch 310/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.4279 - accuracy: 0.8005 - val_loss: 0.5119 - val_accuracy: 0.7512\n",
      "Epoch 311/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.4278 - accuracy: 0.8005 - val_loss: 0.5132 - val_accuracy: 0.7488\n",
      "Epoch 312/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.4273 - accuracy: 0.7980 - val_loss: 0.5124 - val_accuracy: 0.7512\n",
      "Epoch 313/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.4257 - accuracy: 0.8021 - val_loss: 0.5116 - val_accuracy: 0.7611\n",
      "Epoch 314/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.4252 - accuracy: 0.7989 - val_loss: 0.5129 - val_accuracy: 0.7537\n",
      "Epoch 315/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.4247 - accuracy: 0.8005 - val_loss: 0.5125 - val_accuracy: 0.7488\n",
      "Epoch 316/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.4269 - accuracy: 0.8030 - val_loss: 0.5113 - val_accuracy: 0.7635\n",
      "Epoch 317/750\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.4264 - accuracy: 0.8021 - val_loss: 0.5158 - val_accuracy: 0.7611\n",
      "Epoch 318/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.4226 - accuracy: 0.8030 - val_loss: 0.5118 - val_accuracy: 0.7562\n",
      "Epoch 319/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.4246 - accuracy: 0.8054 - val_loss: 0.5136 - val_accuracy: 0.7586\n",
      "Epoch 320/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.4223 - accuracy: 0.8038 - val_loss: 0.5109 - val_accuracy: 0.7635\n",
      "Epoch 321/750\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.4204 - accuracy: 0.8054 - val_loss: 0.5126 - val_accuracy: 0.7562\n",
      "Epoch 322/750\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.4194 - accuracy: 0.8046 - val_loss: 0.5109 - val_accuracy: 0.7611\n",
      "Epoch 323/750\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.4199 - accuracy: 0.8071 - val_loss: 0.5109 - val_accuracy: 0.7611\n",
      "Epoch 324/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.4211 - accuracy: 0.8054 - val_loss: 0.5129 - val_accuracy: 0.7586\n",
      "Epoch 325/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.4171 - accuracy: 0.8103 - val_loss: 0.5112 - val_accuracy: 0.7586\n",
      "Epoch 326/750\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.4165 - accuracy: 0.8079 - val_loss: 0.5134 - val_accuracy: 0.7660\n",
      "Epoch 327/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.4159 - accuracy: 0.8062 - val_loss: 0.5107 - val_accuracy: 0.7611\n",
      "Epoch 328/750\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.4150 - accuracy: 0.8095 - val_loss: 0.5105 - val_accuracy: 0.7611\n",
      "Epoch 329/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.4145 - accuracy: 0.8103 - val_loss: 0.5126 - val_accuracy: 0.7635\n",
      "Epoch 330/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.4122 - accuracy: 0.8095 - val_loss: 0.5106 - val_accuracy: 0.7611\n",
      "Epoch 331/750\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.4135 - accuracy: 0.8095 - val_loss: 0.5112 - val_accuracy: 0.7635\n",
      "Epoch 332/750\n",
      "5/5 [==============================] - 1s 280ms/step - loss: 0.4121 - accuracy: 0.8128 - val_loss: 0.5122 - val_accuracy: 0.7709\n",
      "Epoch 333/750\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.4118 - accuracy: 0.8087 - val_loss: 0.5110 - val_accuracy: 0.7635\n",
      "Epoch 334/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.4119 - accuracy: 0.8103 - val_loss: 0.5104 - val_accuracy: 0.7586\n",
      "Epoch 335/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.4122 - accuracy: 0.8062 - val_loss: 0.5130 - val_accuracy: 0.7709\n",
      "Epoch 336/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.4073 - accuracy: 0.8136 - val_loss: 0.5107 - val_accuracy: 0.7611\n",
      "Epoch 337/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.4104 - accuracy: 0.8136 - val_loss: 0.5115 - val_accuracy: 0.7709\n",
      "Epoch 338/750\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.4089 - accuracy: 0.8120 - val_loss: 0.5120 - val_accuracy: 0.7734\n",
      "Epoch 339/750\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.4055 - accuracy: 0.8144 - val_loss: 0.5103 - val_accuracy: 0.7611\n",
      "Epoch 340/750\n",
      "5/5 [==============================] - 1s 257ms/step - loss: 0.4078 - accuracy: 0.8186 - val_loss: 0.5130 - val_accuracy: 0.7783\n",
      "Epoch 341/750\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 0.4073 - accuracy: 0.8136 - val_loss: 0.5098 - val_accuracy: 0.7635\n",
      "Epoch 342/750\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.4095 - accuracy: 0.8136 - val_loss: 0.5100 - val_accuracy: 0.7660\n",
      "Epoch 343/750\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.4043 - accuracy: 0.8087 - val_loss: 0.5115 - val_accuracy: 0.7783\n",
      "Epoch 344/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.4034 - accuracy: 0.8103 - val_loss: 0.5095 - val_accuracy: 0.7611\n",
      "Epoch 345/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.4017 - accuracy: 0.8128 - val_loss: 0.5117 - val_accuracy: 0.7783\n",
      "Epoch 346/750\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.4047 - accuracy: 0.8112 - val_loss: 0.5098 - val_accuracy: 0.7685\n",
      "Epoch 347/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.4020 - accuracy: 0.8177 - val_loss: 0.5094 - val_accuracy: 0.7586\n",
      "Epoch 348/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.4003 - accuracy: 0.8120 - val_loss: 0.5114 - val_accuracy: 0.7783\n",
      "Epoch 349/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3992 - accuracy: 0.8112 - val_loss: 0.5095 - val_accuracy: 0.7611\n",
      "Epoch 350/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3987 - accuracy: 0.8128 - val_loss: 0.5102 - val_accuracy: 0.7734\n",
      "Epoch 351/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.3979 - accuracy: 0.8136 - val_loss: 0.5108 - val_accuracy: 0.7759\n",
      "Epoch 352/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3981 - accuracy: 0.8144 - val_loss: 0.5094 - val_accuracy: 0.7537\n",
      "Epoch 353/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3988 - accuracy: 0.8202 - val_loss: 0.5108 - val_accuracy: 0.7783\n",
      "Epoch 354/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.3990 - accuracy: 0.8153 - val_loss: 0.5094 - val_accuracy: 0.7709\n",
      "Epoch 355/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.3985 - accuracy: 0.8210 - val_loss: 0.5096 - val_accuracy: 0.7734\n",
      "Epoch 356/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.3977 - accuracy: 0.8112 - val_loss: 0.5119 - val_accuracy: 0.7759\n",
      "Epoch 357/750\n",
      "5/5 [==============================] - 1s 263ms/step - loss: 0.3953 - accuracy: 0.8251 - val_loss: 0.5093 - val_accuracy: 0.7537\n",
      "Epoch 358/750\n",
      "5/5 [==============================] - 1s 265ms/step - loss: 0.3936 - accuracy: 0.8177 - val_loss: 0.5139 - val_accuracy: 0.7783\n",
      "Epoch 359/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.3922 - accuracy: 0.8202 - val_loss: 0.5090 - val_accuracy: 0.7562\n",
      "Epoch 360/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.3928 - accuracy: 0.8243 - val_loss: 0.5102 - val_accuracy: 0.7783\n",
      "Epoch 361/750\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.3932 - accuracy: 0.8177 - val_loss: 0.5091 - val_accuracy: 0.7734\n",
      "Epoch 362/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3900 - accuracy: 0.8235 - val_loss: 0.5087 - val_accuracy: 0.7586\n",
      "Epoch 363/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3917 - accuracy: 0.8194 - val_loss: 0.5099 - val_accuracy: 0.7783\n",
      "Epoch 364/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.3890 - accuracy: 0.8194 - val_loss: 0.5085 - val_accuracy: 0.7611\n",
      "Epoch 365/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3884 - accuracy: 0.8210 - val_loss: 0.5096 - val_accuracy: 0.7783\n",
      "Epoch 366/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.3878 - accuracy: 0.8218 - val_loss: 0.5086 - val_accuracy: 0.7734\n",
      "Epoch 367/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3868 - accuracy: 0.8218 - val_loss: 0.5090 - val_accuracy: 0.7759\n",
      "Epoch 368/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.3869 - accuracy: 0.8169 - val_loss: 0.5084 - val_accuracy: 0.7685\n",
      "Epoch 369/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.3859 - accuracy: 0.8251 - val_loss: 0.5079 - val_accuracy: 0.7635\n",
      "Epoch 370/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3868 - accuracy: 0.8235 - val_loss: 0.5098 - val_accuracy: 0.7783\n",
      "Epoch 371/750\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.3861 - accuracy: 0.8227 - val_loss: 0.5082 - val_accuracy: 0.7759\n",
      "Epoch 372/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.3855 - accuracy: 0.8284 - val_loss: 0.5086 - val_accuracy: 0.7783\n",
      "Epoch 373/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.3852 - accuracy: 0.8243 - val_loss: 0.5086 - val_accuracy: 0.7783\n",
      "Epoch 374/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3826 - accuracy: 0.8227 - val_loss: 0.5082 - val_accuracy: 0.7734\n",
      "Epoch 375/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.3838 - accuracy: 0.8284 - val_loss: 0.5085 - val_accuracy: 0.7783\n",
      "Epoch 376/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.3817 - accuracy: 0.8276 - val_loss: 0.5089 - val_accuracy: 0.7783\n",
      "Epoch 377/750\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.3806 - accuracy: 0.8251 - val_loss: 0.5077 - val_accuracy: 0.7685\n",
      "Epoch 378/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3812 - accuracy: 0.8259 - val_loss: 0.5116 - val_accuracy: 0.7759\n",
      "Epoch 379/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3809 - accuracy: 0.8210 - val_loss: 0.5078 - val_accuracy: 0.7685\n",
      "Epoch 380/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.3799 - accuracy: 0.8259 - val_loss: 0.5118 - val_accuracy: 0.7759\n",
      "Epoch 381/750\n",
      "5/5 [==============================] - 1s 264ms/step - loss: 0.3792 - accuracy: 0.8259 - val_loss: 0.5076 - val_accuracy: 0.7611\n",
      "Epoch 382/750\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.3777 - accuracy: 0.8317 - val_loss: 0.5113 - val_accuracy: 0.7734\n",
      "Epoch 383/750\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.3774 - accuracy: 0.8243 - val_loss: 0.5080 - val_accuracy: 0.7660\n",
      "Epoch 384/750\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.3766 - accuracy: 0.8309 - val_loss: 0.5107 - val_accuracy: 0.7759\n",
      "Epoch 385/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.3756 - accuracy: 0.8276 - val_loss: 0.5075 - val_accuracy: 0.7635\n",
      "Epoch 386/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3777 - accuracy: 0.8350 - val_loss: 0.5113 - val_accuracy: 0.7759\n",
      "Epoch 387/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.3825 - accuracy: 0.8268 - val_loss: 0.5075 - val_accuracy: 0.7635\n",
      "Epoch 388/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3802 - accuracy: 0.8317 - val_loss: 0.5080 - val_accuracy: 0.7734\n",
      "Epoch 389/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3769 - accuracy: 0.8284 - val_loss: 0.5072 - val_accuracy: 0.7635\n",
      "Epoch 390/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3733 - accuracy: 0.8325 - val_loss: 0.5088 - val_accuracy: 0.7734\n",
      "Epoch 391/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3717 - accuracy: 0.8333 - val_loss: 0.5077 - val_accuracy: 0.7734\n",
      "Epoch 392/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3705 - accuracy: 0.8276 - val_loss: 0.5072 - val_accuracy: 0.7635\n",
      "Epoch 393/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3761 - accuracy: 0.8317 - val_loss: 0.5072 - val_accuracy: 0.7635\n",
      "Epoch 394/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3719 - accuracy: 0.8292 - val_loss: 0.5082 - val_accuracy: 0.7734\n",
      "Epoch 395/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3715 - accuracy: 0.8350 - val_loss: 0.5071 - val_accuracy: 0.7635\n",
      "Epoch 396/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.3716 - accuracy: 0.8383 - val_loss: 0.5078 - val_accuracy: 0.7709\n",
      "Epoch 397/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3724 - accuracy: 0.8342 - val_loss: 0.5068 - val_accuracy: 0.7635\n",
      "Epoch 398/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3712 - accuracy: 0.8432 - val_loss: 0.5067 - val_accuracy: 0.7635\n",
      "Epoch 399/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3688 - accuracy: 0.8284 - val_loss: 0.5101 - val_accuracy: 0.7783\n",
      "Epoch 400/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.3670 - accuracy: 0.8350 - val_loss: 0.5066 - val_accuracy: 0.7685\n",
      "Epoch 401/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 239ms/step - loss: 0.3645 - accuracy: 0.8342 - val_loss: 0.5102 - val_accuracy: 0.7783\n",
      "Epoch 402/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.3644 - accuracy: 0.8342 - val_loss: 0.5068 - val_accuracy: 0.7685\n",
      "Epoch 403/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3666 - accuracy: 0.8366 - val_loss: 0.5087 - val_accuracy: 0.7734\n",
      "Epoch 404/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3714 - accuracy: 0.8358 - val_loss: 0.5078 - val_accuracy: 0.7709\n",
      "Epoch 405/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3796 - accuracy: 0.8292 - val_loss: 0.5066 - val_accuracy: 0.7685\n",
      "Epoch 406/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3667 - accuracy: 0.8383 - val_loss: 0.5075 - val_accuracy: 0.7734\n",
      "Epoch 407/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3615 - accuracy: 0.8383 - val_loss: 0.5073 - val_accuracy: 0.7685\n",
      "Epoch 408/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3625 - accuracy: 0.8383 - val_loss: 0.5069 - val_accuracy: 0.7685\n",
      "Epoch 409/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3620 - accuracy: 0.8415 - val_loss: 0.5069 - val_accuracy: 0.7709\n",
      "Epoch 410/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.3592 - accuracy: 0.8399 - val_loss: 0.5104 - val_accuracy: 0.7759\n",
      "Epoch 411/750\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.3593 - accuracy: 0.8366 - val_loss: 0.5068 - val_accuracy: 0.7759\n",
      "Epoch 412/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3584 - accuracy: 0.8366 - val_loss: 0.5111 - val_accuracy: 0.7759\n",
      "Epoch 413/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3599 - accuracy: 0.8358 - val_loss: 0.5066 - val_accuracy: 0.7734\n",
      "Epoch 414/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3578 - accuracy: 0.8440 - val_loss: 0.5069 - val_accuracy: 0.7759\n",
      "Epoch 415/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3571 - accuracy: 0.8407 - val_loss: 0.5063 - val_accuracy: 0.7759\n",
      "Epoch 416/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3572 - accuracy: 0.8374 - val_loss: 0.5087 - val_accuracy: 0.7734\n",
      "Epoch 417/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3585 - accuracy: 0.8374 - val_loss: 0.5065 - val_accuracy: 0.7783\n",
      "Epoch 418/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3563 - accuracy: 0.8366 - val_loss: 0.5064 - val_accuracy: 0.7759\n",
      "Epoch 419/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.3554 - accuracy: 0.8432 - val_loss: 0.5068 - val_accuracy: 0.7783\n",
      "Epoch 420/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.3536 - accuracy: 0.8399 - val_loss: 0.5070 - val_accuracy: 0.7783\n",
      "Epoch 421/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.3533 - accuracy: 0.8424 - val_loss: 0.5065 - val_accuracy: 0.7759\n",
      "Epoch 422/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3525 - accuracy: 0.8415 - val_loss: 0.5103 - val_accuracy: 0.7734\n",
      "Epoch 423/750\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.3531 - accuracy: 0.8424 - val_loss: 0.5066 - val_accuracy: 0.7808\n",
      "Epoch 424/750\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.3526 - accuracy: 0.8448 - val_loss: 0.5065 - val_accuracy: 0.7734\n",
      "Epoch 425/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.3504 - accuracy: 0.8432 - val_loss: 0.5087 - val_accuracy: 0.7759\n",
      "Epoch 426/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3504 - accuracy: 0.8432 - val_loss: 0.5065 - val_accuracy: 0.7808\n",
      "Epoch 427/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.3500 - accuracy: 0.8448 - val_loss: 0.5067 - val_accuracy: 0.7783\n",
      "Epoch 428/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.3486 - accuracy: 0.8424 - val_loss: 0.5080 - val_accuracy: 0.7783\n",
      "Epoch 429/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3482 - accuracy: 0.8424 - val_loss: 0.5079 - val_accuracy: 0.7783\n",
      "Epoch 430/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3505 - accuracy: 0.8415 - val_loss: 0.5085 - val_accuracy: 0.7808\n",
      "Epoch 431/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3511 - accuracy: 0.8432 - val_loss: 0.5143 - val_accuracy: 0.7734\n",
      "Epoch 432/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3516 - accuracy: 0.8399 - val_loss: 0.5067 - val_accuracy: 0.7759\n",
      "Epoch 433/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3486 - accuracy: 0.8383 - val_loss: 0.5068 - val_accuracy: 0.7808\n",
      "Epoch 434/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.3504 - accuracy: 0.8432 - val_loss: 0.5125 - val_accuracy: 0.7709\n",
      "Epoch 435/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3521 - accuracy: 0.8415 - val_loss: 0.5163 - val_accuracy: 0.7660\n",
      "Epoch 436/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3579 - accuracy: 0.8465 - val_loss: 0.5283 - val_accuracy: 0.7709\n",
      "Epoch 437/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.3507 - accuracy: 0.8547 - val_loss: 0.5094 - val_accuracy: 0.7759\n",
      "Epoch 438/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3496 - accuracy: 0.8424 - val_loss: 0.5074 - val_accuracy: 0.7783\n",
      "Epoch 439/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3477 - accuracy: 0.8555 - val_loss: 0.5122 - val_accuracy: 0.7709\n",
      "Epoch 440/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3480 - accuracy: 0.8440 - val_loss: 0.5062 - val_accuracy: 0.7808\n",
      "Epoch 441/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3416 - accuracy: 0.8522 - val_loss: 0.5118 - val_accuracy: 0.7734\n",
      "Epoch 442/750\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.3422 - accuracy: 0.8440 - val_loss: 0.5069 - val_accuracy: 0.7833\n",
      "Epoch 443/750\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.3442 - accuracy: 0.8547 - val_loss: 0.5172 - val_accuracy: 0.7685\n",
      "Epoch 444/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.3448 - accuracy: 0.8506 - val_loss: 0.5075 - val_accuracy: 0.7833\n",
      "Epoch 445/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3445 - accuracy: 0.8440 - val_loss: 0.5076 - val_accuracy: 0.7759\n",
      "Epoch 446/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3393 - accuracy: 0.8547 - val_loss: 0.5072 - val_accuracy: 0.7759\n",
      "Epoch 447/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3398 - accuracy: 0.8498 - val_loss: 0.5079 - val_accuracy: 0.7759\n",
      "Epoch 448/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.3456 - accuracy: 0.8415 - val_loss: 0.5132 - val_accuracy: 0.7685\n",
      "Epoch 449/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3421 - accuracy: 0.8506 - val_loss: 0.5225 - val_accuracy: 0.7709\n",
      "Epoch 450/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3420 - accuracy: 0.8506 - val_loss: 0.5067 - val_accuracy: 0.7808\n",
      "Epoch 451/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3362 - accuracy: 0.8489 - val_loss: 0.5083 - val_accuracy: 0.7759\n",
      "Epoch 452/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3370 - accuracy: 0.8555 - val_loss: 0.5105 - val_accuracy: 0.7759\n",
      "Epoch 453/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3346 - accuracy: 0.8547 - val_loss: 0.5073 - val_accuracy: 0.7783\n",
      "Epoch 454/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3352 - accuracy: 0.8539 - val_loss: 0.5201 - val_accuracy: 0.7685\n",
      "Epoch 455/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3369 - accuracy: 0.8530 - val_loss: 0.5120 - val_accuracy: 0.7759\n",
      "Epoch 456/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3360 - accuracy: 0.8555 - val_loss: 0.5125 - val_accuracy: 0.7734\n",
      "Epoch 457/750\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.3340 - accuracy: 0.8456 - val_loss: 0.5091 - val_accuracy: 0.7808\n",
      "Epoch 458/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3333 - accuracy: 0.8555 - val_loss: 0.5155 - val_accuracy: 0.7734\n",
      "Epoch 459/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3358 - accuracy: 0.8555 - val_loss: 0.5068 - val_accuracy: 0.7808\n",
      "Epoch 460/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3337 - accuracy: 0.8489 - val_loss: 0.5072 - val_accuracy: 0.7783\n",
      "Epoch 461/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3323 - accuracy: 0.8588 - val_loss: 0.5079 - val_accuracy: 0.7783\n",
      "Epoch 462/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3298 - accuracy: 0.8563 - val_loss: 0.5083 - val_accuracy: 0.7783\n",
      "Epoch 463/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3327 - accuracy: 0.8547 - val_loss: 0.5091 - val_accuracy: 0.7759\n",
      "Epoch 464/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3350 - accuracy: 0.8621 - val_loss: 0.5180 - val_accuracy: 0.7734\n",
      "Epoch 465/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3382 - accuracy: 0.8514 - val_loss: 0.5153 - val_accuracy: 0.7709\n",
      "Epoch 466/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3331 - accuracy: 0.8547 - val_loss: 0.5139 - val_accuracy: 0.7734\n",
      "Epoch 467/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3342 - accuracy: 0.8539 - val_loss: 0.5096 - val_accuracy: 0.7734\n",
      "Epoch 468/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3327 - accuracy: 0.8481 - val_loss: 0.5136 - val_accuracy: 0.7709\n",
      "Epoch 469/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3392 - accuracy: 0.8498 - val_loss: 0.5243 - val_accuracy: 0.7734\n",
      "Epoch 470/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3348 - accuracy: 0.8555 - val_loss: 0.5073 - val_accuracy: 0.7808\n",
      "Epoch 471/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3284 - accuracy: 0.8604 - val_loss: 0.5072 - val_accuracy: 0.7783\n",
      "Epoch 472/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3372 - accuracy: 0.8473 - val_loss: 0.5153 - val_accuracy: 0.7783\n",
      "Epoch 473/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3244 - accuracy: 0.8596 - val_loss: 0.5079 - val_accuracy: 0.7759\n",
      "Epoch 474/750\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.3234 - accuracy: 0.8621 - val_loss: 0.5122 - val_accuracy: 0.7709\n",
      "Epoch 475/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3241 - accuracy: 0.8621 - val_loss: 0.5086 - val_accuracy: 0.7783\n",
      "Epoch 476/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3235 - accuracy: 0.8580 - val_loss: 0.5083 - val_accuracy: 0.7759\n",
      "Epoch 477/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3234 - accuracy: 0.8637 - val_loss: 0.5107 - val_accuracy: 0.7709\n",
      "Epoch 478/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.3218 - accuracy: 0.8621 - val_loss: 0.5096 - val_accuracy: 0.7759\n",
      "Epoch 479/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3241 - accuracy: 0.8588 - val_loss: 0.5109 - val_accuracy: 0.7734\n",
      "Epoch 480/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.3256 - accuracy: 0.8612 - val_loss: 0.5204 - val_accuracy: 0.7759\n",
      "Epoch 481/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3238 - accuracy: 0.8678 - val_loss: 0.5096 - val_accuracy: 0.7734\n",
      "Epoch 482/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.3215 - accuracy: 0.8588 - val_loss: 0.5125 - val_accuracy: 0.7734\n",
      "Epoch 483/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3203 - accuracy: 0.8637 - val_loss: 0.5108 - val_accuracy: 0.7759\n",
      "Epoch 484/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3198 - accuracy: 0.8596 - val_loss: 0.5110 - val_accuracy: 0.7759\n",
      "Epoch 485/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3240 - accuracy: 0.8612 - val_loss: 0.5235 - val_accuracy: 0.7709\n",
      "Epoch 486/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3239 - accuracy: 0.8547 - val_loss: 0.5094 - val_accuracy: 0.7734\n",
      "Epoch 487/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3204 - accuracy: 0.8580 - val_loss: 0.5102 - val_accuracy: 0.7709\n",
      "Epoch 488/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3198 - accuracy: 0.8621 - val_loss: 0.5305 - val_accuracy: 0.7709\n",
      "Epoch 489/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.3187 - accuracy: 0.8580 - val_loss: 0.5128 - val_accuracy: 0.7734\n",
      "Epoch 490/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3207 - accuracy: 0.8539 - val_loss: 0.5105 - val_accuracy: 0.7759\n",
      "Epoch 491/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3210 - accuracy: 0.8654 - val_loss: 0.5110 - val_accuracy: 0.7783\n",
      "Epoch 492/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3206 - accuracy: 0.8637 - val_loss: 0.5314 - val_accuracy: 0.7734\n",
      "Epoch 493/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.3261 - accuracy: 0.8506 - val_loss: 0.5135 - val_accuracy: 0.7734\n",
      "Epoch 494/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.3208 - accuracy: 0.8555 - val_loss: 0.5107 - val_accuracy: 0.7759\n",
      "Epoch 495/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3146 - accuracy: 0.8678 - val_loss: 0.5197 - val_accuracy: 0.7709\n",
      "Epoch 496/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.3136 - accuracy: 0.8695 - val_loss: 0.5115 - val_accuracy: 0.7734\n",
      "Epoch 497/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3114 - accuracy: 0.8604 - val_loss: 0.5134 - val_accuracy: 0.7734\n",
      "Epoch 498/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3133 - accuracy: 0.8662 - val_loss: 0.5143 - val_accuracy: 0.7783\n",
      "Epoch 499/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3116 - accuracy: 0.8662 - val_loss: 0.5153 - val_accuracy: 0.7759\n",
      "Epoch 500/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3106 - accuracy: 0.8670 - val_loss: 0.5120 - val_accuracy: 0.7709\n",
      "Epoch 501/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.3101 - accuracy: 0.8629 - val_loss: 0.5126 - val_accuracy: 0.7709\n",
      "Epoch 502/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3106 - accuracy: 0.8678 - val_loss: 0.5137 - val_accuracy: 0.7783\n",
      "Epoch 503/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.3102 - accuracy: 0.8662 - val_loss: 0.5182 - val_accuracy: 0.7759\n",
      "Epoch 504/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3138 - accuracy: 0.8612 - val_loss: 0.5179 - val_accuracy: 0.7783\n",
      "Epoch 505/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3159 - accuracy: 0.8637 - val_loss: 0.5131 - val_accuracy: 0.7685\n",
      "Epoch 506/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3075 - accuracy: 0.8678 - val_loss: 0.5192 - val_accuracy: 0.7759\n",
      "Epoch 507/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.3065 - accuracy: 0.8711 - val_loss: 0.5139 - val_accuracy: 0.7660\n",
      "Epoch 508/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3082 - accuracy: 0.8695 - val_loss: 0.5202 - val_accuracy: 0.7759\n",
      "Epoch 509/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3050 - accuracy: 0.8686 - val_loss: 0.5134 - val_accuracy: 0.7660\n",
      "Epoch 510/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3065 - accuracy: 0.8695 - val_loss: 0.5137 - val_accuracy: 0.7635\n",
      "Epoch 511/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3071 - accuracy: 0.8588 - val_loss: 0.5139 - val_accuracy: 0.7685\n",
      "Epoch 512/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3070 - accuracy: 0.8670 - val_loss: 0.5175 - val_accuracy: 0.7783\n",
      "Epoch 513/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3093 - accuracy: 0.8711 - val_loss: 0.5246 - val_accuracy: 0.7783\n",
      "Epoch 514/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3156 - accuracy: 0.8662 - val_loss: 0.5153 - val_accuracy: 0.7685\n",
      "Epoch 515/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3109 - accuracy: 0.8645 - val_loss: 0.5263 - val_accuracy: 0.7734\n",
      "Epoch 516/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.3108 - accuracy: 0.8670 - val_loss: 0.5246 - val_accuracy: 0.7709\n",
      "Epoch 517/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3102 - accuracy: 0.8695 - val_loss: 0.5165 - val_accuracy: 0.7660\n",
      "Epoch 518/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3017 - accuracy: 0.8711 - val_loss: 0.5181 - val_accuracy: 0.7783\n",
      "Epoch 519/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3009 - accuracy: 0.8703 - val_loss: 0.5177 - val_accuracy: 0.7808\n",
      "Epoch 520/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3018 - accuracy: 0.8678 - val_loss: 0.5165 - val_accuracy: 0.7759\n",
      "Epoch 521/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3009 - accuracy: 0.8711 - val_loss: 0.5230 - val_accuracy: 0.7783\n",
      "Epoch 522/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3031 - accuracy: 0.8719 - val_loss: 0.5207 - val_accuracy: 0.7759\n",
      "Epoch 523/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3030 - accuracy: 0.8703 - val_loss: 0.5258 - val_accuracy: 0.7734\n",
      "Epoch 524/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3132 - accuracy: 0.8703 - val_loss: 0.5201 - val_accuracy: 0.7709\n",
      "Epoch 525/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3040 - accuracy: 0.8744 - val_loss: 0.5319 - val_accuracy: 0.7685\n",
      "Epoch 526/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3054 - accuracy: 0.8695 - val_loss: 0.5182 - val_accuracy: 0.7783\n",
      "Epoch 527/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2986 - accuracy: 0.8711 - val_loss: 0.5188 - val_accuracy: 0.7808\n",
      "Epoch 528/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2972 - accuracy: 0.8744 - val_loss: 0.5185 - val_accuracy: 0.7734\n",
      "Epoch 529/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3008 - accuracy: 0.8670 - val_loss: 0.5286 - val_accuracy: 0.7709\n",
      "Epoch 530/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.3074 - accuracy: 0.8670 - val_loss: 0.5187 - val_accuracy: 0.7685\n",
      "Epoch 531/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2958 - accuracy: 0.8768 - val_loss: 0.5192 - val_accuracy: 0.7734\n",
      "Epoch 532/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2964 - accuracy: 0.8727 - val_loss: 0.5334 - val_accuracy: 0.7709\n",
      "Epoch 533/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2972 - accuracy: 0.8695 - val_loss: 0.5197 - val_accuracy: 0.7709\n",
      "Epoch 534/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2968 - accuracy: 0.8736 - val_loss: 0.5175 - val_accuracy: 0.7685\n",
      "Epoch 535/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.2951 - accuracy: 0.8777 - val_loss: 0.5189 - val_accuracy: 0.7635\n",
      "Epoch 536/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2936 - accuracy: 0.8744 - val_loss: 0.5192 - val_accuracy: 0.7734\n",
      "Epoch 537/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2960 - accuracy: 0.8801 - val_loss: 0.5241 - val_accuracy: 0.7808\n",
      "Epoch 538/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2929 - accuracy: 0.8785 - val_loss: 0.5205 - val_accuracy: 0.7734\n",
      "Epoch 539/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2927 - accuracy: 0.8752 - val_loss: 0.5206 - val_accuracy: 0.7709\n",
      "Epoch 540/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2925 - accuracy: 0.8785 - val_loss: 0.5322 - val_accuracy: 0.7734\n",
      "Epoch 541/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2957 - accuracy: 0.8719 - val_loss: 0.5219 - val_accuracy: 0.7759\n",
      "Epoch 542/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2921 - accuracy: 0.8727 - val_loss: 0.5226 - val_accuracy: 0.7660\n",
      "Epoch 543/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2914 - accuracy: 0.8768 - val_loss: 0.5217 - val_accuracy: 0.7759\n",
      "Epoch 544/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.2922 - accuracy: 0.8752 - val_loss: 0.5219 - val_accuracy: 0.7759\n",
      "Epoch 545/750\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.2959 - accuracy: 0.8711 - val_loss: 0.5616 - val_accuracy: 0.7857\n",
      "Epoch 546/750\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.3019 - accuracy: 0.8719 - val_loss: 0.5223 - val_accuracy: 0.7734\n",
      "Epoch 547/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.2895 - accuracy: 0.8744 - val_loss: 0.5231 - val_accuracy: 0.7709\n",
      "Epoch 548/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2882 - accuracy: 0.8785 - val_loss: 0.5230 - val_accuracy: 0.7759\n",
      "Epoch 549/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2889 - accuracy: 0.8818 - val_loss: 0.5228 - val_accuracy: 0.7734\n",
      "Epoch 550/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2881 - accuracy: 0.8810 - val_loss: 0.5225 - val_accuracy: 0.7759\n",
      "Epoch 551/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2864 - accuracy: 0.8768 - val_loss: 0.5223 - val_accuracy: 0.7734\n",
      "Epoch 552/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2859 - accuracy: 0.8810 - val_loss: 0.5261 - val_accuracy: 0.7685\n",
      "Epoch 553/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2910 - accuracy: 0.8752 - val_loss: 0.5253 - val_accuracy: 0.7734\n",
      "Epoch 554/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2837 - accuracy: 0.8818 - val_loss: 0.5236 - val_accuracy: 0.7685\n",
      "Epoch 555/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2902 - accuracy: 0.8744 - val_loss: 0.5275 - val_accuracy: 0.7759\n",
      "Epoch 556/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2869 - accuracy: 0.8851 - val_loss: 0.5240 - val_accuracy: 0.7734\n",
      "Epoch 557/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2847 - accuracy: 0.8834 - val_loss: 0.5267 - val_accuracy: 0.7783\n",
      "Epoch 558/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2886 - accuracy: 0.8752 - val_loss: 0.5266 - val_accuracy: 0.7709\n",
      "Epoch 559/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.2884 - accuracy: 0.8777 - val_loss: 0.5318 - val_accuracy: 0.7685\n",
      "Epoch 560/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2981 - accuracy: 0.8760 - val_loss: 0.5331 - val_accuracy: 0.7709\n",
      "Epoch 561/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.2937 - accuracy: 0.8744 - val_loss: 0.5409 - val_accuracy: 0.7833\n",
      "Epoch 562/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2899 - accuracy: 0.8834 - val_loss: 0.5403 - val_accuracy: 0.7857\n",
      "Epoch 563/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2889 - accuracy: 0.8810 - val_loss: 0.5273 - val_accuracy: 0.7759\n",
      "Epoch 564/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2867 - accuracy: 0.8768 - val_loss: 0.5332 - val_accuracy: 0.7734\n",
      "Epoch 565/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2871 - accuracy: 0.8752 - val_loss: 0.5291 - val_accuracy: 0.7759\n",
      "Epoch 566/750\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.2992 - accuracy: 0.8744 - val_loss: 0.5666 - val_accuracy: 0.7906\n",
      "Epoch 567/750\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.2926 - accuracy: 0.8727 - val_loss: 0.5321 - val_accuracy: 0.7808\n",
      "Epoch 568/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.2829 - accuracy: 0.8785 - val_loss: 0.5260 - val_accuracy: 0.7709\n",
      "Epoch 569/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2830 - accuracy: 0.8801 - val_loss: 0.5343 - val_accuracy: 0.7660\n",
      "Epoch 570/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2866 - accuracy: 0.8801 - val_loss: 0.5311 - val_accuracy: 0.7759\n",
      "Epoch 571/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2886 - accuracy: 0.8900 - val_loss: 0.5676 - val_accuracy: 0.7906\n",
      "Epoch 572/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2965 - accuracy: 0.8752 - val_loss: 0.5277 - val_accuracy: 0.7734\n",
      "Epoch 573/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2818 - accuracy: 0.8908 - val_loss: 0.5266 - val_accuracy: 0.7709\n",
      "Epoch 574/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2757 - accuracy: 0.8867 - val_loss: 0.5424 - val_accuracy: 0.7882\n",
      "Epoch 575/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2795 - accuracy: 0.8768 - val_loss: 0.5268 - val_accuracy: 0.7709\n",
      "Epoch 576/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2808 - accuracy: 0.8867 - val_loss: 0.5479 - val_accuracy: 0.7709\n",
      "Epoch 577/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2851 - accuracy: 0.8810 - val_loss: 0.5498 - val_accuracy: 0.7833\n",
      "Epoch 578/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2954 - accuracy: 0.8719 - val_loss: 0.5801 - val_accuracy: 0.7906\n",
      "Epoch 579/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2972 - accuracy: 0.8727 - val_loss: 0.5309 - val_accuracy: 0.7734\n",
      "Epoch 580/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2967 - accuracy: 0.8777 - val_loss: 0.5786 - val_accuracy: 0.7562\n",
      "Epoch 581/750\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3121 - accuracy: 0.8629 - val_loss: 0.5451 - val_accuracy: 0.7709\n",
      "Epoch 582/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3076 - accuracy: 0.8695 - val_loss: 0.5446 - val_accuracy: 0.7857\n",
      "Epoch 583/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2788 - accuracy: 0.8859 - val_loss: 0.5339 - val_accuracy: 0.7833\n",
      "Epoch 584/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2767 - accuracy: 0.8859 - val_loss: 0.5295 - val_accuracy: 0.7734\n",
      "Epoch 585/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2736 - accuracy: 0.8892 - val_loss: 0.5481 - val_accuracy: 0.7882\n",
      "Epoch 586/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2835 - accuracy: 0.8867 - val_loss: 0.5301 - val_accuracy: 0.7759\n",
      "Epoch 587/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2727 - accuracy: 0.8859 - val_loss: 0.5340 - val_accuracy: 0.7660\n",
      "Epoch 588/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2817 - accuracy: 0.8859 - val_loss: 0.5301 - val_accuracy: 0.7685\n",
      "Epoch 589/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2886 - accuracy: 0.8785 - val_loss: 0.5320 - val_accuracy: 0.7759\n",
      "Epoch 590/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2861 - accuracy: 0.8670 - val_loss: 0.5490 - val_accuracy: 0.7882\n",
      "Epoch 591/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2816 - accuracy: 0.8810 - val_loss: 0.5534 - val_accuracy: 0.7808\n",
      "Epoch 592/750\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 0.2813 - accuracy: 0.8785 - val_loss: 0.5453 - val_accuracy: 0.7931\n",
      "Epoch 593/750\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.2808 - accuracy: 0.8826 - val_loss: 0.5674 - val_accuracy: 0.7882\n",
      "Epoch 594/750\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.2909 - accuracy: 0.8695 - val_loss: 0.5309 - val_accuracy: 0.7709\n",
      "Epoch 595/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2776 - accuracy: 0.8842 - val_loss: 0.5488 - val_accuracy: 0.7783\n",
      "Epoch 596/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2873 - accuracy: 0.8777 - val_loss: 0.5358 - val_accuracy: 0.7685\n",
      "Epoch 597/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.3048 - accuracy: 0.8654 - val_loss: 0.5419 - val_accuracy: 0.7857\n",
      "Epoch 598/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2760 - accuracy: 0.8842 - val_loss: 0.5560 - val_accuracy: 0.7906\n",
      "Epoch 599/750\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.2752 - accuracy: 0.8842 - val_loss: 0.5322 - val_accuracy: 0.7685\n",
      "Epoch 600/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2799 - accuracy: 0.8793 - val_loss: 0.5428 - val_accuracy: 0.7759\n",
      "Epoch 601/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2757 - accuracy: 0.8859 - val_loss: 0.5422 - val_accuracy: 0.7734\n",
      "Epoch 602/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2743 - accuracy: 0.8867 - val_loss: 0.5335 - val_accuracy: 0.7685\n",
      "Epoch 603/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2659 - accuracy: 0.8941 - val_loss: 0.5317 - val_accuracy: 0.7709\n",
      "Epoch 604/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2649 - accuracy: 0.8924 - val_loss: 0.5329 - val_accuracy: 0.7709\n",
      "Epoch 605/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2685 - accuracy: 0.8900 - val_loss: 0.5329 - val_accuracy: 0.7685\n",
      "Epoch 606/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2646 - accuracy: 0.8941 - val_loss: 0.5453 - val_accuracy: 0.7882\n",
      "Epoch 607/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2704 - accuracy: 0.8867 - val_loss: 0.5532 - val_accuracy: 0.7833\n",
      "Epoch 608/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2737 - accuracy: 0.8851 - val_loss: 0.5374 - val_accuracy: 0.7833\n",
      "Epoch 609/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2733 - accuracy: 0.8851 - val_loss: 0.5405 - val_accuracy: 0.7709\n",
      "Epoch 610/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2670 - accuracy: 0.8900 - val_loss: 0.5392 - val_accuracy: 0.7709\n",
      "Epoch 611/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2651 - accuracy: 0.8982 - val_loss: 0.5360 - val_accuracy: 0.7709\n",
      "Epoch 612/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2612 - accuracy: 0.8941 - val_loss: 0.5392 - val_accuracy: 0.7833\n",
      "Epoch 613/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2621 - accuracy: 0.8933 - val_loss: 0.5359 - val_accuracy: 0.7685\n",
      "Epoch 614/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2609 - accuracy: 0.8924 - val_loss: 0.5360 - val_accuracy: 0.7709\n",
      "Epoch 615/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2635 - accuracy: 0.8916 - val_loss: 0.5411 - val_accuracy: 0.7833\n",
      "Epoch 616/750\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.2673 - accuracy: 0.8883 - val_loss: 0.5648 - val_accuracy: 0.7882\n",
      "Epoch 617/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2730 - accuracy: 0.8859 - val_loss: 0.5690 - val_accuracy: 0.7882\n",
      "Epoch 618/750\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.2834 - accuracy: 0.8760 - val_loss: 0.5476 - val_accuracy: 0.7906\n",
      "Epoch 619/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2710 - accuracy: 0.8834 - val_loss: 0.5603 - val_accuracy: 0.7734\n",
      "Epoch 620/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2773 - accuracy: 0.8826 - val_loss: 0.5525 - val_accuracy: 0.7759\n",
      "Epoch 621/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2794 - accuracy: 0.8867 - val_loss: 0.5415 - val_accuracy: 0.7660\n",
      "Epoch 622/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2586 - accuracy: 0.8966 - val_loss: 0.5385 - val_accuracy: 0.7709\n",
      "Epoch 623/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2631 - accuracy: 0.8966 - val_loss: 0.5811 - val_accuracy: 0.7882\n",
      "Epoch 624/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2706 - accuracy: 0.8842 - val_loss: 0.5410 - val_accuracy: 0.7709\n",
      "Epoch 625/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2567 - accuracy: 0.8990 - val_loss: 0.5453 - val_accuracy: 0.7882\n",
      "Epoch 626/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2594 - accuracy: 0.8966 - val_loss: 0.5528 - val_accuracy: 0.7882\n",
      "Epoch 627/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2595 - accuracy: 0.8941 - val_loss: 0.5433 - val_accuracy: 0.7833\n",
      "Epoch 628/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2618 - accuracy: 0.8908 - val_loss: 0.5408 - val_accuracy: 0.7734\n",
      "Epoch 629/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2561 - accuracy: 0.8949 - val_loss: 0.5457 - val_accuracy: 0.7685\n",
      "Epoch 630/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2592 - accuracy: 0.8900 - val_loss: 0.5415 - val_accuracy: 0.7709\n",
      "Epoch 631/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2688 - accuracy: 0.8859 - val_loss: 0.5415 - val_accuracy: 0.7709\n",
      "Epoch 632/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2673 - accuracy: 0.8834 - val_loss: 0.5481 - val_accuracy: 0.7882\n",
      "Epoch 633/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2548 - accuracy: 0.8982 - val_loss: 0.5523 - val_accuracy: 0.7906\n",
      "Epoch 634/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2586 - accuracy: 0.8941 - val_loss: 0.5544 - val_accuracy: 0.7906\n",
      "Epoch 635/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2581 - accuracy: 0.8957 - val_loss: 0.5477 - val_accuracy: 0.7685\n",
      "Epoch 636/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2532 - accuracy: 0.8998 - val_loss: 0.5460 - val_accuracy: 0.7783\n",
      "Epoch 637/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2517 - accuracy: 0.8990 - val_loss: 0.5450 - val_accuracy: 0.7783\n",
      "Epoch 638/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2519 - accuracy: 0.8990 - val_loss: 0.5483 - val_accuracy: 0.7882\n",
      "Epoch 639/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2564 - accuracy: 0.8941 - val_loss: 0.5504 - val_accuracy: 0.7882\n",
      "Epoch 640/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2551 - accuracy: 0.8949 - val_loss: 0.5441 - val_accuracy: 0.7709\n",
      "Epoch 641/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2512 - accuracy: 0.8990 - val_loss: 0.5500 - val_accuracy: 0.7660\n",
      "Epoch 642/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2528 - accuracy: 0.8933 - val_loss: 0.5464 - val_accuracy: 0.7685\n",
      "Epoch 643/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2600 - accuracy: 0.8933 - val_loss: 0.5675 - val_accuracy: 0.7808\n",
      "Epoch 644/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2576 - accuracy: 0.8908 - val_loss: 0.5482 - val_accuracy: 0.7833\n",
      "Epoch 645/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2506 - accuracy: 0.9031 - val_loss: 0.5495 - val_accuracy: 0.7857\n",
      "Epoch 646/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2486 - accuracy: 0.9031 - val_loss: 0.5564 - val_accuracy: 0.7882\n",
      "Epoch 647/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2568 - accuracy: 0.8892 - val_loss: 0.5492 - val_accuracy: 0.7734\n",
      "Epoch 648/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2571 - accuracy: 0.8924 - val_loss: 0.5563 - val_accuracy: 0.7709\n",
      "Epoch 649/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2516 - accuracy: 0.8949 - val_loss: 0.5478 - val_accuracy: 0.7734\n",
      "Epoch 650/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2483 - accuracy: 0.8990 - val_loss: 0.5582 - val_accuracy: 0.7709\n",
      "Epoch 651/750\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2569 - accuracy: 0.8949 - val_loss: 0.5898 - val_accuracy: 0.7685\n",
      "Epoch 652/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2685 - accuracy: 0.8760 - val_loss: 0.5504 - val_accuracy: 0.7734\n",
      "Epoch 653/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2630 - accuracy: 0.8933 - val_loss: 0.5632 - val_accuracy: 0.7857\n",
      "Epoch 654/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2513 - accuracy: 0.8908 - val_loss: 0.5635 - val_accuracy: 0.7931\n",
      "Epoch 655/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2535 - accuracy: 0.8834 - val_loss: 0.5662 - val_accuracy: 0.7931\n",
      "Epoch 656/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2544 - accuracy: 0.8933 - val_loss: 0.5927 - val_accuracy: 0.7759\n",
      "Epoch 657/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2658 - accuracy: 0.8768 - val_loss: 0.5589 - val_accuracy: 0.7882\n",
      "Epoch 658/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2734 - accuracy: 0.8834 - val_loss: 0.5567 - val_accuracy: 0.7833\n",
      "Epoch 659/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2672 - accuracy: 0.8842 - val_loss: 0.5653 - val_accuracy: 0.7734\n",
      "Epoch 660/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2520 - accuracy: 0.8957 - val_loss: 0.5598 - val_accuracy: 0.7734\n",
      "Epoch 661/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2455 - accuracy: 0.9015 - val_loss: 0.5527 - val_accuracy: 0.7759\n",
      "Epoch 662/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2441 - accuracy: 0.9048 - val_loss: 0.5587 - val_accuracy: 0.7906\n",
      "Epoch 663/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2497 - accuracy: 0.8949 - val_loss: 0.5584 - val_accuracy: 0.7833\n",
      "Epoch 664/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.2511 - accuracy: 0.8957 - val_loss: 0.5641 - val_accuracy: 0.7931\n",
      "Epoch 665/750\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.2522 - accuracy: 0.8908 - val_loss: 0.5551 - val_accuracy: 0.7759\n",
      "Epoch 666/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.2503 - accuracy: 0.8957 - val_loss: 0.5592 - val_accuracy: 0.7734\n",
      "Epoch 667/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.2466 - accuracy: 0.9007 - val_loss: 0.5893 - val_accuracy: 0.7734\n",
      "Epoch 668/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.2554 - accuracy: 0.8933 - val_loss: 0.5676 - val_accuracy: 0.7709\n",
      "Epoch 669/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.2649 - accuracy: 0.8842 - val_loss: 0.5780 - val_accuracy: 0.7759\n",
      "Epoch 670/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.2739 - accuracy: 0.8834 - val_loss: 0.5554 - val_accuracy: 0.7783\n",
      "Epoch 671/750\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.2590 - accuracy: 0.8900 - val_loss: 0.5643 - val_accuracy: 0.7882\n",
      "Epoch 672/750\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.2594 - accuracy: 0.8859 - val_loss: 0.5840 - val_accuracy: 0.7931\n",
      "Epoch 673/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.2632 - accuracy: 0.8924 - val_loss: 0.6110 - val_accuracy: 0.7833\n",
      "Epoch 674/750\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.2604 - accuracy: 0.8777 - val_loss: 0.5801 - val_accuracy: 0.7906\n",
      "Epoch 675/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2520 - accuracy: 0.8990 - val_loss: 0.5675 - val_accuracy: 0.7906\n",
      "Epoch 676/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2469 - accuracy: 0.8957 - val_loss: 0.5628 - val_accuracy: 0.7906\n",
      "Epoch 677/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2406 - accuracy: 0.9072 - val_loss: 0.5634 - val_accuracy: 0.7882\n",
      "Epoch 678/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2494 - accuracy: 0.8949 - val_loss: 0.5935 - val_accuracy: 0.7833\n",
      "Epoch 679/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2601 - accuracy: 0.8892 - val_loss: 0.5699 - val_accuracy: 0.7931\n",
      "Epoch 680/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2452 - accuracy: 0.9039 - val_loss: 0.5599 - val_accuracy: 0.7734\n",
      "Epoch 681/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2467 - accuracy: 0.8916 - val_loss: 0.5638 - val_accuracy: 0.7759\n",
      "Epoch 682/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2452 - accuracy: 0.8974 - val_loss: 0.5786 - val_accuracy: 0.7734\n",
      "Epoch 683/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2468 - accuracy: 0.8998 - val_loss: 0.5627 - val_accuracy: 0.7783\n",
      "Epoch 684/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2485 - accuracy: 0.8990 - val_loss: 0.5675 - val_accuracy: 0.7783\n",
      "Epoch 685/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2436 - accuracy: 0.8998 - val_loss: 0.5657 - val_accuracy: 0.7808\n",
      "Epoch 686/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2449 - accuracy: 0.8998 - val_loss: 0.5587 - val_accuracy: 0.7759\n",
      "Epoch 687/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2398 - accuracy: 0.9015 - val_loss: 0.5687 - val_accuracy: 0.7906\n",
      "Epoch 688/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2433 - accuracy: 0.9023 - val_loss: 0.5716 - val_accuracy: 0.7906\n",
      "Epoch 689/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2444 - accuracy: 0.9039 - val_loss: 0.5821 - val_accuracy: 0.7857\n",
      "Epoch 690/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2610 - accuracy: 0.8851 - val_loss: 0.5922 - val_accuracy: 0.7833\n",
      "Epoch 691/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2699 - accuracy: 0.8793 - val_loss: 0.6116 - val_accuracy: 0.7833\n",
      "Epoch 692/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2637 - accuracy: 0.8826 - val_loss: 0.5783 - val_accuracy: 0.7882\n",
      "Epoch 693/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2346 - accuracy: 0.9056 - val_loss: 0.5602 - val_accuracy: 0.7833\n",
      "Epoch 694/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2327 - accuracy: 0.9130 - val_loss: 0.5592 - val_accuracy: 0.7759\n",
      "Epoch 695/750\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.2313 - accuracy: 0.9097 - val_loss: 0.5617 - val_accuracy: 0.7808\n",
      "Epoch 696/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2317 - accuracy: 0.9080 - val_loss: 0.5602 - val_accuracy: 0.7783\n",
      "Epoch 697/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2372 - accuracy: 0.8998 - val_loss: 0.5665 - val_accuracy: 0.7783\n",
      "Epoch 698/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2319 - accuracy: 0.9080 - val_loss: 0.5696 - val_accuracy: 0.7931\n",
      "Epoch 699/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2334 - accuracy: 0.9064 - val_loss: 0.5664 - val_accuracy: 0.7783\n",
      "Epoch 700/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2338 - accuracy: 0.9056 - val_loss: 0.5698 - val_accuracy: 0.7906\n",
      "Epoch 701/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2438 - accuracy: 0.9007 - val_loss: 0.5652 - val_accuracy: 0.7833\n",
      "Epoch 702/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2537 - accuracy: 0.8957 - val_loss: 0.5716 - val_accuracy: 0.7931\n",
      "Epoch 703/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2332 - accuracy: 0.9048 - val_loss: 0.5682 - val_accuracy: 0.7833\n",
      "Epoch 704/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2348 - accuracy: 0.9015 - val_loss: 0.5740 - val_accuracy: 0.7808\n",
      "Epoch 705/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2425 - accuracy: 0.8933 - val_loss: 0.5758 - val_accuracy: 0.7783\n",
      "Epoch 706/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2320 - accuracy: 0.9048 - val_loss: 0.5805 - val_accuracy: 0.7808\n",
      "Epoch 707/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2321 - accuracy: 0.9097 - val_loss: 0.5773 - val_accuracy: 0.7882\n",
      "Epoch 708/750\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.2451 - accuracy: 0.8916 - val_loss: 0.5731 - val_accuracy: 0.7906\n",
      "Epoch 709/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2266 - accuracy: 0.9048 - val_loss: 0.5792 - val_accuracy: 0.7734\n",
      "Epoch 710/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2442 - accuracy: 0.8949 - val_loss: 0.5998 - val_accuracy: 0.7685\n",
      "Epoch 711/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2367 - accuracy: 0.9007 - val_loss: 0.5804 - val_accuracy: 0.7759\n",
      "Epoch 712/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2342 - accuracy: 0.9064 - val_loss: 0.5775 - val_accuracy: 0.7783\n",
      "Epoch 713/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2286 - accuracy: 0.9089 - val_loss: 0.5695 - val_accuracy: 0.7857\n",
      "Epoch 714/750\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.2271 - accuracy: 0.9039 - val_loss: 0.5692 - val_accuracy: 0.7808\n",
      "Epoch 715/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2268 - accuracy: 0.9080 - val_loss: 0.5684 - val_accuracy: 0.7833\n",
      "Epoch 716/750\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2321 - accuracy: 0.9039 - val_loss: 0.5701 - val_accuracy: 0.7808\n",
      "Epoch 717/750\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.2295 - accuracy: 0.9039 - val_loss: 0.5744 - val_accuracy: 0.7808\n",
      "Epoch 718/750\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2262 - accuracy: 0.9031 - val_loss: 0.5878 - val_accuracy: 0.7783\n",
      "Epoch 719/750\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2357 - accuracy: 0.9023 - val_loss: 0.5735 - val_accuracy: 0.7882\n",
      "Epoch 720/750\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.2251 - accuracy: 0.9080 - val_loss: 0.5970 - val_accuracy: 0.7709\n",
      "Epoch 721/750\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 0.2574 - accuracy: 0.8851 - val_loss: 0.5783 - val_accuracy: 0.7906\n",
      "Epoch 722/750\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.2323 - accuracy: 0.9015 - val_loss: 0.5794 - val_accuracy: 0.7931\n",
      "Epoch 723/750\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.2396 - accuracy: 0.8990 - val_loss: 0.5745 - val_accuracy: 0.7857\n",
      "Epoch 724/750\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 0.2363 - accuracy: 0.8982 - val_loss: 0.5717 - val_accuracy: 0.7857\n",
      "Epoch 725/750\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.2174 - accuracy: 0.9122 - val_loss: 0.5895 - val_accuracy: 0.7906\n",
      "Epoch 726/750\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.2281 - accuracy: 0.9023 - val_loss: 0.5922 - val_accuracy: 0.7906\n",
      "Epoch 727/750\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.2376 - accuracy: 0.8998 - val_loss: 0.6135 - val_accuracy: 0.7857\n",
      "Epoch 728/750\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.2455 - accuracy: 0.8908 - val_loss: 0.6182 - val_accuracy: 0.7857\n",
      "Epoch 729/750\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.2301 - accuracy: 0.9048 - val_loss: 0.5864 - val_accuracy: 0.7882\n",
      "Epoch 730/750\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.2234 - accuracy: 0.9056 - val_loss: 0.5744 - val_accuracy: 0.7734\n",
      "Epoch 731/750\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.2187 - accuracy: 0.9130 - val_loss: 0.5746 - val_accuracy: 0.7808\n",
      "Epoch 732/750\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.2181 - accuracy: 0.9179 - val_loss: 0.5812 - val_accuracy: 0.7857\n",
      "Epoch 733/750\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.2237 - accuracy: 0.9048 - val_loss: 0.5897 - val_accuracy: 0.7833\n",
      "Epoch 734/750\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.2243 - accuracy: 0.9039 - val_loss: 0.5785 - val_accuracy: 0.7808\n",
      "Epoch 735/750\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.2171 - accuracy: 0.9146 - val_loss: 0.5779 - val_accuracy: 0.7808\n",
      "Epoch 736/750\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.2161 - accuracy: 0.9146 - val_loss: 0.5777 - val_accuracy: 0.7882\n",
      "Epoch 737/750\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.2148 - accuracy: 0.9171 - val_loss: 0.5787 - val_accuracy: 0.7857\n",
      "Epoch 738/750\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.2164 - accuracy: 0.9105 - val_loss: 0.5941 - val_accuracy: 0.7808\n",
      "Epoch 739/750\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.2177 - accuracy: 0.9113 - val_loss: 0.5790 - val_accuracy: 0.7783\n",
      "Epoch 740/750\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.2184 - accuracy: 0.9064 - val_loss: 0.5901 - val_accuracy: 0.7857\n",
      "Epoch 741/750\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.2228 - accuracy: 0.9064 - val_loss: 0.5901 - val_accuracy: 0.7783\n",
      "Epoch 742/750\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.2141 - accuracy: 0.9138 - val_loss: 0.5823 - val_accuracy: 0.7808\n",
      "Epoch 743/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 252ms/step - loss: 0.2154 - accuracy: 0.9163 - val_loss: 0.5833 - val_accuracy: 0.7808\n",
      "Epoch 744/750\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.2135 - accuracy: 0.9146 - val_loss: 0.5841 - val_accuracy: 0.7857\n",
      "Epoch 745/750\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.2116 - accuracy: 0.9113 - val_loss: 0.5938 - val_accuracy: 0.7833\n",
      "Epoch 746/750\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.2172 - accuracy: 0.9122 - val_loss: 0.5997 - val_accuracy: 0.7808\n",
      "Epoch 747/750\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.2187 - accuracy: 0.9097 - val_loss: 0.5954 - val_accuracy: 0.7833\n",
      "Epoch 748/750\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.2212 - accuracy: 0.9097 - val_loss: 0.5965 - val_accuracy: 0.7833\n",
      "Epoch 749/750\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.2157 - accuracy: 0.9122 - val_loss: 0.5985 - val_accuracy: 0.7833\n",
      "Epoch 750/750\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.2211 - accuracy: 0.9105 - val_loss: 0.5864 - val_accuracy: 0.7857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21052c0a2f0>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = SGD(lr=1e-3, momentum=0.9)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='C:\\\\Users\\\\linhl\\\\Desktop\\\\IT7143\\\\Module 12',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "model.fit(trainX_embs, trainY_embs, epochs=750, batch_size=256, validation_data=(validX_embs, validY_embs), callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b50458a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 31ms/step - loss: 0.4952 - accuracy: 0.8051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4951643943786621, 0.8051282167434692]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('C:\\\\Users\\\\linhl\\\\Desktop\\\\IT7143\\\\Module 12')\n",
    "model.evaluate(testX_embs, testY_embs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
