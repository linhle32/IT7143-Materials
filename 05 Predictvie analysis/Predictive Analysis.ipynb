{"cells":[{"cell_type":"markdown","id":"109e61ad","metadata":{"id":"109e61ad"},"source":["<h2>Predictive Analysis</h2>\n","\n","After having data ready for modeling, we can now build, train, and test our models. This module discuss the tasks in predictive analysis that are regression and classification. Recall, these two belong to **supervised learning** which means they need a target in the provided data. \n","\n","First, we import and split data as usual"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/IT7143\\ Module\\ 5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zr6UcygVNdR_","executionInfo":{"status":"ok","timestamp":1676320280473,"user_tz":300,"elapsed":18745,"user":{"displayName":"Linh Le","userId":"00514130171715816639"}},"outputId":"abd91dc3-4975-4b36-b3b1-3d8bed79ef28"},"id":"zr6UcygVNdR_","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/IT7143 Module 5\n"]}]},{"cell_type":"code","execution_count":2,"id":"7c0379b2","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"7c0379b2","executionInfo":{"status":"ok","timestamp":1676320286278,"user_tz":300,"elapsed":1913,"user":{"displayName":"Linh Le","userId":"00514130171715816639"}},"outputId":"a25f4d78-a958-496e-cca6-9f3a824b82d4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     StudentID  FirstName  LastName                   Major  HighSchoolGPA  \\\n","0    202303595     Baxter   Dengler        Computer Science           2.82   \n","1    202309162  Christian    Wickey            Data Science           3.07   \n","2    202306337     Lonnie     Wulff    Software Engineering           2.68   \n","3    202306072   Mitchell  Deshotel    Software Engineering           3.21   \n","4    202301733    Linwood   Willing  Information Technology           3.44   \n","..         ...        ...       ...                     ...            ...   \n","995  202302372    Michael   Richman        Computer Science           4.00   \n","996  202309892       Lacy     Anton    Software Engineering           3.02   \n","997  202308310        Ell     Benke    Software Engineering           2.05   \n","998  202305648      Elzie   Enderle  Information Technology           2.19   \n","999  202307731     Adolph   Cornman            Data Science           3.84   \n","\n","     FamilyIncome State  AvgDailyStudyTime  TotalAbsence  FirstYearGPA  isGRA  \n","0           45013    WA               2.01          14.0          1.93      0  \n","1          128358    GA               5.41           NaN          2.76      0  \n","2          112392    GA               9.57          13.0          3.09      0  \n","3          190846    GA               8.57          16.0          3.08      0  \n","4          187163    GA               6.24          20.0          2.73      0  \n","..            ...   ...                ...           ...           ...    ...  \n","995         32210    SC               8.84          16.0          3.31      1  \n","996        163481    GA               6.61          17.0          2.53      0  \n","997         45446    GA               3.68          30.0          1.77      0  \n","998         44714    GA               2.74          17.0          2.11      0  \n","999         43195    AL               7.23          15.0          2.94      0  \n","\n","[1000 rows x 11 columns]"],"text/html":["\n","  <div id=\"df-047fa8a9-c173-43a3-a107-705581b14011\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>StudentID</th>\n","      <th>FirstName</th>\n","      <th>LastName</th>\n","      <th>Major</th>\n","      <th>HighSchoolGPA</th>\n","      <th>FamilyIncome</th>\n","      <th>State</th>\n","      <th>AvgDailyStudyTime</th>\n","      <th>TotalAbsence</th>\n","      <th>FirstYearGPA</th>\n","      <th>isGRA</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>202303595</td>\n","      <td>Baxter</td>\n","      <td>Dengler</td>\n","      <td>Computer Science</td>\n","      <td>2.82</td>\n","      <td>45013</td>\n","      <td>WA</td>\n","      <td>2.01</td>\n","      <td>14.0</td>\n","      <td>1.93</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>202309162</td>\n","      <td>Christian</td>\n","      <td>Wickey</td>\n","      <td>Data Science</td>\n","      <td>3.07</td>\n","      <td>128358</td>\n","      <td>GA</td>\n","      <td>5.41</td>\n","      <td>NaN</td>\n","      <td>2.76</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>202306337</td>\n","      <td>Lonnie</td>\n","      <td>Wulff</td>\n","      <td>Software Engineering</td>\n","      <td>2.68</td>\n","      <td>112392</td>\n","      <td>GA</td>\n","      <td>9.57</td>\n","      <td>13.0</td>\n","      <td>3.09</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>202306072</td>\n","      <td>Mitchell</td>\n","      <td>Deshotel</td>\n","      <td>Software Engineering</td>\n","      <td>3.21</td>\n","      <td>190846</td>\n","      <td>GA</td>\n","      <td>8.57</td>\n","      <td>16.0</td>\n","      <td>3.08</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>202301733</td>\n","      <td>Linwood</td>\n","      <td>Willing</td>\n","      <td>Information Technology</td>\n","      <td>3.44</td>\n","      <td>187163</td>\n","      <td>GA</td>\n","      <td>6.24</td>\n","      <td>20.0</td>\n","      <td>2.73</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>202302372</td>\n","      <td>Michael</td>\n","      <td>Richman</td>\n","      <td>Computer Science</td>\n","      <td>4.00</td>\n","      <td>32210</td>\n","      <td>SC</td>\n","      <td>8.84</td>\n","      <td>16.0</td>\n","      <td>3.31</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>202309892</td>\n","      <td>Lacy</td>\n","      <td>Anton</td>\n","      <td>Software Engineering</td>\n","      <td>3.02</td>\n","      <td>163481</td>\n","      <td>GA</td>\n","      <td>6.61</td>\n","      <td>17.0</td>\n","      <td>2.53</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>202308310</td>\n","      <td>Ell</td>\n","      <td>Benke</td>\n","      <td>Software Engineering</td>\n","      <td>2.05</td>\n","      <td>45446</td>\n","      <td>GA</td>\n","      <td>3.68</td>\n","      <td>30.0</td>\n","      <td>1.77</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>202305648</td>\n","      <td>Elzie</td>\n","      <td>Enderle</td>\n","      <td>Information Technology</td>\n","      <td>2.19</td>\n","      <td>44714</td>\n","      <td>GA</td>\n","      <td>2.74</td>\n","      <td>17.0</td>\n","      <td>2.11</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>202307731</td>\n","      <td>Adolph</td>\n","      <td>Cornman</td>\n","      <td>Data Science</td>\n","      <td>3.84</td>\n","      <td>43195</td>\n","      <td>AL</td>\n","      <td>7.23</td>\n","      <td>15.0</td>\n","      <td>2.94</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows Ã— 11 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-047fa8a9-c173-43a3-a107-705581b14011')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-047fa8a9-c173-43a3-a107-705581b14011 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-047fa8a9-c173-43a3-a107-705581b14011');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":2}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","students = pd.read_csv('students_m5.csv')\n","students"]},{"cell_type":"code","execution_count":3,"id":"9c9bf275","metadata":{"id":"9c9bf275","executionInfo":{"status":"ok","timestamp":1676320288761,"user_tz":300,"elapsed":2489,"user":{"displayName":"Linh Le","userId":"00514130171715816639"}}},"outputs":[],"source":["features = students.drop(['StudentID','FirstName','LastName','FirstYearGPA','isGRA'], axis=1)\n","labels = students['FirstYearGPA']\n","\n","from sklearn.model_selection import train_test_split\n","\n","trainX, testX, trainY, testY = train_test_split(features, labels, test_size=0.2)"]},{"cell_type":"markdown","id":"99cc22a5","metadata":{"id":"99cc22a5"},"source":["<h3>Processing Pipeline</h3>\n","\n","Processing data with pandas is fine however not too convenient, especially if we have to repeat the same process multiple times.\n","\n","Instead, we will utilize the **SKLearn Pipeline** in this module. A pipeline allows mutiple processing steps to be wrapped inside a single object that can be reusable.\n","\n","*This part is kept simple since this notebook focuses on modeling. Please refer to the Pipeline Explained notebook for more descriptions on each step in the pipeline.*\n","\n","For steps like outlier clipping, log transformation, and removing rare values, we need to write the functions. For more common processes like standardization and one hot encoder, we will use module from sklearn.\n","\n","The below code for pipeline is pretty standard. You can **reuse the code in different analysis**, just make sure to change the list of numeric columns and class columns, as well as verify whether the hard-coded numbers are what you want."]},{"cell_type":"code","execution_count":4,"id":"4a9eed70","metadata":{"id":"4a9eed70","executionInfo":{"status":"ok","timestamp":1676320288761,"user_tz":300,"elapsed":3,"user":{"displayName":"Linh Le","userId":"00514130171715816639"}}},"outputs":[],"source":["num_cols = ['HighSchoolGPA','FamilyIncome','AvgDailyStudyTime','TotalAbsence']\n","cat_cols = ['Major','State']\n","\n","#function to clip outliers\n","def outlier_clip(data):\n","    num_sds = trainX[num_cols].std()\n","    num_means = trainX[num_cols].mean()\n","    return np.clip(data, num_means - 4*num_sds, num_means + 4*num_sds, axis=1)    #you can change 4 to other numbers\n","\n","#function to log transform\n","def log_transform(data):\n","    return pd.concat([data, np.log(data.add_suffix('_log') + 0.001)], axis=1)     #you can change 0.001 to other numbers\n","\n","#function to remove rare classes\n","def remove_rare_classes(data):\n","    data_copy = data.copy()\n","    kept_classes = {}\n","    for col in cat_cols:\n","        cat_counts = trainX[col].value_counts()\n","        kept_classes[col] = cat_counts.index[cat_counts > 40]                     #you can change 40 to other numbers\n","    for col in cat_cols:\n","        data_copy.loc[~data_copy[col].isin(kept_classes[col]), col] = 'Other'\n","    return data_copy"]},{"cell_type":"markdown","id":"bac95651","metadata":{"id":"bac95651"},"source":["Now we import all the other needed tools from sklearn. \n","- **FunctionTransformer** is used for transformation that are not prebuilt in sklearn. This included removing outliers, log transformation, and removing rare classes. \n","    - FunctionTransformer needs the written function as an input\n","- **Pipeline** in an object that takes inputs as a *list of transformations*\n","    - Each item in the list requires a name (as a string) and the sklearn transformer, i.e., FunctionTransformer, SimpleImputer, etc. The two components are separated by a comma\n","    - The listed transformations will be performed in the order they appear\n","- **ColumnTransformer** combines the two pipelines for numeric and class columns into one uniform, final pipeline\n","    - Only use fit_transform() on training data\n","    - Testing data must be transformed with transform()"]},{"cell_type":"code","execution_count":5,"id":"dccb696d","metadata":{"id":"dccb696d","executionInfo":{"status":"ok","timestamp":1676320289357,"user_tz":300,"elapsed":598,"user":{"displayName":"Linh Le","userId":"00514130171715816639"}}},"outputs":[],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import FunctionTransformer\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.impute import SimpleImputer\n","\n","#pipeline for numeric columns\n","num_pipeline = Pipeline([\n","    ('outlier clip', FunctionTransformer(outlier_clip)),\n","    ('log transform', FunctionTransformer(log_transform)),\n","    ('standardize', StandardScaler()),\n","    ('impute', SimpleImputer(strategy='median'))    \n","])\n","\n","#pipeline for class columns\n","cat_pipeline = Pipeline([\n","    ('remove rare classes', FunctionTransformer(remove_rare_classes)),\n","    ('encode', OneHotEncoder())\n","])\n","\n","from sklearn.compose import ColumnTransformer\n","\n","#combining\n","full_pipeline = ColumnTransformer([\n","    ('numeric', num_pipeline, num_cols),\n","    ('class', cat_pipeline, cat_cols)\n","])\n","\n","#use the built pipeline to process training and testing data\n","trainX_prc = full_pipeline.fit_transform(trainX)\n","testX_prc = full_pipeline.transform(testX)"]},{"cell_type":"code","source":["trainX_prc.shape, testX_prc.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xQtWay4Medm7","executionInfo":{"status":"ok","timestamp":1676320309978,"user_tz":300,"elapsed":146,"user":{"displayName":"Linh Le","userId":"00514130171715816639"}},"outputId":"a29e8117-b46a-4edb-8351-f05ac256298e"},"id":"xQtWay4Medm7","execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((800, 10), (200, 10))"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","id":"cc4676df","metadata":{"id":"cc4676df"},"source":["<h3> Predictive Analysis - Regression </h3>\n","\n","Recall, regression is a supervised task in which the target/label is numeric type\n","- Numerical comparisons like < or > are meaningful\n","- Statistics like mean, variance, standard deviation, etc. make are meaningful\n","\n","We will talk more about different models in the next module. Here, we will use the basic Linear Regression and discuss how to evaluate a regression model.\n","\n","In sklearn, modeling is very easy. Step-by-step, the cell below\n","1. import the model from the correct sklearn module\n","2. create a new model\n","3. train the model. Notice you have to **provide both features and labels in fit()**."]},{"cell_type":"code","execution_count":null,"id":"0d4fb110","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0d4fb110","executionInfo":{"status":"ok","timestamp":1676299186015,"user_tz":300,"elapsed":172,"user":{"displayName":"Linh Le","userId":"00514130171715816639"}},"outputId":"b8f1d69c-1f46-4a1a-e31a-084401a9bb3e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["LinearRegression()"]},"metadata":{},"execution_count":6}],"source":["from sklearn.linear_model import LinearRegression\n","\n","linear_reg = LinearRegression()\n","\n","linear_reg.fit(trainX_prc,trainY)"]},{"cell_type":"markdown","id":"9cbce430","metadata":{"id":"9cbce430"},"source":["The most common evaluation measurement for regression problem is Mean Squared Error - MSE. As each data point has a true value for the target, and a predicted value made by a model, MSE is the average squared differences among all true/predicted value pairs\n","\n","$MSE = \\dfrac{(true - predicted)^2}{n}$\n","\n","We can import the MSE function from sklearn to use without having to write too much code. \n","\n","After training, all sklearn models will have access to a **predict()** function which can be used to make prediction of the labels based on features. Notice that we only feed the features to predict()"]},{"cell_type":"code","execution_count":null,"id":"9d6bb9ad","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9d6bb9ad","executionInfo":{"status":"ok","timestamp":1676299187581,"user_tz":300,"elapsed":161,"user":{"displayName":"Linh Le","userId":"00514130171715816639"}},"outputId":"d1bd16ad-f1b3-4cde-eba3-53be637b76d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.05687847627686117\n"]}],"source":["from sklearn.metrics import mean_squared_error\n","\n","#get the prediction\n","trainY_pred = linear_reg.predict(trainX_prc)\n","\n","#get the MSE\n","mse_lr = mean_squared_error(trainY, trainY_pred)\n","print(mse_lr)"]},{"cell_type":"markdown","id":"a3e75779","metadata":{"id":"a3e75779"},"source":["Lower MSE means better more accurate models. However, **do not compare MSE of models trained on different data**.\n","\n","A very similar metric is Root Mean Squared Error - RMSE which is the square root of the MSE"]},{"cell_type":"code","execution_count":null,"id":"f319bbb8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f319bbb8","executionInfo":{"status":"ok","timestamp":1676299188508,"user_tz":300,"elapsed":4,"user":{"displayName":"Linh Le","userId":"00514130171715816639"}},"outputId":"4d342433-78b2-4cd0-c48f-438f0200ddc7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.23849208849951642"]},"metadata":{},"execution_count":8}],"source":["np.sqrt(mse_lr)"]},{"cell_type":"markdown","id":"e806d494","metadata":{"id":"e806d494"},"source":["RMSE is intepreted as the average errors between the predicted values and the true values, in this case, the predicted first year GPA and the true first year GPA of the students.\n","\n","Is this a good model? Recall, the range of GPA is from 0 - 4 (or in this data, 2.0 - 4.15), so is an average error of 0.381 good enough?\n","\n","Measurements like MSE and RMSE are dependent on the target range, and could be hard to interprete sometimes. We can use a different measurement that is the R-Squared"]},{"cell_type":"code","execution_count":null,"id":"9bd6aafd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9bd6aafd","executionInfo":{"status":"ok","timestamp":1676299190579,"user_tz":300,"elapsed":167,"user":{"displayName":"Linh Le","userId":"00514130171715816639"}},"outputId":"23b581de-7bce-49bc-9d0f-e7c91cf4ac0e"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8106208828937093\n"]}],"source":["from sklearn.metrics import r2_score\n","\n","r2_lr = r2_score(trainY, trainY_pred)\n","print(r2_lr)"]},{"cell_type":"markdown","id":"adaebf27","metadata":{"id":"adaebf27"},"source":["R2 score is always less than 1, and it is interpreted as the percentage of variation in the data that our model can explain. In cases with very bad-fit models, R2 can get to negative values.\n","\n","In this case, this linear regression model can explain about 81% variation in the data.\n","\n","Now we can see how the model adapt to new data, i.e., the test set"]},{"cell_type":"code","execution_count":null,"id":"44b960e1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"44b960e1","executionInfo":{"status":"ok","timestamp":1676299214378,"user_tz":300,"elapsed":149,"user":{"displayName":"Linh Le","userId":"00514130171715816639"}},"outputId":"3c334f27-9076-4b9e-b7a5-cb92d2935ab8"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.053492752679506615\n"]}],"source":["#get the MSE\n","testY_pred = linear_reg.predict(testX_prc)\n","\n","mse_lr_test = mean_squared_error(testY, testY_pred)\n","print(mse_lr_test)"]},{"cell_type":"code","execution_count":null,"id":"6fc33d85","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6fc33d85","executionInfo":{"status":"ok","timestamp":1676299214987,"user_tz":300,"elapsed":3,"user":{"displayName":"Linh Le","userId":"00514130171715816639"}},"outputId":"d60499be-a576-441a-b1a8-7ef978257ee5"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8150714678652767\n"]}],"source":["r2_lr_test = r2_score(testY, testY_pred)\n","print(r2_lr_test)"]},{"cell_type":"markdown","id":"dabab957","metadata":{"id":"dabab957"},"source":["<h3> Predictive Analysis - Classification </h3>\n","\n","Classification is a supervised task in which the target/label is discrete. We will now utilize the isGRA column as the label. This require a reset of features and labels, and re-splitting them.\n","\n","The pipeline, however, can be directly reused, since the lists of numeric columns and class columns, and all processing steps stay the same."]},{"cell_type":"code","execution_count":null,"id":"aa955f7f","metadata":{"id":"aa955f7f"},"outputs":[],"source":["features = students.drop(['StudentID','FirstName','LastName','FirstYearGPA','FirstYearGPA'], axis=1)\n","labels = students['isGRA']\n","\n","trainX, testX, trainY, testY = train_test_split(features, labels, test_size=0.2)\n","\n","trainX_prc = full_pipeline.fit_transform(trainX)\n","testX_prc = full_pipeline.transform(testX)"]},{"cell_type":"markdown","id":"99715eb5","metadata":{"id":"99715eb5"},"source":["For classification, we use a **Logistic Regression** model. Details will be discussed in later modules. For now, we will import, create, and train the model."]},{"cell_type":"code","execution_count":null,"id":"e0891b00","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"e0891b00","executionInfo":{"status":"ok","timestamp":1676299220717,"user_tz":300,"elapsed":164,"user":{"displayName":"Linh Le","userId":"00514130171715816639"}},"outputId":"e8c48fe8-298e-427c-9cdc-00500e741827"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["LogisticRegression()"]},"metadata":{},"execution_count":13}],"source":["from sklearn.linear_model import LogisticRegression\n","\n","logistic_reg = LogisticRegression()\n","\n","logistic_reg.fit(trainX_prc, trainY)"]},{"cell_type":"markdown","id":"6dff801e","metadata":{"id":"6dff801e"},"source":["<h4>Accuracy</h4>\n","\n","The easiest way to evaluate a classification model is to use **accuracy rate**. Accuracy rate represents how much of the data get assigned labels correctly. In other words, accuracy is the rate of data in which predicted labels are equal to true labels.\n","\n","Accuracy is always between 0 and 1, and can be converted to percent by multiplying to 100"]},{"cell_type":"code","execution_count":null,"id":"4f02aff1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4f02aff1","executionInfo":{"status":"ok","timestamp":1676299221377,"user_tz":300,"elapsed":3,"user":{"displayName":"Linh Le","userId":"00514130171715816639"}},"outputId":"32ca4a4e-b0d2-4f24-801b-e59c0598432b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.89"]},"metadata":{},"execution_count":14}],"source":["logistic_reg.score(trainX_prc, trainY)"]},{"cell_type":"code","execution_count":null,"id":"1ab6574a","metadata":{"id":"1ab6574a"},"outputs":[],"source":["trainY_pred = logistic_reg.predict(trainX_prc)"]},{"cell_type":"markdown","id":"d543f5bf","metadata":{"id":"d543f5bf"},"source":["<h4>F1 Score</h4>\n","\n","Accuracy is not always the best evaluation metric, especially in data that labels have rare values. In such case, the proper metric to use is **F1 score**. F1 is also between 0 and 1, and higher F1 means better models."]},{"cell_type":"code","execution_count":null,"id":"c161db82","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c161db82","executionInfo":{"status":"ok","timestamp":1676299225254,"user_tz":300,"elapsed":460,"user":{"displayName":"Linh Le","userId":"00514130171715816639"}},"outputId":"f33ef4a2-062d-46ed-8591-174e3659d917"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7086092715231788"]},"metadata":{},"execution_count":16}],"source":["from sklearn.metrics import f1_score\n","f1_score(trainY, trainY_pred)"]},{"cell_type":"markdown","id":"bd484aac","metadata":{"id":"bd484aac"},"source":["In the test data"]},{"cell_type":"code","execution_count":null,"id":"1c238393","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1c238393","executionInfo":{"status":"ok","timestamp":1676299229081,"user_tz":300,"elapsed":453,"user":{"displayName":"Linh Le","userId":"00514130171715816639"}},"outputId":"98bd69bd-0d17-46b9-842e-aaa7822c0977"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.915"]},"metadata":{},"execution_count":17}],"source":["testY_pred = logistic_reg.predict(testX_prc)\n","logistic_reg.score(testX_prc, testY)"]},{"cell_type":"code","execution_count":null,"id":"29ce3c83","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"29ce3c83","executionInfo":{"status":"ok","timestamp":1676299229753,"user_tz":300,"elapsed":8,"user":{"displayName":"Linh Le","userId":"00514130171715816639"}},"outputId":"007508e4-c35d-4e2c-ce68-1108d04c324f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7733333333333334"]},"metadata":{},"execution_count":18}],"source":["f1_score(testY, testY_pred)"]},{"cell_type":"code","source":[],"metadata":{"id":"-U8MqPjiOFg0"},"id":"-U8MqPjiOFg0","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.1"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}