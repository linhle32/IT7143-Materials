{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41ac5d3d",
   "metadata": {},
   "source": [
    "<h2>Forecasting</h2>\n",
    "\n",
    "In this module, we discuss the forecasting task. This is a special case of the regression task - the prediction target (label) is numeric, however, we also have the time correlation among the instances in the data. The data for this task is usually referred to as time series data.\n",
    "\n",
    "<h3> One-Dimensional Time Series</h3>\n",
    "\n",
    "These are data with only one column (and possibly some time columns). While they are not that different from higher dimensional sequential data, we start with one dimension for simplicity.\n",
    "\n",
    "For this task, we use the the daily minimum temperature data. This data consists of the daily minimum temperatures from 1981 to 1990 and only has two columns, Date and Temp. The task is to use current/historical data at a date to predict next day's temperature. \n",
    "\n",
    "<h4> Loading and Visualizing Data </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ae3c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8e6c23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1981-01-01</td>\n",
       "      <td>20.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1981-01-02</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1981-01-03</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1981-01-04</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1981-01-05</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3645</th>\n",
       "      <td>1990-12-27</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3646</th>\n",
       "      <td>1990-12-28</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3647</th>\n",
       "      <td>1990-12-29</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>1990-12-30</td>\n",
       "      <td>15.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3650 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Temp\n",
       "0    1981-01-01  20.7\n",
       "1    1981-01-02  17.9\n",
       "2    1981-01-03  18.8\n",
       "3    1981-01-04  14.6\n",
       "4    1981-01-05  15.8\n",
       "...         ...   ...\n",
       "3645 1990-12-27  14.0\n",
       "3646 1990-12-28  13.6\n",
       "3647 1990-12-29  13.5\n",
       "3648 1990-12-30  15.7\n",
       "3649 1990-12-31  13.0\n",
       "\n",
       "[3650 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailytemp = pd.read_csv('daily-min-temperatures.csv')\n",
    "dailytemp['Date'] = pd.to_datetime(dailytemp['Date']) #date will be read in as string, so we manually convert it to pandas date\n",
    "dailytemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85c34698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,3))\n",
    "plt.plot(dailytemp['Date'], dailytemp['Temp'])\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95dd297",
   "metadata": {},
   "source": [
    "<h4>Using with Regular Regression Models</h4>\n",
    "\n",
    "Regular regression models like SVM, decision tree, random forest, while not having been designed specifically for data with time correlations, can still be applied to this task. However, we need to manually process the data to the desired format before being able to use them.\n",
    "\n",
    "<h5>Obtaining Historical Data</h5>\n",
    "\n",
    "In general, we can obtain historical data by having a moving window, for example, 5. Then, for each day, we use its temparature and the previous four as features.\n",
    "\n",
    "Note that for any window size, we will need to remove the first window rows in the data as they do not have enough historical data.\n",
    "\n",
    "Let's investigate the case with window=5. In this case, the 6th row will have enough historical data of 5 days before it, but the 1st-5th do not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "274852cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1981-01-01</td>\n",
       "      <td>20.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1981-01-02</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1981-01-03</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1981-01-04</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1981-01-05</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1981-01-06</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Temp\n",
       "0 1981-01-01  20.7\n",
       "1 1981-01-02  17.9\n",
       "2 1981-01-03  18.8\n",
       "3 1981-01-04  14.6\n",
       "4 1981-01-05  15.8\n",
       "5 1981-01-06  15.8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailytemp.loc[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ccebba",
   "metadata": {},
   "source": [
    "So the historical data for 6th day will be\n",
    "\n",
    "|Date|Temp|Temp (t-1)|Temp (t-2)|Temp (t-3)|Temp (t-4)|Temp (t-5)|\n",
    "|----|----|----------|----------|----------|----------|----------|\n",
    "|1981-01-06\t|15.8|15.8|14.6|18.8|17.9|20.7|\n",
    "\n",
    "This is also called **lagged** data. In this case, lag=window=5. The same transformation will go for the rest of the rows. \n",
    "\n",
    "The lagged data is only the feature part. We still need targets. As the target in the forecasting task we discuss in this class is always next time point, we do a similar shift, but ahead from the current time. So, for the 6th day, lagged data is temparature day 1 - 6, and target is temparature of day 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5afa1179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1981-01-01</td>\n",
       "      <td>20.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1981-01-02</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1981-01-03</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1981-01-04</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1981-01-05</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1981-01-06</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1981-01-07</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Temp\n",
       "0 1981-01-01  20.7\n",
       "1 1981-01-02  17.9\n",
       "2 1981-01-03  18.8\n",
       "3 1981-01-04  14.6\n",
       "4 1981-01-05  15.8\n",
       "5 1981-01-06  15.8\n",
       "6 1981-01-07  15.8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailytemp.loc[:6,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f493b127",
   "metadata": {},
   "source": [
    "|Date|Temp|Temp (t-1)|Temp (t-2)|Temp (t-3)|Temp (t-4)|Temp (t-5)|Temp (next)|\n",
    "|----|----|----------|----------|----------|----------|----------|-----------|\n",
    "|1981-01-06\t|15.8|15.8|14.6|18.8|17.9|20.7|15.8|\n",
    "\n",
    "We will utilize the shift function in pandas to create a dataset of lagged data and next-day target.\n",
    "\n",
    "The function below is reusable for any sequential data with any window size, assuming there is one column for timestamp. You need to input the dataframe, window, and the timecolumn (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ed7744e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_hist_data(data,window,target,timecol=None):\n",
    "    if timecol is None:\n",
    "        lag_data = pd.concat([data.shift(t).add_suffix(f\" (t-{t})\") for t in range(window+1)], axis=1)\n",
    "    else:\n",
    "        time_data = data[timecol]\n",
    "        lag_data = pd.concat([time_data]+[data.drop(timecol,axis=1).shift(t).add_suffix(f\" (t-{t})\") \n",
    "                                          for t in range(window+1)], axis=1)\n",
    "    lag_data = pd.concat([lag_data, data[[target]].shift(-1).add_suffix(\" (next)\")], axis=1)\n",
    "    return lag_data.iloc[window:-1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c07d62",
   "metadata": {},
   "source": [
    "example: window = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4a95c526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Temp (t-0)</th>\n",
       "      <th>Temp (t-1)</th>\n",
       "      <th>Temp (t-2)</th>\n",
       "      <th>Temp (t-3)</th>\n",
       "      <th>Temp (t-4)</th>\n",
       "      <th>Temp (t-5)</th>\n",
       "      <th>Temp (next)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1981-01-06</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>14.6</td>\n",
       "      <td>18.8</td>\n",
       "      <td>17.9</td>\n",
       "      <td>20.7</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1981-01-07</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>14.6</td>\n",
       "      <td>18.8</td>\n",
       "      <td>17.9</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1981-01-08</td>\n",
       "      <td>17.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>14.6</td>\n",
       "      <td>18.8</td>\n",
       "      <td>21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1981-01-09</td>\n",
       "      <td>21.8</td>\n",
       "      <td>17.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>14.6</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1981-01-10</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>17.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>16.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3644</th>\n",
       "      <td>1990-12-26</td>\n",
       "      <td>14.6</td>\n",
       "      <td>12.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>13.2</td>\n",
       "      <td>13.1</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3645</th>\n",
       "      <td>1990-12-27</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>12.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>13.2</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3646</th>\n",
       "      <td>1990-12-28</td>\n",
       "      <td>13.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>12.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3647</th>\n",
       "      <td>1990-12-29</td>\n",
       "      <td>13.5</td>\n",
       "      <td>13.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>12.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>1990-12-30</td>\n",
       "      <td>15.7</td>\n",
       "      <td>13.5</td>\n",
       "      <td>13.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>12.9</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3644 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Temp (t-0)  Temp (t-1)  Temp (t-2)  Temp (t-3)  Temp (t-4)  \\\n",
       "5    1981-01-06        15.8        15.8        14.6        18.8        17.9   \n",
       "6    1981-01-07        15.8        15.8        15.8        14.6        18.8   \n",
       "7    1981-01-08        17.4        15.8        15.8        15.8        14.6   \n",
       "8    1981-01-09        21.8        17.4        15.8        15.8        15.8   \n",
       "9    1981-01-10        20.0        21.8        17.4        15.8        15.8   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "3644 1990-12-26        14.6        12.9        10.0        13.9        13.2   \n",
       "3645 1990-12-27        14.0        14.6        12.9        10.0        13.9   \n",
       "3646 1990-12-28        13.6        14.0        14.6        12.9        10.0   \n",
       "3647 1990-12-29        13.5        13.6        14.0        14.6        12.9   \n",
       "3648 1990-12-30        15.7        13.5        13.6        14.0        14.6   \n",
       "\n",
       "      Temp (t-5)  Temp (next)  \n",
       "5           20.7         15.8  \n",
       "6           17.9         17.4  \n",
       "7           18.8         21.8  \n",
       "8           14.6         20.0  \n",
       "9           15.8         16.2  \n",
       "...          ...          ...  \n",
       "3644        13.1         14.0  \n",
       "3645        13.2         13.6  \n",
       "3646        13.9         13.5  \n",
       "3647        10.0         15.7  \n",
       "3648        12.9         13.0  \n",
       "\n",
       "[3644 rows x 8 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailytemp5 = gen_hist_data(dailytemp, 5, 'Temp', 'Date')\n",
    "dailytemp5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cadb00",
   "metadata": {},
   "source": [
    "example: window = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "80043db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Temp (t-0)</th>\n",
       "      <th>Temp (t-1)</th>\n",
       "      <th>Temp (t-2)</th>\n",
       "      <th>Temp (t-3)</th>\n",
       "      <th>Temp (t-4)</th>\n",
       "      <th>Temp (t-5)</th>\n",
       "      <th>Temp (t-6)</th>\n",
       "      <th>Temp (t-7)</th>\n",
       "      <th>Temp (t-8)</th>\n",
       "      <th>Temp (t-9)</th>\n",
       "      <th>Temp (t-10)</th>\n",
       "      <th>Temp (next)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1981-01-11</td>\n",
       "      <td>16.2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>17.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>14.6</td>\n",
       "      <td>18.8</td>\n",
       "      <td>17.9</td>\n",
       "      <td>20.7</td>\n",
       "      <td>13.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1981-01-12</td>\n",
       "      <td>13.3</td>\n",
       "      <td>16.2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>17.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>14.6</td>\n",
       "      <td>18.8</td>\n",
       "      <td>17.9</td>\n",
       "      <td>16.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1981-01-13</td>\n",
       "      <td>16.7</td>\n",
       "      <td>13.3</td>\n",
       "      <td>16.2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>17.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>14.6</td>\n",
       "      <td>18.8</td>\n",
       "      <td>21.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1981-01-14</td>\n",
       "      <td>21.5</td>\n",
       "      <td>16.7</td>\n",
       "      <td>13.3</td>\n",
       "      <td>16.2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>17.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>14.6</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1981-01-15</td>\n",
       "      <td>25.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>16.7</td>\n",
       "      <td>13.3</td>\n",
       "      <td>16.2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>17.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>20.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3644</th>\n",
       "      <td>1990-12-26</td>\n",
       "      <td>14.6</td>\n",
       "      <td>12.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>13.2</td>\n",
       "      <td>13.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>14.7</td>\n",
       "      <td>17.2</td>\n",
       "      <td>13.9</td>\n",
       "      <td>13.6</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3645</th>\n",
       "      <td>1990-12-27</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>12.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>13.2</td>\n",
       "      <td>13.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>14.7</td>\n",
       "      <td>17.2</td>\n",
       "      <td>13.9</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3646</th>\n",
       "      <td>1990-12-28</td>\n",
       "      <td>13.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>12.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>13.2</td>\n",
       "      <td>13.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>14.7</td>\n",
       "      <td>17.2</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3647</th>\n",
       "      <td>1990-12-29</td>\n",
       "      <td>13.5</td>\n",
       "      <td>13.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>12.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>13.2</td>\n",
       "      <td>13.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>14.7</td>\n",
       "      <td>15.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>1990-12-30</td>\n",
       "      <td>15.7</td>\n",
       "      <td>13.5</td>\n",
       "      <td>13.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>12.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>13.2</td>\n",
       "      <td>13.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3639 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Temp (t-0)  Temp (t-1)  Temp (t-2)  Temp (t-3)  Temp (t-4)  \\\n",
       "10   1981-01-11        16.2        20.0        21.8        17.4        15.8   \n",
       "11   1981-01-12        13.3        16.2        20.0        21.8        17.4   \n",
       "12   1981-01-13        16.7        13.3        16.2        20.0        21.8   \n",
       "13   1981-01-14        21.5        16.7        13.3        16.2        20.0   \n",
       "14   1981-01-15        25.0        21.5        16.7        13.3        16.2   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "3644 1990-12-26        14.6        12.9        10.0        13.9        13.2   \n",
       "3645 1990-12-27        14.0        14.6        12.9        10.0        13.9   \n",
       "3646 1990-12-28        13.6        14.0        14.6        12.9        10.0   \n",
       "3647 1990-12-29        13.5        13.6        14.0        14.6        12.9   \n",
       "3648 1990-12-30        15.7        13.5        13.6        14.0        14.6   \n",
       "\n",
       "      Temp (t-5)  Temp (t-6)  Temp (t-7)  Temp (t-8)  Temp (t-9)  Temp (t-10)  \\\n",
       "10          15.8        15.8        14.6        18.8        17.9         20.7   \n",
       "11          15.8        15.8        15.8        14.6        18.8         17.9   \n",
       "12          17.4        15.8        15.8        15.8        14.6         18.8   \n",
       "13          21.8        17.4        15.8        15.8        15.8         14.6   \n",
       "14          20.0        21.8        17.4        15.8        15.8         15.8   \n",
       "...          ...         ...         ...         ...         ...          ...   \n",
       "3644        13.1        15.4        14.7        17.2        13.9         13.6   \n",
       "3645        13.2        13.1        15.4        14.7        17.2         13.9   \n",
       "3646        13.9        13.2        13.1        15.4        14.7         17.2   \n",
       "3647        10.0        13.9        13.2        13.1        15.4         14.7   \n",
       "3648        12.9        10.0        13.9        13.2        13.1         15.4   \n",
       "\n",
       "      Temp (next)  \n",
       "10           13.3  \n",
       "11           16.7  \n",
       "12           21.5  \n",
       "13           25.0  \n",
       "14           20.7  \n",
       "...           ...  \n",
       "3644         14.0  \n",
       "3645         13.6  \n",
       "3646         13.5  \n",
       "3647         15.7  \n",
       "3648         13.0  \n",
       "\n",
       "[3639 rows x 13 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailytemp10 = gen_hist_data(dailytemp, 10, 'Temp', 'Date')\n",
    "dailytemp10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6d7c91",
   "metadata": {},
   "source": [
    "I will use the data with lag=5 to continue. Next, we split data into training, validation, and testing data. Since this is time correlated data, we will select a time point to split the train and test. In this case, I will use data before 1990 for training and data in 1990 for testing. \n",
    "\n",
    "The below function will split a time series dataset into train and test, as well as split the target from the features. You need to define the input data, time point to split, the target name, and the time column (if any)\n",
    "- With a timecol, the split time should be a string in similar format to the time column\n",
    "- Without a time col, the split time should be the index of the time to split\n",
    "- Similarly like before, this function is reusable in general\n",
    "\n",
    "In order, the function will output training features, testing features, training label, testing label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0aa90ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_seq_data(data,split,target,timecol=None):\n",
    "    if timecol is None:\n",
    "        trainX = data.drop(target, axis=1).loc[:split,:]\n",
    "        testX = data.drop(target, axis=1).loc[split:,:]\n",
    "        trainY = data[target][:split]\n",
    "        testY = data[target][split:]\n",
    "    else:\n",
    "        trainX = data.drop([target,timecol], axis=1).loc[data[timecol] < split, :]\n",
    "        testX = data.drop([target,timecol], axis=1).loc[data[timecol] >= split, :]\n",
    "        trainY = data[target][data[timecol] < split]\n",
    "        testY = data[target][data[timecol]>= split]\n",
    "    return trainX, testX, trainY, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e3caa0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = split_seq_data(dailytemp5, '1990-01-01', 'Temp (next)', 'Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0ad823d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temp (t-0)</th>\n",
       "      <th>Temp (t-1)</th>\n",
       "      <th>Temp (t-2)</th>\n",
       "      <th>Temp (t-3)</th>\n",
       "      <th>Temp (t-4)</th>\n",
       "      <th>Temp (t-5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>14.6</td>\n",
       "      <td>18.8</td>\n",
       "      <td>17.9</td>\n",
       "      <td>20.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>14.6</td>\n",
       "      <td>18.8</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>14.6</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21.8</td>\n",
       "      <td>17.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>17.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3280</th>\n",
       "      <td>13.3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>12.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3281</th>\n",
       "      <td>11.7</td>\n",
       "      <td>13.3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>12.7</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3282</th>\n",
       "      <td>10.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>13.3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3283</th>\n",
       "      <td>14.4</td>\n",
       "      <td>10.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>13.3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3284</th>\n",
       "      <td>12.7</td>\n",
       "      <td>14.4</td>\n",
       "      <td>10.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>13.3</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3280 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Temp (t-0)  Temp (t-1)  Temp (t-2)  Temp (t-3)  Temp (t-4)  Temp (t-5)\n",
       "5           15.8        15.8        14.6        18.8        17.9        20.7\n",
       "6           15.8        15.8        15.8        14.6        18.8        17.9\n",
       "7           17.4        15.8        15.8        15.8        14.6        18.8\n",
       "8           21.8        17.4        15.8        15.8        15.8        14.6\n",
       "9           20.0        21.8        17.4        15.8        15.8        15.8\n",
       "...          ...         ...         ...         ...         ...         ...\n",
       "3280        13.3        16.0        16.4        12.7        12.0        11.8\n",
       "3281        11.7        13.3        16.0        16.4        12.7        12.0\n",
       "3282        10.4        11.7        13.3        16.0        16.4        12.7\n",
       "3283        14.4        10.4        11.7        13.3        16.0        16.4\n",
       "3284        12.7        14.4        10.4        11.7        13.3        16.0\n",
       "\n",
       "[3280 rows x 6 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8cb36b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temp (t-0)</th>\n",
       "      <th>Temp (t-1)</th>\n",
       "      <th>Temp (t-2)</th>\n",
       "      <th>Temp (t-3)</th>\n",
       "      <th>Temp (t-4)</th>\n",
       "      <th>Temp (t-5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3285</th>\n",
       "      <td>14.8</td>\n",
       "      <td>12.7</td>\n",
       "      <td>14.4</td>\n",
       "      <td>10.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>13.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3286</th>\n",
       "      <td>13.3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>12.7</td>\n",
       "      <td>14.4</td>\n",
       "      <td>10.4</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3287</th>\n",
       "      <td>15.6</td>\n",
       "      <td>13.3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>12.7</td>\n",
       "      <td>14.4</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3288</th>\n",
       "      <td>14.5</td>\n",
       "      <td>15.6</td>\n",
       "      <td>13.3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>12.7</td>\n",
       "      <td>14.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3289</th>\n",
       "      <td>14.3</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.6</td>\n",
       "      <td>13.3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3644</th>\n",
       "      <td>14.6</td>\n",
       "      <td>12.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>13.2</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3645</th>\n",
       "      <td>14.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>12.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3646</th>\n",
       "      <td>13.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>12.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3647</th>\n",
       "      <td>13.5</td>\n",
       "      <td>13.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>12.9</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>15.7</td>\n",
       "      <td>13.5</td>\n",
       "      <td>13.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Temp (t-0)  Temp (t-1)  Temp (t-2)  Temp (t-3)  Temp (t-4)  Temp (t-5)\n",
       "3285        14.8        12.7        14.4        10.4        11.7        13.3\n",
       "3286        13.3        14.8        12.7        14.4        10.4        11.7\n",
       "3287        15.6        13.3        14.8        12.7        14.4        10.4\n",
       "3288        14.5        15.6        13.3        14.8        12.7        14.4\n",
       "3289        14.3        14.5        15.6        13.3        14.8        12.7\n",
       "...          ...         ...         ...         ...         ...         ...\n",
       "3644        14.6        12.9        10.0        13.9        13.2        13.1\n",
       "3645        14.0        14.6        12.9        10.0        13.9        13.2\n",
       "3646        13.6        14.0        14.6        12.9        10.0        13.9\n",
       "3647        13.5        13.6        14.0        14.6        12.9        10.0\n",
       "3648        15.7        13.5        13.6        14.0        14.6        12.9\n",
       "\n",
       "[364 rows x 6 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eb05cb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5       15.8\n",
       "6       17.4\n",
       "7       21.8\n",
       "8       20.0\n",
       "9       16.2\n",
       "        ... \n",
       "3280    11.7\n",
       "3281    10.4\n",
       "3282    14.4\n",
       "3283    12.7\n",
       "3284    14.8\n",
       "Name: Temp (next), Length: 3280, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "26ff021f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3285    13.3\n",
       "3286    15.6\n",
       "3287    14.5\n",
       "3288    14.3\n",
       "3289    15.3\n",
       "        ... \n",
       "3644    14.0\n",
       "3645    13.6\n",
       "3646    13.5\n",
       "3647    15.7\n",
       "3648    13.0\n",
       "Name: Temp (next), Length: 364, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0f979b",
   "metadata": {},
   "source": [
    "<h3> Modeling </h3>\n",
    "\n",
    "With the data defined, we can apply regression models like SVR, trees, forests, etc., just like before\n",
    "\n",
    "<h4>Support Vector Regressor</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4ffe0874",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVR(),\n",
       "             param_grid=[{&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                          &#x27;gamma&#x27;: [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                          &#x27;kernel&#x27;: [&#x27;rbf&#x27;]}],\n",
       "             return_train_score=True, scoring=&#x27;r2&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVR(),\n",
       "             param_grid=[{&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                          &#x27;gamma&#x27;: [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                          &#x27;kernel&#x27;: [&#x27;rbf&#x27;]}],\n",
       "             return_train_score=True, scoring=&#x27;r2&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVR</label><div class=\"sk-toggleable__content\"><pre>SVR()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVR(),\n",
       "             param_grid=[{'C': [0.01, 0.1, 1, 10, 100],\n",
       "                          'gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                          'kernel': ['rbf']}],\n",
       "             return_train_score=True, scoring='r2')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "param_grid = [{\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'kernel' : ['rbf'],\n",
    "    'gamma' : [0.01, 0.1, 1, 10, 100]\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(svr, param_grid, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bc720f",
   "metadata": {},
   "source": [
    "The finetuned model (note that score is now R2 since we are doing regression):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "edc4886b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.6313535923306105\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d247a3ce",
   "metadata": {},
   "source": [
    "And the testing performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47e1e35a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6452033263905497"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svr = grid_search.best_estimator_\n",
    "best_svr.score(testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fbee2e",
   "metadata": {},
   "source": [
    "<h4>Decision Tree Regressor</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "821bfe8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
       "             param_grid=[{&#x27;max_depth&#x27;: [3, 4, 5, 6], &#x27;max_features&#x27;: [4],\n",
       "                          &#x27;min_samples_leaf&#x27;: [1, 10, 20, 30, 40],\n",
       "                          &#x27;min_samples_split&#x27;: [2, 10, 20, 30, 40]}],\n",
       "             return_train_score=True, scoring=&#x27;r2&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
       "             param_grid=[{&#x27;max_depth&#x27;: [3, 4, 5, 6], &#x27;max_features&#x27;: [4],\n",
       "                          &#x27;min_samples_leaf&#x27;: [1, 10, 20, 30, 40],\n",
       "                          &#x27;min_samples_split&#x27;: [2, 10, 20, 30, 40]}],\n",
       "             return_train_score=True, scoring=&#x27;r2&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
       "             param_grid=[{'max_depth': [3, 4, 5, 6], 'max_features': [4],\n",
       "                          'min_samples_leaf': [1, 10, 20, 30, 40],\n",
       "                          'min_samples_split': [2, 10, 20, 30, 40]}],\n",
       "             return_train_score=True, scoring='r2')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dtr = DecisionTreeRegressor()\n",
    "\n",
    "param_grid = [{\n",
    "    'max_depth': [3,4,5,6],\n",
    "    'max_features' : [4],\n",
    "    'min_samples_split' : [2, 10, 20, 30, 40],\n",
    "    'min_samples_leaf' : [1, 10, 20, 30, 40]\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(dtr, param_grid, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4606bfc6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6, 'max_features': 4, 'min_samples_leaf': 30, 'min_samples_split': 40}\n",
      "0.5971285202965745\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d3ec005d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6302256775417214"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dt = grid_search.best_estimator_\n",
    "best_dt.score(testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13957094",
   "metadata": {},
   "source": [
    "<h4>Random Forest Regressor</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d29578a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{&#x27;max_depth&#x27;: [3, 4, 5], &#x27;max_features&#x27;: [4],\n",
       "                          &#x27;min_samples_leaf&#x27;: [1, 10, 20, 30, 40],\n",
       "                          &#x27;min_samples_split&#x27;: [2, 10, 20, 30, 40],\n",
       "                          &#x27;n_estimators&#x27;: [5, 10, 20, 50]}],\n",
       "             return_train_score=True, scoring=&#x27;r2&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{&#x27;max_depth&#x27;: [3, 4, 5], &#x27;max_features&#x27;: [4],\n",
       "                          &#x27;min_samples_leaf&#x27;: [1, 10, 20, 30, 40],\n",
       "                          &#x27;min_samples_split&#x27;: [2, 10, 20, 30, 40],\n",
       "                          &#x27;n_estimators&#x27;: [5, 10, 20, 50]}],\n",
       "             return_train_score=True, scoring=&#x27;r2&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{'max_depth': [3, 4, 5], 'max_features': [4],\n",
       "                          'min_samples_leaf': [1, 10, 20, 30, 40],\n",
       "                          'min_samples_split': [2, 10, 20, 30, 40],\n",
       "                          'n_estimators': [5, 10, 20, 50]}],\n",
       "             return_train_score=True, scoring='r2')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "\n",
    "param_grid = [{\n",
    "    'n_estimators' : [5, 10, 20, 50],\n",
    "    'max_depth': [3,4,5],\n",
    "    'max_features' : [4],\n",
    "    'min_samples_split' : [2, 10, 20, 30, 40],\n",
    "    'min_samples_leaf' : [1, 10, 20, 30, 40]\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(rfr, param_grid, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "26651f57",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 4, 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "0.6265604561864488\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "831b0e01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6492139752619523"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dt = grid_search.best_estimator_\n",
    "best_dt.score(testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168b1302",
   "metadata": {},
   "source": [
    "<h4>Neural Network Regressor</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dcf1061",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MLPRegressor(max_iter=2000),\n",
       "             param_grid=[{'alpha': [0.001, 0.01, 0.1, 1, 10],\n",
       "                          'hidden_layer_sizes': [[5, 5], [5, 5, 5], [2, 2],\n",
       "                                                 [2, 2, 2], [10, 10],\n",
       "                                                 [10, 10, 10]]}],\n",
       "             return_train_score=True, scoring='r2')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "n_features = window\n",
    "\n",
    "param_grid = [{\n",
    "    'hidden_layer_sizes' : [[n_features,n_features],                       #two hidden layer with n_features neurons\n",
    "                            [n_features,n_features,n_features],            #three hidden layer with n_features neurons \n",
    "                            [n_features//2,n_features//2],                 #two hidden layer with n_features/2 neurons\n",
    "                            [n_features//2,n_features//2,n_features//2],   #three hidden layer with n_features/2 neurons\n",
    "                            [n_features*2,n_features*2],                   #two hidden layer with n_features*2 neurons\n",
    "                            [n_features*2,n_features*2,n_features*2]],     #three hidden layer with n_features*2 neurons\n",
    "    'alpha' : [0.001, 0.01, 0.1, 1, 10]                                    #regularization terms\n",
    "}]\n",
    "\n",
    "mlp = MLPRegressor(max_iter=2000)\n",
    "\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2135db06",
   "metadata": {},
   "source": [
    "Best training model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26291bf3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 10, 'hidden_layer_sizes': [5, 5, 5]}\n",
      "0.6074306509535325\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bb00e3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.654323350476238"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dt = grid_search.best_estimator_\n",
    "best_dt.score(testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82d8d7a",
   "metadata": {},
   "source": [
    "<h4>Using Longer Historical Data</h4>\n",
    "\n",
    "For this kind of problem, window size can be considered a hyperparameter. Different window size may yield different model performances. Longer historical data is potentially better, however, not all the times, and the improvement might be marginally compared to the increase in model complexity. Furthermore, the larger the window size, the less training data we have. So, this parameter should be selected carefully. \n",
    "\n",
    "Now let's try window=10. We created that data as dailytemp10 previously, so we will split it and retrain the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "302536f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = split_seq_data(dailytemp10, '1990-01-01', 'Temp (next)', 'Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a55fc3",
   "metadata": {},
   "source": [
    "<h5> Support Vector Regressor </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "179ddf80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVR(),\n",
       "             param_grid=[{&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                          &#x27;gamma&#x27;: [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                          &#x27;kernel&#x27;: [&#x27;rbf&#x27;]}],\n",
       "             return_train_score=True, scoring=&#x27;r2&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVR(),\n",
       "             param_grid=[{&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                          &#x27;gamma&#x27;: [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                          &#x27;kernel&#x27;: [&#x27;rbf&#x27;]}],\n",
       "             return_train_score=True, scoring=&#x27;r2&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVR</label><div class=\"sk-toggleable__content\"><pre>SVR()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVR(),\n",
       "             param_grid=[{'C': [0.01, 0.1, 1, 10, 100],\n",
       "                          'gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                          'kernel': ['rbf']}],\n",
       "             return_train_score=True, scoring='r2')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "param_grid = [{\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'kernel' : ['rbf'],\n",
    "    'gamma' : [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(svr, param_grid, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f1682e",
   "metadata": {},
   "source": [
    "The finetuned model (note that score is now R2 since we are doing regression):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "53772103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.6349386352391839\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11e8907",
   "metadata": {},
   "source": [
    "And the testing performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "30fbe984",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6540507735483436"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svr = grid_search.best_estimator_\n",
    "best_svr.score(testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27714bc",
   "metadata": {},
   "source": [
    "<h4>Decision Tree Regressor</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "49d1ed46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
       "             param_grid=[{&#x27;max_depth&#x27;: [3, 4, 5, 6], &#x27;max_features&#x27;: [4],\n",
       "                          &#x27;min_samples_leaf&#x27;: [1, 10, 20, 30, 40],\n",
       "                          &#x27;min_samples_split&#x27;: [2, 10, 20, 30, 40]}],\n",
       "             return_train_score=True, scoring=&#x27;r2&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
       "             param_grid=[{&#x27;max_depth&#x27;: [3, 4, 5, 6], &#x27;max_features&#x27;: [4],\n",
       "                          &#x27;min_samples_leaf&#x27;: [1, 10, 20, 30, 40],\n",
       "                          &#x27;min_samples_split&#x27;: [2, 10, 20, 30, 40]}],\n",
       "             return_train_score=True, scoring=&#x27;r2&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
       "             param_grid=[{'max_depth': [3, 4, 5, 6], 'max_features': [4],\n",
       "                          'min_samples_leaf': [1, 10, 20, 30, 40],\n",
       "                          'min_samples_split': [2, 10, 20, 30, 40]}],\n",
       "             return_train_score=True, scoring='r2')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dtr = DecisionTreeRegressor()\n",
    "\n",
    "param_grid = [{\n",
    "    'max_depth': [3,4,5,6],\n",
    "    'max_features' : [4],\n",
    "    'min_samples_split' : [2, 10, 20, 30, 40],\n",
    "    'min_samples_leaf' : [1, 10, 20, 30, 40]\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(dtr, param_grid, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4104bfc6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 4, 'min_samples_leaf': 10, 'min_samples_split': 30}\n",
      "0.5745055653063447\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d8ec005d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5829644952708148"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dt = grid_search.best_estimator_\n",
    "best_dt.score(testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13967094",
   "metadata": {},
   "source": [
    "<h4>Random Forest Regressor</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d29538a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{&#x27;max_depth&#x27;: [3, 4, 5], &#x27;max_features&#x27;: [4],\n",
       "                          &#x27;min_samples_leaf&#x27;: [1, 10, 20, 30, 40],\n",
       "                          &#x27;min_samples_split&#x27;: [2, 10, 20, 30, 40],\n",
       "                          &#x27;n_estimators&#x27;: [5, 10, 20, 50]}],\n",
       "             return_train_score=True, scoring=&#x27;r2&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{&#x27;max_depth&#x27;: [3, 4, 5], &#x27;max_features&#x27;: [4],\n",
       "                          &#x27;min_samples_leaf&#x27;: [1, 10, 20, 30, 40],\n",
       "                          &#x27;min_samples_split&#x27;: [2, 10, 20, 30, 40],\n",
       "                          &#x27;n_estimators&#x27;: [5, 10, 20, 50]}],\n",
       "             return_train_score=True, scoring=&#x27;r2&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{'max_depth': [3, 4, 5], 'max_features': [4],\n",
       "                          'min_samples_leaf': [1, 10, 20, 30, 40],\n",
       "                          'min_samples_split': [2, 10, 20, 30, 40],\n",
       "                          'n_estimators': [5, 10, 20, 50]}],\n",
       "             return_train_score=True, scoring='r2')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "\n",
    "param_grid = [{\n",
    "    'n_estimators' : [5, 10, 20, 50],\n",
    "    'max_depth': [3,4,5],\n",
    "    'max_features' : [4],\n",
    "    'min_samples_split' : [2, 10, 20, 30, 40],\n",
    "    'min_samples_leaf' : [1, 10, 20, 30, 40]\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(rfr, param_grid, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "26671f57",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 4, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "0.6213425284436289\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "131b0e01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6575329743329863"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dt = grid_search.best_estimator_\n",
    "best_dt.score(testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168b1802",
   "metadata": {},
   "source": [
    "<h4>Neural Network Regressor</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9dcf1661",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MLPRegressor(max_iter=1000),\n",
       "             param_grid=[{'alpha': [0.001, 0.01, 0.1, 1, 10],\n",
       "                          'hidden_layer_sizes': [[10, 10], [10, 10, 10], [5, 5],\n",
       "                                                 [5, 5, 5], [20, 20],\n",
       "                                                 [20, 20, 20]]}],\n",
       "             return_train_score=True, scoring='r2')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "n_features = window\n",
    "\n",
    "param_grid = [{\n",
    "    'hidden_layer_sizes' : [[n_features,n_features],                       #two hidden layer with n_features neurons\n",
    "                            [n_features,n_features,n_features],            #three hidden layer with n_features neurons \n",
    "                            [n_features//2,n_features//2],                 #two hidden layer with n_features/2 neurons\n",
    "                            [n_features//2,n_features//2,n_features//2],   #three hidden layer with n_features/2 neurons\n",
    "                            [n_features*2,n_features*2],                   #two hidden layer with n_features*2 neurons\n",
    "                            [n_features*2,n_features*2,n_features*2]],     #three hidden layer with n_features*2 neurons\n",
    "    'alpha' : [0.001, 0.01, 0.1, 1, 10]                                    #regularization terms\n",
    "}]\n",
    "\n",
    "mlp = MLPRegressor(max_iter=1000)\n",
    "\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2335db06",
   "metadata": {},
   "source": [
    "Best training model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26791bf3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 10, 'hidden_layer_sizes': [5, 5, 5]}\n",
      "0.6175110252511391\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3bb08e3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6643633185675655"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dt = grid_search.best_estimator_\n",
    "best_dt.score(testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c653b2c1",
   "metadata": {},
   "source": [
    "<h3> Deep Learning: Recurrent Neural Network </h3>\n",
    "\n",
    "Recurrent neural network is a special family of neural network specifically designed for sequential data. RNN models can utilize much longer historical data than manually-shifted models as we have been doing.\n",
    "\n",
    "As these are deep learning models, sklearn no longer support them. We will use tensorflow library instead.\n",
    "\n",
    "First, we retransform the data to carry a longer lag. I will use 60. The training features also need to be reshaped for the RNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7732b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 60\n",
    "\n",
    "dailytemp60 = gen_hist_data(dailytemp,60, 'Temp', 'Date')\n",
    "\n",
    "trainX,testX,trainY,testY = split_seq_data(dailytemp60,'1990-01-01','Temp (next)','Date')\n",
    "trainX = trainX.values.reshape(trainX.shape[0],window+1,-1)\n",
    "testX = testX.values.reshape(testX.shape[0],window+1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "50b7768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a37f8122",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 100.4943 - mse: 100.4943 - val_loss: 96.2843 - val_mse: 96.2843\n",
      "Epoch 2/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 87.2142 - mse: 87.2142 - val_loss: 83.7313 - val_mse: 83.7313\n",
      "Epoch 3/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 75.5271 - mse: 75.5271 - val_loss: 72.1771 - val_mse: 72.1771\n",
      "Epoch 4/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 64.3466 - mse: 64.3466 - val_loss: 60.8032 - val_mse: 60.8032\n",
      "Epoch 5/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 53.3919 - mse: 53.3919 - val_loss: 49.8092 - val_mse: 49.8092\n",
      "Epoch 6/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 43.0148 - mse: 43.0148 - val_loss: 39.5530 - val_mse: 39.5530\n",
      "Epoch 7/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 33.5444 - mse: 33.5444 - val_loss: 30.4939 - val_mse: 30.4939\n",
      "Epoch 8/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 25.8472 - mse: 25.8472 - val_loss: 23.4285 - val_mse: 23.4285\n",
      "Epoch 9/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 20.2862 - mse: 20.2862 - val_loss: 18.7139 - val_mse: 18.7139\n",
      "Epoch 10/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 17.1652 - mse: 17.1652 - val_loss: 16.4662 - val_mse: 16.4662\n",
      "Epoch 11/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 15.9746 - mse: 15.9746 - val_loss: 15.7689 - val_mse: 15.7689\n",
      "Epoch 12/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 15.7742 - mse: 15.7742 - val_loss: 15.6481 - val_mse: 15.6481\n",
      "Epoch 13/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 15.6538 - mse: 15.6538 - val_loss: 15.5174 - val_mse: 15.5174\n",
      "Epoch 14/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 15.4790 - mse: 15.4790 - val_loss: 15.3488 - val_mse: 15.3488\n",
      "Epoch 15/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 15.2488 - mse: 15.2488 - val_loss: 15.1406 - val_mse: 15.1406\n",
      "Epoch 16/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 15.0220 - mse: 15.0220 - val_loss: 14.9564 - val_mse: 14.9564\n",
      "Epoch 17/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 14.8315 - mse: 14.8315 - val_loss: 14.8137 - val_mse: 14.8137\n",
      "Epoch 18/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 14.6530 - mse: 14.6530 - val_loss: 14.6740 - val_mse: 14.6740\n",
      "Epoch 19/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 14.4770 - mse: 14.4770 - val_loss: 14.6118 - val_mse: 14.6118\n",
      "Epoch 20/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 14.3223 - mse: 14.3223 - val_loss: 14.3953 - val_mse: 14.3953\n",
      "Epoch 21/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 14.1378 - mse: 14.1378 - val_loss: 14.3255 - val_mse: 14.3255\n",
      "Epoch 22/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 13.9794 - mse: 13.9794 - val_loss: 14.2153 - val_mse: 14.2153\n",
      "Epoch 23/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 13.8352 - mse: 13.8352 - val_loss: 14.0836 - val_mse: 14.0836\n",
      "Epoch 24/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 13.6919 - mse: 13.6919 - val_loss: 13.9735 - val_mse: 13.9735\n",
      "Epoch 25/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 13.5750 - mse: 13.5750 - val_loss: 13.8677 - val_mse: 13.8677\n",
      "Epoch 26/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 13.4320 - mse: 13.4320 - val_loss: 13.7893 - val_mse: 13.7893\n",
      "Epoch 27/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 13.3405 - mse: 13.3405 - val_loss: 13.6492 - val_mse: 13.6492\n",
      "Epoch 28/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 13.2288 - mse: 13.2288 - val_loss: 13.5422 - val_mse: 13.5422\n",
      "Epoch 29/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 13.1137 - mse: 13.1137 - val_loss: 13.4020 - val_mse: 13.4020\n",
      "Epoch 30/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 12.9928 - mse: 12.9928 - val_loss: 13.3012 - val_mse: 13.3012\n",
      "Epoch 31/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 12.8842 - mse: 12.8842 - val_loss: 13.1228 - val_mse: 13.1228\n",
      "Epoch 32/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 12.7217 - mse: 12.7217 - val_loss: 12.9223 - val_mse: 12.9223\n",
      "Epoch 33/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 12.5253 - mse: 12.5253 - val_loss: 12.8162 - val_mse: 12.8162\n",
      "Epoch 34/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 12.3307 - mse: 12.3307 - val_loss: 12.4985 - val_mse: 12.4985\n",
      "Epoch 35/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 12.0721 - mse: 12.0721 - val_loss: 12.1144 - val_mse: 12.1144\n",
      "Epoch 36/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 11.7964 - mse: 11.7964 - val_loss: 11.8083 - val_mse: 11.8083\n",
      "Epoch 37/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 11.4994 - mse: 11.4994 - val_loss: 11.5323 - val_mse: 11.5323\n",
      "Epoch 38/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 11.2091 - mse: 11.2091 - val_loss: 11.1710 - val_mse: 11.1710\n",
      "Epoch 39/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 10.9428 - mse: 10.9428 - val_loss: 10.8690 - val_mse: 10.8690\n",
      "Epoch 40/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 10.6712 - mse: 10.6712 - val_loss: 10.5682 - val_mse: 10.5682\n",
      "Epoch 41/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 10.3865 - mse: 10.3865 - val_loss: 10.2643 - val_mse: 10.2643\n",
      "Epoch 42/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 10.0975 - mse: 10.0975 - val_loss: 9.8931 - val_mse: 9.8931\n",
      "Epoch 43/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 9.7552 - mse: 9.7552 - val_loss: 9.5057 - val_mse: 9.5057\n",
      "Epoch 44/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 9.4583 - mse: 9.4583 - val_loss: 9.2257 - val_mse: 9.2257\n",
      "Epoch 45/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 9.2562 - mse: 9.2562 - val_loss: 8.9032 - val_mse: 8.9032\n",
      "Epoch 46/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 9.0495 - mse: 9.0495 - val_loss: 8.7492 - val_mse: 8.7492\n",
      "Epoch 47/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 8.9258 - mse: 8.9258 - val_loss: 8.5476 - val_mse: 8.5476\n",
      "Epoch 48/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 8.7963 - mse: 8.7963 - val_loss: 8.3896 - val_mse: 8.3896\n",
      "Epoch 49/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 8.6928 - mse: 8.6928 - val_loss: 8.2651 - val_mse: 8.2651\n",
      "Epoch 50/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 8.6176 - mse: 8.6176 - val_loss: 8.2076 - val_mse: 8.2076\n",
      "Epoch 51/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 8.5325 - mse: 8.5325 - val_loss: 8.1698 - val_mse: 8.1698\n",
      "Epoch 52/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 8.4620 - mse: 8.4620 - val_loss: 7.9620 - val_mse: 7.9620\n",
      "Epoch 53/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 8.3807 - mse: 8.3807 - val_loss: 7.9371 - val_mse: 7.9371\n",
      "Epoch 54/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 8.3118 - mse: 8.3118 - val_loss: 7.8419 - val_mse: 7.8419\n",
      "Epoch 55/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 8.2724 - mse: 8.2724 - val_loss: 7.7371 - val_mse: 7.7371\n",
      "Epoch 56/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 8.2068 - mse: 8.2068 - val_loss: 7.7681 - val_mse: 7.7681\n",
      "Epoch 57/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 8.1501 - mse: 8.1501 - val_loss: 7.6401 - val_mse: 7.6401\n",
      "Epoch 58/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 8.0621 - mse: 8.0621 - val_loss: 8.0420 - val_mse: 8.0420\n",
      "Epoch 59/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 8.0297 - mse: 8.0297 - val_loss: 7.4703 - val_mse: 7.4703\n",
      "Epoch 60/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 7.9838 - mse: 7.9838 - val_loss: 7.4232 - val_mse: 7.4232\n",
      "Epoch 61/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 7.9491 - mse: 7.9491 - val_loss: 7.3732 - val_mse: 7.3732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 7.8931 - mse: 7.8931 - val_loss: 7.3707 - val_mse: 7.3707\n",
      "Epoch 63/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 7.8348 - mse: 7.8348 - val_loss: 7.2310 - val_mse: 7.2310\n",
      "Epoch 64/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 7.7759 - mse: 7.7759 - val_loss: 7.1871 - val_mse: 7.1871\n",
      "Epoch 65/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 7.7356 - mse: 7.7356 - val_loss: 7.1766 - val_mse: 7.1766\n",
      "Epoch 66/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 7.6697 - mse: 7.6697 - val_loss: 7.1769 - val_mse: 7.1769\n",
      "Epoch 67/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 7.6271 - mse: 7.6271 - val_loss: 7.0121 - val_mse: 7.0121\n",
      "Epoch 68/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 7.5470 - mse: 7.5470 - val_loss: 7.0660 - val_mse: 7.0660\n",
      "Epoch 69/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 7.5478 - mse: 7.5478 - val_loss: 6.9358 - val_mse: 6.9358\n",
      "Epoch 70/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 7.4532 - mse: 7.4532 - val_loss: 7.0126 - val_mse: 7.0126\n",
      "Epoch 71/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 7.4185 - mse: 7.4185 - val_loss: 6.7865 - val_mse: 6.7865\n",
      "Epoch 72/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 7.3761 - mse: 7.3761 - val_loss: 6.7904 - val_mse: 6.7904\n",
      "Epoch 73/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 7.2823 - mse: 7.2823 - val_loss: 6.7132 - val_mse: 6.7132\n",
      "Epoch 74/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 7.2530 - mse: 7.2530 - val_loss: 6.7693 - val_mse: 6.7693\n",
      "Epoch 75/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 7.2137 - mse: 7.2137 - val_loss: 6.5868 - val_mse: 6.5868\n",
      "Epoch 76/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 7.1520 - mse: 7.1520 - val_loss: 6.6233 - val_mse: 6.6233\n",
      "Epoch 77/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 7.1082 - mse: 7.1082 - val_loss: 6.6516 - val_mse: 6.6516\n",
      "Epoch 78/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 7.0384 - mse: 7.0384 - val_loss: 6.4780 - val_mse: 6.4780\n",
      "Epoch 79/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.9706 - mse: 6.9706 - val_loss: 6.4548 - val_mse: 6.4548\n",
      "Epoch 80/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.9632 - mse: 6.9632 - val_loss: 6.3451 - val_mse: 6.3451\n",
      "Epoch 81/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.8842 - mse: 6.8842 - val_loss: 6.3372 - val_mse: 6.3372\n",
      "Epoch 82/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.8465 - mse: 6.8465 - val_loss: 6.2817 - val_mse: 6.2817\n",
      "Epoch 83/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.8153 - mse: 6.8153 - val_loss: 6.3350 - val_mse: 6.3350\n",
      "Epoch 84/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.7616 - mse: 6.7616 - val_loss: 6.2302 - val_mse: 6.2302\n",
      "Epoch 85/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.7090 - mse: 6.7090 - val_loss: 6.2480 - val_mse: 6.2480\n",
      "Epoch 86/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.6945 - mse: 6.6945 - val_loss: 6.1787 - val_mse: 6.1787\n",
      "Epoch 87/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.6553 - mse: 6.6553 - val_loss: 6.2598 - val_mse: 6.2598\n",
      "Epoch 88/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.6504 - mse: 6.6504 - val_loss: 6.0810 - val_mse: 6.0810\n",
      "Epoch 89/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.5765 - mse: 6.5765 - val_loss: 6.2406 - val_mse: 6.2406\n",
      "Epoch 90/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.5782 - mse: 6.5782 - val_loss: 6.0278 - val_mse: 6.0278\n",
      "Epoch 91/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.5537 - mse: 6.5537 - val_loss: 6.0745 - val_mse: 6.0745\n",
      "Epoch 92/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.5411 - mse: 6.5411 - val_loss: 5.9888 - val_mse: 5.9888\n",
      "Epoch 93/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.4898 - mse: 6.4898 - val_loss: 6.1574 - val_mse: 6.1574\n",
      "Epoch 94/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.4974 - mse: 6.4974 - val_loss: 5.9376 - val_mse: 5.9376\n",
      "Epoch 95/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.4358 - mse: 6.4358 - val_loss: 5.9366 - val_mse: 5.9366\n",
      "Epoch 96/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.4106 - mse: 6.4106 - val_loss: 6.1534 - val_mse: 6.1534\n",
      "Epoch 97/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.4246 - mse: 6.4246 - val_loss: 5.9005 - val_mse: 5.9005\n",
      "Epoch 98/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.3725 - mse: 6.3725 - val_loss: 5.8799 - val_mse: 5.8799\n",
      "Epoch 99/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.3890 - mse: 6.3890 - val_loss: 5.8977 - val_mse: 5.8977\n",
      "Epoch 100/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.3423 - mse: 6.3423 - val_loss: 5.8626 - val_mse: 5.8626\n",
      "Epoch 101/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.3877 - mse: 6.3877 - val_loss: 5.9090 - val_mse: 5.9090\n",
      "Epoch 102/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.3539 - mse: 6.3539 - val_loss: 5.9209 - val_mse: 5.9209\n",
      "Epoch 103/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.3442 - mse: 6.3442 - val_loss: 6.0171 - val_mse: 6.0171\n",
      "Epoch 104/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.3518 - mse: 6.3518 - val_loss: 5.9262 - val_mse: 5.9262\n",
      "Epoch 105/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.3143 - mse: 6.3143 - val_loss: 5.8539 - val_mse: 5.8539\n",
      "Epoch 106/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.3031 - mse: 6.3031 - val_loss: 6.0417 - val_mse: 6.0417\n",
      "Epoch 107/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.3350 - mse: 6.3350 - val_loss: 5.8302 - val_mse: 5.8302\n",
      "Epoch 108/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.3146 - mse: 6.3146 - val_loss: 5.9179 - val_mse: 5.9179\n",
      "Epoch 109/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.2906 - mse: 6.2906 - val_loss: 5.7821 - val_mse: 5.7821\n",
      "Epoch 110/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.2661 - mse: 6.2661 - val_loss: 5.8332 - val_mse: 5.8332\n",
      "Epoch 111/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.2961 - mse: 6.2961 - val_loss: 5.8013 - val_mse: 5.8013\n",
      "Epoch 112/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.2704 - mse: 6.2704 - val_loss: 5.7306 - val_mse: 5.7306\n",
      "Epoch 113/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.2712 - mse: 6.2712 - val_loss: 5.7797 - val_mse: 5.7797\n",
      "Epoch 114/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.2796 - mse: 6.2796 - val_loss: 5.9474 - val_mse: 5.9474\n",
      "Epoch 115/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.2382 - mse: 6.2382 - val_loss: 5.7014 - val_mse: 5.7014\n",
      "Epoch 116/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.2418 - mse: 6.2418 - val_loss: 6.0762 - val_mse: 6.0762\n",
      "Epoch 117/500\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.2661 - mse: 6.2661 - val_loss: 5.8806 - val_mse: 5.8806\n",
      "Epoch 118/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.2472 - mse: 6.2472 - val_loss: 5.7198 - val_mse: 5.7198\n",
      "Epoch 119/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.1995 - mse: 6.1995 - val_loss: 5.8241 - val_mse: 5.8241\n",
      "Epoch 120/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.2392 - mse: 6.2392 - val_loss: 5.7456 - val_mse: 5.7456\n",
      "Epoch 121/500\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.2296 - mse: 6.2296 - val_loss: 5.6864 - val_mse: 5.6864\n",
      "Epoch 122/500\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.2352 - mse: 6.2352 - val_loss: 5.6611 - val_mse: 5.6611\n",
      "Epoch 123/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.2253 - mse: 6.2253 - val_loss: 5.8147 - val_mse: 5.8147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.2095 - mse: 6.2095 - val_loss: 5.6932 - val_mse: 5.6932\n",
      "Epoch 125/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.1987 - mse: 6.1987 - val_loss: 5.6969 - val_mse: 5.6969\n",
      "Epoch 126/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.2051 - mse: 6.2051 - val_loss: 5.7059 - val_mse: 5.7059\n",
      "Epoch 127/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.2233 - mse: 6.2233 - val_loss: 5.9721 - val_mse: 5.9721\n",
      "Epoch 128/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.2117 - mse: 6.2117 - val_loss: 5.6392 - val_mse: 5.6392\n",
      "Epoch 129/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.2067 - mse: 6.2067 - val_loss: 5.7386 - val_mse: 5.7386\n",
      "Epoch 130/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.1974 - mse: 6.1974 - val_loss: 5.9264 - val_mse: 5.9264\n",
      "Epoch 131/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.1889 - mse: 6.1889 - val_loss: 5.6421 - val_mse: 5.6421\n",
      "Epoch 132/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.1941 - mse: 6.1941 - val_loss: 5.6208 - val_mse: 5.6208\n",
      "Epoch 133/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.2010 - mse: 6.2010 - val_loss: 5.6256 - val_mse: 5.6256\n",
      "Epoch 134/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.1946 - mse: 6.1946 - val_loss: 5.6410 - val_mse: 5.6410\n",
      "Epoch 135/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.1836 - mse: 6.1836 - val_loss: 5.7079 - val_mse: 5.7079\n",
      "Epoch 136/500\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.1724 - mse: 6.1724 - val_loss: 5.6255 - val_mse: 5.6255\n",
      "Epoch 137/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.1618 - mse: 6.1618 - val_loss: 6.1946 - val_mse: 6.1946\n",
      "Epoch 138/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.1884 - mse: 6.1884 - val_loss: 5.6076 - val_mse: 5.6076\n",
      "Epoch 139/500\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 6.1799 - mse: 6.1799 - val_loss: 5.7886 - val_mse: 5.7886\n",
      "Epoch 140/500\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 6.1628 - mse: 6.1628 - val_loss: 5.6303 - val_mse: 5.6303\n",
      "Epoch 141/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.1727 - mse: 6.1727 - val_loss: 5.6903 - val_mse: 5.6903\n",
      "Epoch 142/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.1511 - mse: 6.1511 - val_loss: 5.9211 - val_mse: 5.9211\n",
      "Epoch 143/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.1905 - mse: 6.1905 - val_loss: 5.7976 - val_mse: 5.7976\n",
      "Epoch 144/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.1391 - mse: 6.1391 - val_loss: 5.6476 - val_mse: 5.6476\n",
      "Epoch 145/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.1593 - mse: 6.1593 - val_loss: 5.8950 - val_mse: 5.8950\n",
      "Epoch 146/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.1519 - mse: 6.1519 - val_loss: 5.5648 - val_mse: 5.5648\n",
      "Epoch 147/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.1282 - mse: 6.1282 - val_loss: 5.6240 - val_mse: 5.6240\n",
      "Epoch 148/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.1470 - mse: 6.1470 - val_loss: 5.7357 - val_mse: 5.7357\n",
      "Epoch 149/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.1765 - mse: 6.1765 - val_loss: 5.6157 - val_mse: 5.6157\n",
      "Epoch 150/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.1211 - mse: 6.1211 - val_loss: 5.5782 - val_mse: 5.5782\n",
      "Epoch 151/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.1143 - mse: 6.1143 - val_loss: 6.2363 - val_mse: 6.2363\n",
      "Epoch 152/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.1498 - mse: 6.1498 - val_loss: 5.5740 - val_mse: 5.5740\n",
      "Epoch 153/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.1253 - mse: 6.1253 - val_loss: 5.6610 - val_mse: 5.6610\n",
      "Epoch 154/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.1416 - mse: 6.1416 - val_loss: 5.6714 - val_mse: 5.6714\n",
      "Epoch 155/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.1090 - mse: 6.1090 - val_loss: 5.6297 - val_mse: 5.6297\n",
      "Epoch 156/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0935 - mse: 6.0935 - val_loss: 5.5545 - val_mse: 5.5545\n",
      "Epoch 157/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.1056 - mse: 6.1056 - val_loss: 5.5379 - val_mse: 5.5379\n",
      "Epoch 158/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.1012 - mse: 6.1012 - val_loss: 5.5796 - val_mse: 5.5796\n",
      "Epoch 159/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.0839 - mse: 6.0839 - val_loss: 5.6051 - val_mse: 5.6051\n",
      "Epoch 160/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.1166 - mse: 6.1166 - val_loss: 5.5306 - val_mse: 5.5306\n",
      "Epoch 161/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0754 - mse: 6.0754 - val_loss: 5.5266 - val_mse: 5.5266\n",
      "Epoch 162/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.1164 - mse: 6.1164 - val_loss: 5.7836 - val_mse: 5.7836\n",
      "Epoch 163/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0979 - mse: 6.0979 - val_loss: 5.6105 - val_mse: 5.6105\n",
      "Epoch 164/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0466 - mse: 6.0466 - val_loss: 5.5341 - val_mse: 5.5341\n",
      "Epoch 165/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.1007 - mse: 6.1007 - val_loss: 5.4939 - val_mse: 5.4939\n",
      "Epoch 166/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0714 - mse: 6.0714 - val_loss: 5.5536 - val_mse: 5.5536\n",
      "Epoch 167/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0607 - mse: 6.0607 - val_loss: 5.5277 - val_mse: 5.5277\n",
      "Epoch 168/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0807 - mse: 6.0807 - val_loss: 5.4703 - val_mse: 5.4703\n",
      "Epoch 169/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0996 - mse: 6.0996 - val_loss: 5.4677 - val_mse: 5.4677\n",
      "Epoch 170/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0915 - mse: 6.0915 - val_loss: 5.4784 - val_mse: 5.4784\n",
      "Epoch 171/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0588 - mse: 6.0588 - val_loss: 5.4633 - val_mse: 5.4633\n",
      "Epoch 172/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.0784 - mse: 6.0784 - val_loss: 5.9372 - val_mse: 5.9372\n",
      "Epoch 173/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0776 - mse: 6.0776 - val_loss: 5.4731 - val_mse: 5.4731\n",
      "Epoch 174/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0633 - mse: 6.0633 - val_loss: 5.6684 - val_mse: 5.6684\n",
      "Epoch 175/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0579 - mse: 6.0579 - val_loss: 5.6778 - val_mse: 5.6778\n",
      "Epoch 176/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.0613 - mse: 6.0613 - val_loss: 5.4744 - val_mse: 5.4744\n",
      "Epoch 177/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.0686 - mse: 6.0686 - val_loss: 5.5080 - val_mse: 5.5080\n",
      "Epoch 178/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.0764 - mse: 6.0764 - val_loss: 5.5099 - val_mse: 5.5099\n",
      "Epoch 179/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.0534 - mse: 6.0534 - val_loss: 5.4588 - val_mse: 5.4588\n",
      "Epoch 180/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0367 - mse: 6.0367 - val_loss: 5.5788 - val_mse: 5.5788\n",
      "Epoch 181/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0668 - mse: 6.0668 - val_loss: 5.5120 - val_mse: 5.5120\n",
      "Epoch 182/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0312 - mse: 6.0312 - val_loss: 5.9005 - val_mse: 5.9005\n",
      "Epoch 183/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.0432 - mse: 6.0432 - val_loss: 5.4915 - val_mse: 5.4915\n",
      "Epoch 184/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0251 - mse: 6.0251 - val_loss: 5.4483 - val_mse: 5.4483\n",
      "Epoch 185/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0448 - mse: 6.0448 - val_loss: 5.7991 - val_mse: 5.7991\n",
      "Epoch 186/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0594 - mse: 6.0594 - val_loss: 5.7249 - val_mse: 5.7249\n",
      "Epoch 187/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.0367 - mse: 6.0367 - val_loss: 5.4680 - val_mse: 5.4680\n",
      "Epoch 188/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0349 - mse: 6.0349 - val_loss: 5.7551 - val_mse: 5.7551\n",
      "Epoch 189/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0370 - mse: 6.0370 - val_loss: 5.5577 - val_mse: 5.5577\n",
      "Epoch 190/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.0174 - mse: 6.0174 - val_loss: 5.4405 - val_mse: 5.4405\n",
      "Epoch 191/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.0091 - mse: 6.0091 - val_loss: 5.4479 - val_mse: 5.4479\n",
      "Epoch 192/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.0259 - mse: 6.0259 - val_loss: 5.6778 - val_mse: 5.6778\n",
      "Epoch 193/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.0281 - mse: 6.0281 - val_loss: 5.5489 - val_mse: 5.5489\n",
      "Epoch 194/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9936 - mse: 5.9936 - val_loss: 6.0283 - val_mse: 6.0283\n",
      "Epoch 195/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0493 - mse: 6.0493 - val_loss: 5.4069 - val_mse: 5.4069\n",
      "Epoch 196/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0042 - mse: 6.0042 - val_loss: 6.0555 - val_mse: 6.0555\n",
      "Epoch 197/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0446 - mse: 6.0446 - val_loss: 5.4416 - val_mse: 5.4416\n",
      "Epoch 198/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0225 - mse: 6.0225 - val_loss: 5.6921 - val_mse: 5.6921\n",
      "Epoch 199/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0125 - mse: 6.0125 - val_loss: 6.2010 - val_mse: 6.2010\n",
      "Epoch 200/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0475 - mse: 6.0475 - val_loss: 5.3981 - val_mse: 5.3981\n",
      "Epoch 201/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0392 - mse: 6.0392 - val_loss: 5.8283 - val_mse: 5.8283\n",
      "Epoch 202/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0263 - mse: 6.0263 - val_loss: 5.4685 - val_mse: 5.4685\n",
      "Epoch 203/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.0384 - mse: 6.0384 - val_loss: 5.3896 - val_mse: 5.3896\n",
      "Epoch 204/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.0191 - mse: 6.0191 - val_loss: 5.5013 - val_mse: 5.5013\n",
      "Epoch 205/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.0155 - mse: 6.0155 - val_loss: 5.6660 - val_mse: 5.6660\n",
      "Epoch 206/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0458 - mse: 6.0458 - val_loss: 5.4345 - val_mse: 5.4345\n",
      "Epoch 207/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9854 - mse: 5.9854 - val_loss: 6.0478 - val_mse: 6.0478\n",
      "Epoch 208/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0107 - mse: 6.0107 - val_loss: 5.5419 - val_mse: 5.5419\n",
      "Epoch 209/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9829 - mse: 5.9829 - val_loss: 5.4618 - val_mse: 5.4618\n",
      "Epoch 210/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0259 - mse: 6.0259 - val_loss: 5.4154 - val_mse: 5.4154\n",
      "Epoch 211/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9940 - mse: 5.9940 - val_loss: 5.8152 - val_mse: 5.8152\n",
      "Epoch 212/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0268 - mse: 6.0268 - val_loss: 5.5805 - val_mse: 5.5805\n",
      "Epoch 213/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0094 - mse: 6.0094 - val_loss: 5.3871 - val_mse: 5.3871\n",
      "Epoch 214/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9910 - mse: 5.9910 - val_loss: 5.4058 - val_mse: 5.4058\n",
      "Epoch 215/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0039 - mse: 6.0039 - val_loss: 5.7698 - val_mse: 5.7698\n",
      "Epoch 216/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.0280 - mse: 6.0280 - val_loss: 5.4231 - val_mse: 5.4231\n",
      "Epoch 217/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0063 - mse: 6.0063 - val_loss: 5.4165 - val_mse: 5.4165\n",
      "Epoch 218/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9952 - mse: 5.9952 - val_loss: 5.7476 - val_mse: 5.7476\n",
      "Epoch 219/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0085 - mse: 6.0085 - val_loss: 5.3743 - val_mse: 5.3743\n",
      "Epoch 220/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9775 - mse: 5.9775 - val_loss: 5.4641 - val_mse: 5.4641\n",
      "Epoch 221/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0124 - mse: 6.0124 - val_loss: 5.6979 - val_mse: 5.6979\n",
      "Epoch 222/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9913 - mse: 5.9913 - val_loss: 5.4100 - val_mse: 5.4100\n",
      "Epoch 223/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9591 - mse: 5.9591 - val_loss: 5.4927 - val_mse: 5.4927\n",
      "Epoch 224/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9859 - mse: 5.9859 - val_loss: 5.4757 - val_mse: 5.4757\n",
      "Epoch 225/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.0007 - mse: 6.0007 - val_loss: 5.4456 - val_mse: 5.4456\n",
      "Epoch 226/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9714 - mse: 5.9714 - val_loss: 6.1477 - val_mse: 6.1477\n",
      "Epoch 227/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 6.0241 - mse: 6.0241 - val_loss: 5.4648 - val_mse: 5.4648\n",
      "Epoch 228/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9694 - mse: 5.9694 - val_loss: 5.3625 - val_mse: 5.3625\n",
      "Epoch 229/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0179 - mse: 6.0179 - val_loss: 5.3847 - val_mse: 5.3847\n",
      "Epoch 230/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9713 - mse: 5.9713 - val_loss: 5.5008 - val_mse: 5.5008\n",
      "Epoch 231/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0116 - mse: 6.0116 - val_loss: 5.4456 - val_mse: 5.4456\n",
      "Epoch 232/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9724 - mse: 5.9724 - val_loss: 5.4011 - val_mse: 5.4011\n",
      "Epoch 233/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9819 - mse: 5.9819 - val_loss: 5.4057 - val_mse: 5.4057\n",
      "Epoch 234/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9734 - mse: 5.9734 - val_loss: 5.7588 - val_mse: 5.7588\n",
      "Epoch 235/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9932 - mse: 5.9932 - val_loss: 5.5292 - val_mse: 5.5292\n",
      "Epoch 236/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9904 - mse: 5.9904 - val_loss: 5.4413 - val_mse: 5.4413\n",
      "Epoch 237/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9797 - mse: 5.9797 - val_loss: 5.3718 - val_mse: 5.3718\n",
      "Epoch 238/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9716 - mse: 5.9716 - val_loss: 5.5754 - val_mse: 5.5754\n",
      "Epoch 239/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9820 - mse: 5.9820 - val_loss: 5.5517 - val_mse: 5.5517\n",
      "Epoch 240/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9995 - mse: 5.9995 - val_loss: 5.3751 - val_mse: 5.3751\n",
      "Epoch 241/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 6.0176 - mse: 6.0176 - val_loss: 5.4116 - val_mse: 5.4116\n",
      "Epoch 242/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9847 - mse: 5.9847 - val_loss: 5.7178 - val_mse: 5.7178\n",
      "Epoch 243/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9689 - mse: 5.9689 - val_loss: 5.3593 - val_mse: 5.3593\n",
      "Epoch 244/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9648 - mse: 5.9648 - val_loss: 5.3431 - val_mse: 5.3431\n",
      "Epoch 245/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9710 - mse: 5.9710 - val_loss: 5.3744 - val_mse: 5.3744\n",
      "Epoch 246/500\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.9888 - mse: 5.9888 - val_loss: 5.5824 - val_mse: 5.5824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9923 - mse: 5.9923 - val_loss: 5.3290 - val_mse: 5.3290\n",
      "Epoch 248/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9876 - mse: 5.9876 - val_loss: 5.3806 - val_mse: 5.3806\n",
      "Epoch 249/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9754 - mse: 5.9754 - val_loss: 5.5709 - val_mse: 5.5709\n",
      "Epoch 250/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9953 - mse: 5.9953 - val_loss: 5.3685 - val_mse: 5.3685\n",
      "Epoch 251/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9587 - mse: 5.9587 - val_loss: 5.4268 - val_mse: 5.4268\n",
      "Epoch 252/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9623 - mse: 5.9623 - val_loss: 5.6635 - val_mse: 5.6635\n",
      "Epoch 253/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9827 - mse: 5.9827 - val_loss: 5.3643 - val_mse: 5.3643\n",
      "Epoch 254/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9558 - mse: 5.9558 - val_loss: 5.3871 - val_mse: 5.3871\n",
      "Epoch 255/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9687 - mse: 5.9687 - val_loss: 5.3291 - val_mse: 5.3291\n",
      "Epoch 256/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9980 - mse: 5.9980 - val_loss: 5.3724 - val_mse: 5.3724\n",
      "Epoch 257/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9889 - mse: 5.9889 - val_loss: 5.4979 - val_mse: 5.4979\n",
      "Epoch 258/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9729 - mse: 5.9729 - val_loss: 5.3360 - val_mse: 5.3360\n",
      "Epoch 259/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9621 - mse: 5.9621 - val_loss: 5.5232 - val_mse: 5.5232\n",
      "Epoch 260/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9625 - mse: 5.9625 - val_loss: 5.3251 - val_mse: 5.3251\n",
      "Epoch 261/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9817 - mse: 5.9817 - val_loss: 5.5838 - val_mse: 5.5838\n",
      "Epoch 262/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9633 - mse: 5.9633 - val_loss: 5.4328 - val_mse: 5.4328\n",
      "Epoch 263/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9799 - mse: 5.9799 - val_loss: 5.9274 - val_mse: 5.9274\n",
      "Epoch 264/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9362 - mse: 5.9362 - val_loss: 5.4863 - val_mse: 5.4863\n",
      "Epoch 265/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9660 - mse: 5.9660 - val_loss: 5.3849 - val_mse: 5.3849\n",
      "Epoch 266/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9556 - mse: 5.9556 - val_loss: 5.3063 - val_mse: 5.3063\n",
      "Epoch 267/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9247 - mse: 5.9247 - val_loss: 5.3552 - val_mse: 5.3552\n",
      "Epoch 268/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9799 - mse: 5.9799 - val_loss: 5.3855 - val_mse: 5.3855\n",
      "Epoch 269/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9687 - mse: 5.9687 - val_loss: 5.6065 - val_mse: 5.6065\n",
      "Epoch 270/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9726 - mse: 5.9726 - val_loss: 5.3948 - val_mse: 5.3948\n",
      "Epoch 271/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9694 - mse: 5.9694 - val_loss: 5.4994 - val_mse: 5.4994\n",
      "Epoch 272/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9721 - mse: 5.9721 - val_loss: 5.7294 - val_mse: 5.7294\n",
      "Epoch 273/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9378 - mse: 5.9378 - val_loss: 6.9407 - val_mse: 6.9407\n",
      "Epoch 274/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9822 - mse: 5.9822 - val_loss: 5.4790 - val_mse: 5.4790\n",
      "Epoch 275/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9599 - mse: 5.9599 - val_loss: 5.3966 - val_mse: 5.3966\n",
      "Epoch 276/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9241 - mse: 5.9241 - val_loss: 5.4427 - val_mse: 5.4427\n",
      "Epoch 277/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9684 - mse: 5.9684 - val_loss: 5.3358 - val_mse: 5.3358\n",
      "Epoch 278/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9438 - mse: 5.9438 - val_loss: 5.5099 - val_mse: 5.5099\n",
      "Epoch 279/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9615 - mse: 5.9615 - val_loss: 5.3120 - val_mse: 5.3120\n",
      "Epoch 280/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9441 - mse: 5.9441 - val_loss: 5.7622 - val_mse: 5.7622\n",
      "Epoch 281/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9557 - mse: 5.9557 - val_loss: 5.3196 - val_mse: 5.3196\n",
      "Epoch 282/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9427 - mse: 5.9427 - val_loss: 5.6100 - val_mse: 5.6100\n",
      "Epoch 283/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9912 - mse: 5.9912 - val_loss: 5.7482 - val_mse: 5.7482\n",
      "Epoch 284/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9871 - mse: 5.9871 - val_loss: 5.4147 - val_mse: 5.4147\n",
      "Epoch 285/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9545 - mse: 5.9545 - val_loss: 5.5343 - val_mse: 5.5343\n",
      "Epoch 286/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9426 - mse: 5.9426 - val_loss: 5.4170 - val_mse: 5.4170\n",
      "Epoch 287/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9639 - mse: 5.9639 - val_loss: 5.4071 - val_mse: 5.4071\n",
      "Epoch 288/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9855 - mse: 5.9855 - val_loss: 5.3412 - val_mse: 5.3412\n",
      "Epoch 289/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9318 - mse: 5.9318 - val_loss: 5.5739 - val_mse: 5.5739\n",
      "Epoch 290/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9756 - mse: 5.9756 - val_loss: 5.2976 - val_mse: 5.2976\n",
      "Epoch 291/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9475 - mse: 5.9475 - val_loss: 5.3405 - val_mse: 5.3405\n",
      "Epoch 292/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9478 - mse: 5.9478 - val_loss: 5.2922 - val_mse: 5.2922\n",
      "Epoch 293/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9446 - mse: 5.9446 - val_loss: 5.3151 - val_mse: 5.3151\n",
      "Epoch 294/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9534 - mse: 5.9534 - val_loss: 5.3353 - val_mse: 5.3353\n",
      "Epoch 295/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9553 - mse: 5.9553 - val_loss: 5.6357 - val_mse: 5.6357\n",
      "Epoch 296/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9275 - mse: 5.9275 - val_loss: 5.6483 - val_mse: 5.6483\n",
      "Epoch 297/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9560 - mse: 5.9560 - val_loss: 5.3157 - val_mse: 5.3157\n",
      "Epoch 298/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9201 - mse: 5.9201 - val_loss: 5.3239 - val_mse: 5.3239\n",
      "Epoch 299/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9407 - mse: 5.9407 - val_loss: 5.2938 - val_mse: 5.2938\n",
      "Epoch 300/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9823 - mse: 5.9823 - val_loss: 5.3519 - val_mse: 5.3519\n",
      "Epoch 301/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9403 - mse: 5.9403 - val_loss: 5.5848 - val_mse: 5.5848\n",
      "Epoch 302/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9330 - mse: 5.9330 - val_loss: 5.3402 - val_mse: 5.3402\n",
      "Epoch 303/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9447 - mse: 5.9447 - val_loss: 5.3798 - val_mse: 5.3798\n",
      "Epoch 304/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9418 - mse: 5.9418 - val_loss: 5.6933 - val_mse: 5.6933\n",
      "Epoch 305/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9676 - mse: 5.9676 - val_loss: 5.2930 - val_mse: 5.2930\n",
      "Epoch 306/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9439 - mse: 5.9439 - val_loss: 5.4746 - val_mse: 5.4746\n",
      "Epoch 307/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9286 - mse: 5.9286 - val_loss: 5.2966 - val_mse: 5.2966\n",
      "Epoch 308/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9310 - mse: 5.9310 - val_loss: 5.3246 - val_mse: 5.3246\n",
      "Epoch 309/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9465 - mse: 5.9465 - val_loss: 5.3144 - val_mse: 5.3144\n",
      "Epoch 310/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9522 - mse: 5.9522 - val_loss: 5.4394 - val_mse: 5.4394\n",
      "Epoch 311/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9478 - mse: 5.9478 - val_loss: 5.4272 - val_mse: 5.4272\n",
      "Epoch 312/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9516 - mse: 5.9516 - val_loss: 5.4302 - val_mse: 5.4302\n",
      "Epoch 313/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9498 - mse: 5.9498 - val_loss: 5.3800 - val_mse: 5.3800\n",
      "Epoch 314/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9196 - mse: 5.9196 - val_loss: 5.6772 - val_mse: 5.6772\n",
      "Epoch 315/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9417 - mse: 5.9417 - val_loss: 5.4904 - val_mse: 5.4904\n",
      "Epoch 316/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9296 - mse: 5.9296 - val_loss: 5.3691 - val_mse: 5.3691\n",
      "Epoch 317/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9180 - mse: 5.9180 - val_loss: 5.5662 - val_mse: 5.5662\n",
      "Epoch 318/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9855 - mse: 5.9855 - val_loss: 5.4008 - val_mse: 5.4008\n",
      "Epoch 319/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9422 - mse: 5.9422 - val_loss: 5.4797 - val_mse: 5.4797\n",
      "Epoch 320/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9368 - mse: 5.9368 - val_loss: 5.3254 - val_mse: 5.3254\n",
      "Epoch 321/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9392 - mse: 5.9392 - val_loss: 5.2854 - val_mse: 5.2854\n",
      "Epoch 322/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9435 - mse: 5.9435 - val_loss: 5.3850 - val_mse: 5.3850\n",
      "Epoch 323/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9500 - mse: 5.9500 - val_loss: 5.3186 - val_mse: 5.3186\n",
      "Epoch 324/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9782 - mse: 5.9782 - val_loss: 5.3635 - val_mse: 5.3635\n",
      "Epoch 325/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9360 - mse: 5.9360 - val_loss: 5.3446 - val_mse: 5.3446\n",
      "Epoch 326/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9267 - mse: 5.9267 - val_loss: 5.2698 - val_mse: 5.2698\n",
      "Epoch 327/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9244 - mse: 5.9244 - val_loss: 5.6899 - val_mse: 5.6899\n",
      "Epoch 328/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9654 - mse: 5.9654 - val_loss: 5.4522 - val_mse: 5.4522\n",
      "Epoch 329/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9199 - mse: 5.9199 - val_loss: 5.3066 - val_mse: 5.3066\n",
      "Epoch 330/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9271 - mse: 5.9271 - val_loss: 5.5165 - val_mse: 5.5165\n",
      "Epoch 331/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9029 - mse: 5.9029 - val_loss: 5.4255 - val_mse: 5.4255\n",
      "Epoch 332/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9376 - mse: 5.9376 - val_loss: 5.2921 - val_mse: 5.2921\n",
      "Epoch 333/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9603 - mse: 5.9603 - val_loss: 5.2738 - val_mse: 5.2738\n",
      "Epoch 334/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9311 - mse: 5.9311 - val_loss: 5.6054 - val_mse: 5.6054\n",
      "Epoch 335/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9437 - mse: 5.9437 - val_loss: 5.2638 - val_mse: 5.2638\n",
      "Epoch 336/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9357 - mse: 5.9357 - val_loss: 5.5681 - val_mse: 5.5681\n",
      "Epoch 337/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9102 - mse: 5.9102 - val_loss: 5.2752 - val_mse: 5.2752\n",
      "Epoch 338/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9559 - mse: 5.9559 - val_loss: 5.2714 - val_mse: 5.2714\n",
      "Epoch 339/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8968 - mse: 5.8968 - val_loss: 5.5932 - val_mse: 5.5932\n",
      "Epoch 340/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9407 - mse: 5.9407 - val_loss: 5.3711 - val_mse: 5.3711\n",
      "Epoch 341/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9588 - mse: 5.9588 - val_loss: 5.4528 - val_mse: 5.4528\n",
      "Epoch 342/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9246 - mse: 5.9246 - val_loss: 5.3508 - val_mse: 5.3508\n",
      "Epoch 343/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9390 - mse: 5.9390 - val_loss: 5.2900 - val_mse: 5.2900\n",
      "Epoch 344/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9268 - mse: 5.9268 - val_loss: 5.4292 - val_mse: 5.4292\n",
      "Epoch 345/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9132 - mse: 5.9132 - val_loss: 5.2964 - val_mse: 5.2964\n",
      "Epoch 346/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9315 - mse: 5.9315 - val_loss: 5.3258 - val_mse: 5.3258\n",
      "Epoch 347/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9174 - mse: 5.9174 - val_loss: 5.2817 - val_mse: 5.2817\n",
      "Epoch 348/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9315 - mse: 5.9315 - val_loss: 5.2949 - val_mse: 5.2949\n",
      "Epoch 349/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9415 - mse: 5.9415 - val_loss: 5.2909 - val_mse: 5.2909\n",
      "Epoch 350/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9178 - mse: 5.9178 - val_loss: 5.3572 - val_mse: 5.3572\n",
      "Epoch 351/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9472 - mse: 5.9472 - val_loss: 5.4083 - val_mse: 5.4083\n",
      "Epoch 352/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9198 - mse: 5.9198 - val_loss: 5.4333 - val_mse: 5.4333\n",
      "Epoch 353/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9049 - mse: 5.9049 - val_loss: 5.3836 - val_mse: 5.3836\n",
      "Epoch 354/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8999 - mse: 5.8999 - val_loss: 5.2982 - val_mse: 5.2982\n",
      "Epoch 355/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9439 - mse: 5.9439 - val_loss: 5.4713 - val_mse: 5.4713\n",
      "Epoch 356/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9101 - mse: 5.9101 - val_loss: 5.3094 - val_mse: 5.3094\n",
      "Epoch 357/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9105 - mse: 5.9105 - val_loss: 5.4476 - val_mse: 5.4476\n",
      "Epoch 358/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9318 - mse: 5.9318 - val_loss: 5.7661 - val_mse: 5.7661\n",
      "Epoch 359/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9285 - mse: 5.9285 - val_loss: 5.3564 - val_mse: 5.3564\n",
      "Epoch 360/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9172 - mse: 5.9172 - val_loss: 5.3362 - val_mse: 5.3362\n",
      "Epoch 361/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8918 - mse: 5.8918 - val_loss: 5.7847 - val_mse: 5.7847\n",
      "Epoch 362/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9232 - mse: 5.9232 - val_loss: 5.3498 - val_mse: 5.3498\n",
      "Epoch 363/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9235 - mse: 5.9235 - val_loss: 5.6491 - val_mse: 5.6491\n",
      "Epoch 364/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9123 - mse: 5.9123 - val_loss: 5.2651 - val_mse: 5.2651\n",
      "Epoch 365/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9156 - mse: 5.9156 - val_loss: 5.2759 - val_mse: 5.2759\n",
      "Epoch 366/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9387 - mse: 5.9387 - val_loss: 5.3880 - val_mse: 5.3880\n",
      "Epoch 367/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9102 - mse: 5.9102 - val_loss: 5.2818 - val_mse: 5.2818\n",
      "Epoch 368/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9100 - mse: 5.9100 - val_loss: 5.3539 - val_mse: 5.3539\n",
      "Epoch 369/500\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 5.9255 - mse: 5.9255 - val_loss: 5.4212 - val_mse: 5.4212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9211 - mse: 5.9211 - val_loss: 5.4899 - val_mse: 5.4899\n",
      "Epoch 371/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9120 - mse: 5.9120 - val_loss: 5.3674 - val_mse: 5.3674\n",
      "Epoch 372/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9103 - mse: 5.9103 - val_loss: 5.3444 - val_mse: 5.3444\n",
      "Epoch 373/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9124 - mse: 5.9124 - val_loss: 5.4301 - val_mse: 5.4301\n",
      "Epoch 374/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9128 - mse: 5.9128 - val_loss: 5.2431 - val_mse: 5.2431\n",
      "Epoch 375/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9000 - mse: 5.9000 - val_loss: 5.3077 - val_mse: 5.3077\n",
      "Epoch 376/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8907 - mse: 5.8907 - val_loss: 5.3934 - val_mse: 5.3934\n",
      "Epoch 377/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9210 - mse: 5.9210 - val_loss: 5.4273 - val_mse: 5.4273\n",
      "Epoch 378/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8974 - mse: 5.8974 - val_loss: 5.4691 - val_mse: 5.4691\n",
      "Epoch 379/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8953 - mse: 5.8953 - val_loss: 5.4644 - val_mse: 5.4644\n",
      "Epoch 380/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9195 - mse: 5.9195 - val_loss: 5.2797 - val_mse: 5.2797\n",
      "Epoch 381/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9308 - mse: 5.9308 - val_loss: 5.3979 - val_mse: 5.3979\n",
      "Epoch 382/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9444 - mse: 5.9444 - val_loss: 5.2953 - val_mse: 5.2953\n",
      "Epoch 383/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9087 - mse: 5.9087 - val_loss: 5.7641 - val_mse: 5.7641\n",
      "Epoch 384/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9491 - mse: 5.9491 - val_loss: 5.2787 - val_mse: 5.2787\n",
      "Epoch 385/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9228 - mse: 5.9228 - val_loss: 5.2638 - val_mse: 5.2638\n",
      "Epoch 386/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9212 - mse: 5.9212 - val_loss: 5.2912 - val_mse: 5.2912\n",
      "Epoch 387/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9013 - mse: 5.9013 - val_loss: 5.4675 - val_mse: 5.4675\n",
      "Epoch 388/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9310 - mse: 5.9310 - val_loss: 5.3136 - val_mse: 5.3136\n",
      "Epoch 389/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8775 - mse: 5.8775 - val_loss: 5.7414 - val_mse: 5.7414\n",
      "Epoch 390/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9255 - mse: 5.9255 - val_loss: 5.3042 - val_mse: 5.3042\n",
      "Epoch 391/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9030 - mse: 5.9030 - val_loss: 5.2989 - val_mse: 5.2989\n",
      "Epoch 392/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9248 - mse: 5.9248 - val_loss: 5.3196 - val_mse: 5.3196\n",
      "Epoch 393/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9147 - mse: 5.9147 - val_loss: 5.3026 - val_mse: 5.3026\n",
      "Epoch 394/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9405 - mse: 5.9405 - val_loss: 5.3021 - val_mse: 5.3021\n",
      "Epoch 395/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9321 - mse: 5.9321 - val_loss: 5.4500 - val_mse: 5.4500\n",
      "Epoch 396/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9046 - mse: 5.9046 - val_loss: 5.2722 - val_mse: 5.2722\n",
      "Epoch 397/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8864 - mse: 5.8864 - val_loss: 5.3971 - val_mse: 5.3971\n",
      "Epoch 398/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9380 - mse: 5.9380 - val_loss: 5.2432 - val_mse: 5.2432\n",
      "Epoch 399/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8828 - mse: 5.8828 - val_loss: 5.4081 - val_mse: 5.4081\n",
      "Epoch 400/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8986 - mse: 5.8986 - val_loss: 5.3496 - val_mse: 5.3496\n",
      "Epoch 401/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9107 - mse: 5.9107 - val_loss: 5.2798 - val_mse: 5.2798\n",
      "Epoch 402/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8897 - mse: 5.8897 - val_loss: 5.6017 - val_mse: 5.6017\n",
      "Epoch 403/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8945 - mse: 5.8945 - val_loss: 5.2817 - val_mse: 5.2817\n",
      "Epoch 404/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9007 - mse: 5.9007 - val_loss: 5.3939 - val_mse: 5.3939\n",
      "Epoch 405/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9146 - mse: 5.9146 - val_loss: 5.2532 - val_mse: 5.2532\n",
      "Epoch 406/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8892 - mse: 5.8892 - val_loss: 5.5695 - val_mse: 5.5695\n",
      "Epoch 407/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9128 - mse: 5.9128 - val_loss: 5.5424 - val_mse: 5.5424\n",
      "Epoch 408/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9206 - mse: 5.9206 - val_loss: 5.3485 - val_mse: 5.3485\n",
      "Epoch 409/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9227 - mse: 5.9227 - val_loss: 5.2541 - val_mse: 5.2541\n",
      "Epoch 410/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8969 - mse: 5.8969 - val_loss: 5.4479 - val_mse: 5.4479\n",
      "Epoch 411/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9057 - mse: 5.9057 - val_loss: 5.3940 - val_mse: 5.3940\n",
      "Epoch 412/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9319 - mse: 5.9319 - val_loss: 5.4982 - val_mse: 5.4982\n",
      "Epoch 413/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8962 - mse: 5.8962 - val_loss: 5.3583 - val_mse: 5.3583\n",
      "Epoch 414/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9327 - mse: 5.9327 - val_loss: 5.4906 - val_mse: 5.4906\n",
      "Epoch 415/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9165 - mse: 5.9165 - val_loss: 5.3433 - val_mse: 5.3433\n",
      "Epoch 416/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8873 - mse: 5.8873 - val_loss: 5.2730 - val_mse: 5.2730\n",
      "Epoch 417/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8898 - mse: 5.8898 - val_loss: 5.4142 - val_mse: 5.4142\n",
      "Epoch 418/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9223 - mse: 5.9223 - val_loss: 5.2623 - val_mse: 5.2623\n",
      "Epoch 419/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9100 - mse: 5.9100 - val_loss: 5.3614 - val_mse: 5.3614\n",
      "Epoch 420/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9131 - mse: 5.9131 - val_loss: 5.3827 - val_mse: 5.3827\n",
      "Epoch 421/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9170 - mse: 5.9170 - val_loss: 5.2542 - val_mse: 5.2542\n",
      "Epoch 422/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9093 - mse: 5.9093 - val_loss: 5.3553 - val_mse: 5.3553\n",
      "Epoch 423/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8717 - mse: 5.8717 - val_loss: 5.3143 - val_mse: 5.3143\n",
      "Epoch 424/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9043 - mse: 5.9043 - val_loss: 5.3379 - val_mse: 5.3379\n",
      "Epoch 425/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8961 - mse: 5.8961 - val_loss: 5.3085 - val_mse: 5.3085\n",
      "Epoch 426/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9386 - mse: 5.9386 - val_loss: 5.3278 - val_mse: 5.3278\n",
      "Epoch 427/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8882 - mse: 5.8882 - val_loss: 5.3826 - val_mse: 5.3826\n",
      "Epoch 428/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8788 - mse: 5.8788 - val_loss: 5.8320 - val_mse: 5.8320\n",
      "Epoch 429/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8881 - mse: 5.8881 - val_loss: 5.3925 - val_mse: 5.3925\n",
      "Epoch 430/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9005 - mse: 5.9005 - val_loss: 5.4279 - val_mse: 5.4279\n",
      "Epoch 431/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8966 - mse: 5.8966 - val_loss: 5.2661 - val_mse: 5.2661\n",
      "Epoch 432/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9165 - mse: 5.9165 - val_loss: 5.2821 - val_mse: 5.2821\n",
      "Epoch 433/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9054 - mse: 5.9054 - val_loss: 5.3275 - val_mse: 5.3275\n",
      "Epoch 434/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9032 - mse: 5.9032 - val_loss: 5.3602 - val_mse: 5.3602\n",
      "Epoch 435/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9126 - mse: 5.9126 - val_loss: 5.2665 - val_mse: 5.2665\n",
      "Epoch 436/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8993 - mse: 5.8993 - val_loss: 5.2337 - val_mse: 5.2337\n",
      "Epoch 437/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8939 - mse: 5.8939 - val_loss: 5.2862 - val_mse: 5.2862\n",
      "Epoch 438/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8980 - mse: 5.8980 - val_loss: 5.2996 - val_mse: 5.2996\n",
      "Epoch 439/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8868 - mse: 5.8868 - val_loss: 5.3625 - val_mse: 5.3625\n",
      "Epoch 440/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8928 - mse: 5.8928 - val_loss: 5.3444 - val_mse: 5.3444\n",
      "Epoch 441/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8874 - mse: 5.8874 - val_loss: 5.4607 - val_mse: 5.4607\n",
      "Epoch 442/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9061 - mse: 5.9061 - val_loss: 5.4036 - val_mse: 5.4036\n",
      "Epoch 443/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8627 - mse: 5.8627 - val_loss: 5.3438 - val_mse: 5.3438\n",
      "Epoch 444/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8788 - mse: 5.8788 - val_loss: 5.5284 - val_mse: 5.5284\n",
      "Epoch 445/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9172 - mse: 5.9172 - val_loss: 5.3381 - val_mse: 5.3381\n",
      "Epoch 446/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8745 - mse: 5.8745 - val_loss: 5.3139 - val_mse: 5.3139\n",
      "Epoch 447/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8780 - mse: 5.8780 - val_loss: 5.2839 - val_mse: 5.2839\n",
      "Epoch 448/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8831 - mse: 5.8831 - val_loss: 5.2747 - val_mse: 5.2747\n",
      "Epoch 449/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8933 - mse: 5.8933 - val_loss: 5.3180 - val_mse: 5.3180\n",
      "Epoch 450/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9004 - mse: 5.9004 - val_loss: 5.2552 - val_mse: 5.2552\n",
      "Epoch 451/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8808 - mse: 5.8808 - val_loss: 5.3014 - val_mse: 5.3014\n",
      "Epoch 452/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8912 - mse: 5.8912 - val_loss: 5.2807 - val_mse: 5.2807\n",
      "Epoch 453/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8847 - mse: 5.8847 - val_loss: 5.7269 - val_mse: 5.7269\n",
      "Epoch 454/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9024 - mse: 5.9024 - val_loss: 5.2613 - val_mse: 5.2613\n",
      "Epoch 455/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8866 - mse: 5.8866 - val_loss: 5.3735 - val_mse: 5.3735\n",
      "Epoch 456/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8952 - mse: 5.8952 - val_loss: 5.3113 - val_mse: 5.3113\n",
      "Epoch 457/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9178 - mse: 5.9178 - val_loss: 5.2672 - val_mse: 5.2672\n",
      "Epoch 458/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8895 - mse: 5.8895 - val_loss: 5.4285 - val_mse: 5.4285\n",
      "Epoch 459/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8912 - mse: 5.8912 - val_loss: 5.5529 - val_mse: 5.5529\n",
      "Epoch 460/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8937 - mse: 5.8937 - val_loss: 5.5456 - val_mse: 5.5456\n",
      "Epoch 461/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8787 - mse: 5.8787 - val_loss: 5.3500 - val_mse: 5.3500\n",
      "Epoch 462/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8825 - mse: 5.8825 - val_loss: 5.2799 - val_mse: 5.2799\n",
      "Epoch 463/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8769 - mse: 5.8769 - val_loss: 5.3161 - val_mse: 5.3161\n",
      "Epoch 464/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8877 - mse: 5.8877 - val_loss: 5.3714 - val_mse: 5.3714\n",
      "Epoch 465/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8736 - mse: 5.8736 - val_loss: 5.4024 - val_mse: 5.4024\n",
      "Epoch 466/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8686 - mse: 5.8686 - val_loss: 5.4315 - val_mse: 5.4315\n",
      "Epoch 467/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8868 - mse: 5.8868 - val_loss: 5.2627 - val_mse: 5.2627\n",
      "Epoch 468/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8792 - mse: 5.8792 - val_loss: 5.3486 - val_mse: 5.3486\n",
      "Epoch 469/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8973 - mse: 5.8973 - val_loss: 5.4337 - val_mse: 5.4337\n",
      "Epoch 470/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8974 - mse: 5.8974 - val_loss: 5.2385 - val_mse: 5.2385\n",
      "Epoch 471/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8681 - mse: 5.8681 - val_loss: 5.2905 - val_mse: 5.2905\n",
      "Epoch 472/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8683 - mse: 5.8683 - val_loss: 5.3307 - val_mse: 5.3307\n",
      "Epoch 473/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8841 - mse: 5.8841 - val_loss: 5.3658 - val_mse: 5.3658\n",
      "Epoch 474/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8948 - mse: 5.8948 - val_loss: 5.4380 - val_mse: 5.4380\n",
      "Epoch 475/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8947 - mse: 5.8947 - val_loss: 5.3426 - val_mse: 5.3426\n",
      "Epoch 476/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8929 - mse: 5.8929 - val_loss: 5.3025 - val_mse: 5.3025\n",
      "Epoch 477/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8962 - mse: 5.8962 - val_loss: 5.2991 - val_mse: 5.2991\n",
      "Epoch 478/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.9124 - mse: 5.9124 - val_loss: 5.2402 - val_mse: 5.2402\n",
      "Epoch 479/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8929 - mse: 5.8929 - val_loss: 5.2832 - val_mse: 5.2832\n",
      "Epoch 480/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.9192 - mse: 5.9192 - val_loss: 5.3927 - val_mse: 5.3927\n",
      "Epoch 481/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8742 - mse: 5.8742 - val_loss: 5.4126 - val_mse: 5.4126\n",
      "Epoch 482/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8618 - mse: 5.8618 - val_loss: 5.2706 - val_mse: 5.2706\n",
      "Epoch 483/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8729 - mse: 5.8729 - val_loss: 5.2812 - val_mse: 5.2812\n",
      "Epoch 484/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8914 - mse: 5.8914 - val_loss: 5.4014 - val_mse: 5.4014\n",
      "Epoch 485/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8738 - mse: 5.8738 - val_loss: 5.2377 - val_mse: 5.2377\n",
      "Epoch 486/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8801 - mse: 5.8801 - val_loss: 5.3151 - val_mse: 5.3151\n",
      "Epoch 487/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8798 - mse: 5.8798 - val_loss: 5.2683 - val_mse: 5.2683\n",
      "Epoch 488/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8782 - mse: 5.8782 - val_loss: 5.6459 - val_mse: 5.6459\n",
      "Epoch 489/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8789 - mse: 5.8789 - val_loss: 5.3254 - val_mse: 5.3254\n",
      "Epoch 490/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8712 - mse: 5.8712 - val_loss: 5.5725 - val_mse: 5.5725\n",
      "Epoch 491/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8897 - mse: 5.8897 - val_loss: 5.3027 - val_mse: 5.3027\n",
      "Epoch 492/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8734 - mse: 5.8734 - val_loss: 5.2464 - val_mse: 5.2464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 493/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8797 - mse: 5.8797 - val_loss: 5.3691 - val_mse: 5.3691\n",
      "Epoch 494/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8930 - mse: 5.8930 - val_loss: 5.2471 - val_mse: 5.2471\n",
      "Epoch 495/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 5.8843 - mse: 5.8843 - val_loss: 5.6300 - val_mse: 5.6300\n",
      "Epoch 496/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8750 - mse: 5.8750 - val_loss: 5.2565 - val_mse: 5.2565\n",
      "Epoch 497/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8846 - mse: 5.8846 - val_loss: 5.4129 - val_mse: 5.4129\n",
      "Epoch 498/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8820 - mse: 5.8820 - val_loss: 5.2587 - val_mse: 5.2587\n",
      "Epoch 499/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8797 - mse: 5.8797 - val_loss: 5.5095 - val_mse: 5.5095\n",
      "Epoch 500/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 5.8758 - mse: 5.8758 - val_loss: 5.5195 - val_mse: 5.5195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24ef56ba100>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Input([trainX.shape[1],trainX.shape[2]]))\n",
    "model.add(layers.GRU(5))\n",
    "model.add(layers.Dense(5, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mse', metrics=['mse'])\n",
    "\n",
    "model.fit(trainX, trainY, epochs=500, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "694b55fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 0s 4ms/step - loss: 6.0151 - mse: 6.0151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.01509952545166, 6.01509952545166]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e3b8fd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 8ms/step - loss: 5.5038 - mse: 5.5038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.5037522315979, 5.5037522315979]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ed1a7c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6302474784568712"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY_pred = model.predict(testX)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(testY, testY_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
