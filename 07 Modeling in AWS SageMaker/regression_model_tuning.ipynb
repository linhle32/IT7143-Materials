{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "825c8abf",
   "metadata": {},
   "source": [
    "<h3> Loading the data </h3>\n",
    "\n",
    "In this module, we practice with the obesity data. Each row in the data represents a subject. The data has 16 attributes on different measurements of the subjects such as gender, age, height, other test measurements, and the obesity level. The target is obesity level of each subject which is as follows\n",
    "\n",
    "- ObesityLevel = 1 : Insufficient_Weight\n",
    "- ObesityLevel = 2 : Normal_Weight\n",
    "- ObesityLevel = 3 : Overweight_Level_I\n",
    "- ObesityLevel = 4 : Overweight_Level_II\n",
    "- ObesityLevel = 5 : Obesity_Type_I\n",
    "- ObesityLevel = 6 : Obesity_Type_II\n",
    "- ObesityLevel = 7 : Obesity_Type_III\n",
    "\n",
    "We will quickly go through data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53e0f27f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1477, 16), (634, 16), (1477,), (634,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('obesity.csv')\n",
    "\n",
    "features = data.drop('ObesityLevel', axis=1)\n",
    "label = data['ObesityLevel'].values\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(features,label,test_size=0.3)\n",
    "trainX.shape, testX.shape, trainY.shape, testY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192b8539",
   "metadata": {},
   "source": [
    "Some descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd409ae3",
   "metadata": {},
   "source": [
    "We use the standard pipeline as developed previously. We also generate the testdata for AWS models later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c7906ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy as np\n",
    "\n",
    "num_cols = trainX.columns[(trainX.dtypes==np.int64) | (trainX.dtypes==np.float64)]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('standardize', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_cols = trainX.columns[trainX.dtypes==object]\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='constant',fill_value='missing')),\n",
    "    ('encode', OneHotEncoder())\n",
    "])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('numeric', num_pipeline, num_cols),\n",
    "    ('class', cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "trainX_prc = full_pipeline.fit_transform(trainX)\n",
    "\n",
    "\n",
    "testX_prc = full_pipeline.transform(testX)\n",
    "testdata = np.array(testX_prc)                                               #for AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72729be6",
   "metadata": {},
   "source": [
    "<h3>Ridge Regression</h3>\n",
    "\n",
    "This version of the linear regression model does not have regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c48367",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid=[{'alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5,\n",
       "                                    10, 50, 100]}],\n",
       "             return_train_score=True, scoring='r2')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{'alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1 , 5, 10, 50, 100]}]\n",
    "ridge_reg = Ridge()\n",
    "grid_search = GridSearchCV(ridge_reg, param_grid, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX_prc,trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea66d13",
   "metadata": {},
   "source": [
    "We can examine the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d39aeb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9487052303942429"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6456874e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MSE: 0.1772674680842385\n",
      "Testing R2: 0.9569792482350228\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "best_ridge = grid_search.best_estimator_\n",
    "testY_pred_ridge = best_ridge.predict(testX_prc)\n",
    "print('Testing MSE:',mean_squared_error(testY, testY_pred_ridge))\n",
    "print('Testing R2:',r2_score(testY, testY_pred_ridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0f979b",
   "metadata": {},
   "source": [
    "<h3> Support Vector Regressor </h3>\n",
    "\n",
    "All hyperparameters are same with SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ffe0874",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVR(),\n",
       "             param_grid=[{'C': [0.01, 0.1, 1, 10, 100],\n",
       "                          'gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                          'kernel': ['rbf']}],\n",
       "             return_train_score=True, scoring='r2')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "param_grid = [{\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'kernel' : ['rbf'],\n",
    "    'gamma' : [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(svr, param_grid, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX_prc,trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bc720f",
   "metadata": {},
   "source": [
    "The finetuned model (note that score is now R2 since we are doing regression):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edc4886b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.9755209421004893\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d247a3ce",
   "metadata": {},
   "source": [
    "And the testing performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47e1e35a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MSE: 0.10099345614575474\n",
      "Testing R2: 0.975490063384507\n"
     ]
    }
   ],
   "source": [
    "best_svr = grid_search.best_estimator_\n",
    "testY_pred_svr = best_svr.predict(testX_prc)\n",
    "print('Testing MSE:',mean_squared_error(testY, testY_pred_svr))\n",
    "print('Testing R2:',r2_score(testY, testY_pred_svr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27714bc",
   "metadata": {},
   "source": [
    "<h3>Decision Tree Regressor</h3>\n",
    "\n",
    "Hyperparameters are same with DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "821bfe8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
       "             param_grid=[{'max_depth': [3, 4, 5, 6], 'max_features': [5, 7, 9],\n",
       "                          'min_samples_leaf': [1, 10, 20, 30, 40],\n",
       "                          'min_samples_split': [2, 10, 20, 30, 40]}],\n",
       "             return_train_score=True, scoring='r2')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dtr = DecisionTreeRegressor()\n",
    "\n",
    "param_grid = [{\n",
    "    'max_depth': [3,4,5,6],\n",
    "    'max_features' : [5, 7, 9],\n",
    "    'min_samples_split' : [2, 10, 20, 30, 40],\n",
    "    'min_samples_leaf' : [1, 10, 20, 30, 40]\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(dtr, param_grid, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX_prc,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4606bfc6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6, 'max_features': 9, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "0.9085674354564596\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3ec005d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MSE: 0.45363254362250405\n",
      "Testing R2: 0.8899086602713534\n"
     ]
    }
   ],
   "source": [
    "best_dt = grid_search.best_estimator_\n",
    "testY_pred_dt = best_dt.predict(testX_prc)\n",
    "print('Testing MSE:',mean_squared_error(testY, testY_pred_dt))\n",
    "print('Testing R2:',r2_score(testY, testY_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13957094",
   "metadata": {},
   "source": [
    "<h3>Random Forest Regressor</h3>\n",
    "\n",
    "Hyperparamters are same with RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29578a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "\n",
    "param_grid = [{\n",
    "    'n_estimators' : [5, 10, 20, 50],\n",
    "    'max_depth': [3,4,5],\n",
    "    'max_features' : [5, 7, 9],\n",
    "    'min_samples_split' : [2, 10, 20, 30, 40],\n",
    "    'min_samples_leaf' : [1, 10, 20, 30, 40]\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(rfr, param_grid, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX_prc,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26651f57",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 9, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "0.9265202665976616\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "831b0e01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MSE: 0.25168248834212265\n",
      "Testing R2: 0.9389195887346182\n"
     ]
    }
   ],
   "source": [
    "best_rf = grid_search.best_estimator_\n",
    "testY_pred_rf = best_rf.predict(testX_prc)\n",
    "print('Testing MSE:',mean_squared_error(testY, testY_pred_rf))\n",
    "print('Testing R2:',r2_score(testY, testY_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1428400f",
   "metadata": {},
   "source": [
    "<h2>AWS Models</h2>\n",
    "\n",
    "XGBoost and LinearLearner for regression are very similar to classification, we just change the objective when setting up their hyperparameter grids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d2e308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "from sagemaker_models import *\n",
    "from sagemaker.parameter import CategoricalParameter, ContinuousParameter, IntegerParameter\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()                    # Set a default S3 bucket for storing training, validation, and testing data\n",
    "prefix = 'obesity'                                # the folder to store your data in the S3 instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424e14a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#further split training data to training and validation\n",
    "trainX_prc, validX_prc, trainY, validY = train_test_split(trainX_prc,trainY,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761f45b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traindata = np.concatenate([trainY.reshape(-1,1),trainX_prc],axis=1)\n",
    "validdata = np.concatenate([validY.reshape(-1,1),validX_prc],axis=1)\n",
    "pd.DataFrame(traindata).to_csv('train.csv', index=False, header=False)\n",
    "pd.DataFrame(validdata).to_csv('validation.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe83ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048925a9",
   "metadata": {},
   "source": [
    "<h3> XGBoost </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f22d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    'eta': ContinuousParameter(0, 1), \n",
    "    'min_child_weight': ContinuousParameter(1, 10),\n",
    "    'alpha': ContinuousParameter(0, 2), \n",
    "    'max_depth': IntegerParameter(1, 10)\n",
    "}\n",
    "\n",
    "xgb_tuner = get_xgb_regressor(region, bucket, prefix, sess, role, hyperparameter_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cd0a77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_xgboost = xgb_tuner.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge', model_name='xgboost-reg')\n",
    "\n",
    "testY_pred_xgb = predict_xgb_reg(best_xgboost, testX_prc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69c8d601",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MSE: 0.10838363262991277\n",
      "Testing R2: 0.9736965535461803\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print('Testing MSE:',mean_squared_error(testY, testY_pred_xgb))\n",
    "print('Testing R2:',r2_score(testY, testY_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5d9c35",
   "metadata": {},
   "source": [
    "<h4>Removing Endpoint before Moving on to Linear Learner</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a755f2fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_xgboost.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb49c167",
   "metadata": {},
   "source": [
    "<h3>Linear Learner</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049500b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    \"l1\": ContinuousParameter(1e-7, 1, scaling_type=\"Auto\"),\n",
    "    \"wd\": ContinuousParameter(1e-7, 1, scaling_type=\"Auto\"),\n",
    "    \"learning_rate\": ContinuousParameter(1e-5, 1, scaling_type=\"Auto\"),\n",
    "    \"mini_batch_size\": IntegerParameter(100, 500, scaling_type=\"Auto\"),\n",
    "}\n",
    "\n",
    "ll_tuner = get_ll_regressor(region, bucket, prefix, sess, role, hyperparameter_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df2a582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_ll = ll_tuner.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge', model_name='ll-reg')\n",
    "\n",
    "testY_pred_ll = predict_ll_reg(best_ll, testX_prc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6635a355",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MSE: 0.1869729891618434\n",
      "Testing R2: 0.9546238312059322\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print('Testing MSE:',mean_squared_error(testY, testY_pred_ll))\n",
    "print('Testing R2:',r2_score(testY, testY_pred_ll))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c8e4c2",
   "metadata": {},
   "source": [
    "<h3>Final Clean up</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93905be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ll.delete_endpoint(delete_endpoint_config=True)\n",
    "\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "# delete model\n",
    "sagemaker_client.delete_model(ModelName='xgboost-reg')\n",
    "sagemaker_client.delete_model(ModelName='ll-reg')\n",
    "\n",
    "# delete bucket\n",
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket)\n",
    "bucket_to_delete.objects.all().delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
